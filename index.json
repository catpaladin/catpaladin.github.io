[{"content":"If you\u0026rsquo;re using AI code assistance, you\u0026rsquo;re likely familiar with Ollama. You might have heard about coding with Ollama, reducing or even removing your plans with AI providers to run models locally; this keeps your wallet and data safer.\nMost people who talk about local models either have access to powerful home labs, high-end data centers, or the financial means to buy a top-tier GPU. Running even a small model with 40B parameters reliably requires serious hardware; something not everyone can afford. That‚Äôs why Ollama Cloud stands out. It lets you run large open source AI models (with hourly, weekly, and monthly limits at a price).\nLike other AI provider services, they have their monthly plans. And for more than a month, I tried their $20 plan; testing it with OpenCode. This blog is one part documentation of my usage and another part review of the service for coding.\nInitial Takes # Once upon a time, I used Ollama for running local models. That was 2023 into 2024. Then I stopped because I had access to several AI provider services (which worked better for code assist). In 2025, we saw an increase of good quality Open Source (and open weight) models. Ollama started its cloud service in 2025 to allow users to authenticate and call large models hosted on their compute.\nFor most of 2025, from its initial release, I didn\u0026rsquo;t pay the service much attention. OpenRouter offered cheap API access to all the large Open Source models. And I was claude-pilled, living ignorantly in the \u0026ldquo;only use Opus and Sonnet. Ultrathink\u0026rdquo;. That was until I decided to try out OpenCode, in the beginning of December 2025; partly because the neovim plugin was way better than the claude code neovim plugin.\nAs I navigated through my experiments, I found myself relying heavily on Claude and other models to help code my own agents. By combining Claude models with Open Source options, I was able to streamline the process. However, my initial use of these models led to a ban due to violating their terms of service. I was surprised by how quickly this happened; especially since I was simply making parallel calls to Claude using my Claude Code subscription, similar to what OpenCode and Oh My Opencode offered.\nLater, I noticed that bans were becoming more common across OpenCode, particularly among users who opted for Oh My Opencode. Ultimately, I was annoyed that I could easily lose access to my prompt history and conversations over something trivial and I decided to purchase the Ollama Cloud subscription out of spite, with the desire not to use a big AI provider subscription. It was\u0026hellip; a learning curve.\nAt my last job, I was always telling engineers within my org, \u0026ldquo;Use the right model for the right use case.\u0026rdquo; That is definitely the case when exploring and using the cloud models in Ollama Cloud. Now what I write here is mostly applicable to this December 2025 to January 2026 period. The recommended models will have changed when you, yes you in the future, are reading this blog.\nI was actually impressed with Ollama Cloud because they generally released new trending Open Source models within the week of their release. Surprisingly, you could use Gemini 3 Pro and Gemini 3 Flash! However, Gemini 3 Pro uses premium usage, which you are very limited on in their plans. Another surprising note was Devstral. There must be a deal going on with Mistral because throughout December I was able to leverage the devstral-2:123b model without consuming limits.\nLearn You Some Basics # Before I get into the meat of it, I want to go over some of the basics with LLMs and inference. That way my config and Ollama Cloud usage will make more sense.\nUnderstanding how modern language models generate responses is crucial for anyone working with AI tools. Let‚Äôs break it down in simple terms:\ncontext window: determines how much information the model can process at once. A larger window helps it remember more of your conversation or document, making responses more coherent. temperature: controls the model‚Äôs creativity. A lower value makes it more focused, while a higher value encourages more varied and imaginative answers. top-p: helps the model prioritize the most likely words, ensuring responses stay relevant and coherent. top-k: limits the model to the top k most probable words, reducing randomness and increasing control over output. budget tokens: used in models that support thinking, for allocating a portion of their processing power to generate thoughtful, detailed answers. Language models are just next token predictors. You give your model your prompt and some context (markdown, code, output, etc) as inputs. Through the process of Tokenization, the text (in text language models) is broken down into tokens; which can be a word, punctuation mark, or even part of a word. For example, if you were to talk about the \u0026ldquo;cat poop box\u0026rdquo; to a LLM, it would break that into [\u0026ldquo;cat\u0026rdquo;, \u0026ldquo;poop\u0026rdquo;, \u0026ldquo;box\u0026rdquo;], find relevance the parameters of training data and know you are talking about a \u0026ldquo;litter box\u0026rdquo;.\nWhen a model processes the tokens, it is holding all of them in the context window. That includes your prompt, the context, the output, your new prompt, the additional files it reads to understand what you\u0026rsquo;re saying, the output, and so on. This can be crucial for selecting a model for the right task.\nFor a LLM to be useful in coding, it must be able to make tool calls. In fact, I\u0026rsquo;m pretty sure you can\u0026rsquo;t use a language model unless it has tools as a capability. This is because it will need to integrate and execute commands. Keep in mind that any model used for code assist will need to allocate some amount of tokens for context on how to make tool calls.\nAnother capability that isn\u0026rsquo;t necessary, but is useful, is thinking. A thinking model will allocate part of its processing to constructing a plan by predicting what was inferred by the context given. This is very useful when attempting to construct a prompt or give the model your intent, because let\u0026rsquo;s face it, a lot of y\u0026rsquo;all aren\u0026rsquo;t the greatest communicators. Thinking (or reasoning) is best used for planning with agents. Once you have a well crafted prompt and context, it is less necessary to allocate tokens with a thinking model and more efficient to use a model with a large context window, better tool use, and better trained in the task you are assigning it.\nContext windows are important because agents in code assist sessions will summarize your entire conversation and prune all context, when approaching your context limit for your selected model. In addition, your active MCPs are loading all their tools and instructions into context. All of this fills your context with useless information and tokens. There is a Goldilocks Zone where the agent, using a LLM, has a refined prompt and context to output satisfactory code. Outside of that, is the undesirable slop.\nAs the session goes on, you can get diminishing returns unless:\nThe agent can offload state of a task to markdown, beads, tickets, etc The model used to compact succinct summaries of the changes for a simple task to be performed next You use 3rd party plugins to get around this behavior In my experiments with Ollama Cloud and OpenCode, I kept a lot of these basics in mind when trying to determine what models to use for each task.\nThe Config # You have either been anticipating this part, skipped straight to this section, or this information is being summarized by some AI. Either way, I send my regards. In my OpenCode opencode.json, I include the following for default agents:\n\u0026#34;agent\u0026#34;: { \u0026#34;plan\u0026#34;: { \u0026#34;model\u0026#34;: \u0026#34;google/gemini-3-pro-preview\u0026#34; }, \u0026#34;general\u0026#34;: { \u0026#34;model\u0026#34;: \u0026#34;ollama/glm-4.7:cloud\u0026#34; }, \u0026#34;explore\u0026#34;: { \u0026#34;model\u0026#34;: \u0026#34;ollama/glm-4.7:cloud\u0026#34; }, \u0026#34;compaction\u0026#34;: { \u0026#34;model\u0026#34;: \u0026#34;ollama/minimax-m2.1:cloud\u0026#34; } }, Now before you start screaming that I included a non-Ollama model in a blog about Ollama Cloud, I just want to remind you that I said the premium models are very limited in the $20 plan. I would get 20 premium Gemini 3 Pro calls a month. I really like Gemini 3 Pro for refining my plan mode prompt because it\u0026rsquo;s a thinking model with a large context and is fantastic at developing a plan. I start abstractly, giving it a general idea of what I am trying to accomplish; including details on what I have tried to do, what I am intending to do, and what I want at a high level.\nüí° Tip It took me a while to get away from creating explicit prompts straight into an agent. I found mixed success in this method because the model needs at least some context on why you\u0026rsquo;re requesting all those explicit instructions. I was also chat sessions with local models, Mistral\u0026rsquo;s Le Chat, or even Lumo to construct prompts before I discovered the more natural way of leverage plan in OpenCode. It can save you a lot of time and get you closer to your desired result by using this correctly. For the general and explore, I use GLM 4.7. I really like this model and I look forward to Z.ai\u0026rsquo;s future releases. It\u0026rsquo;s fantastic at coding tasks and even GLM 4.7 Flash works amazingly, locally.\nThe most interesting choice is using MiniMax M2.1 for compaction. When this model released, I did not understand the hype. It was satisfactory at frontend work, but I found myself preferring GLM 4.7. Then I started using MiniMax M2.1 for creating markdowns and realized that the summarizes were pretty good. It had the same context window as GLM 4.7, but was running faster because it is not a thinking model (at least not in Ollama). Offloading compaction to MiniMax felt like the right choice because I didn\u0026rsquo;t want to spend API token usage on compaction or deal with context lengths of local models.\nNow for the Ollama provider config. I\u0026rsquo;ll preface this one with saying that it took time to create these configs, in OpenCode. Both OpenCode and Ollama only provide users with the most basic of configs. Like no docs tell you that you can add the example opencode.json:\n{ \u0026#34;$schema\u0026#34;: \u0026#34;https://opencode.ai/config.json\u0026#34;, \u0026#34;provider\u0026#34;: { \u0026#34;ollama\u0026#34;: { \u0026#34;npm\u0026#34;: \u0026#34;@ai-sdk/openai-compatible\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Ollama (local)\u0026#34;, \u0026#34;options\u0026#34;: { \u0026#34;baseURL\u0026#34;: \u0026#34;http://localhost:11434/v1\u0026#34; }, \u0026#34;models\u0026#34;: { \u0026#34;llama2\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Llama 2\u0026#34; } } } } } And then simply run:\nollama pull minimax-m2.1:cloud Which creates a file to let you proxy commands to your local Ollama server to the cloud, using your auth credentials.\nYour opencode.json then looks like:\n{ \u0026#34;$schema\u0026#34;: \u0026#34;https://opencode.ai/config.json\u0026#34;, \u0026#34;provider\u0026#34;: { \u0026#34;ollama\u0026#34;: { \u0026#34;npm\u0026#34;: \u0026#34;@ai-sdk/openai-compatible\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Ollama (local)\u0026#34;, \u0026#34;options\u0026#34;: { \u0026#34;baseURL\u0026#34;: \u0026#34;http://localhost:11434/v1\u0026#34; }, \u0026#34;models\u0026#34;: { \u0026#34;minimax-m2.1:cloud\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;minimax-m2.1:cloud\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;MiniMax M2.1 (cloud)\u0026#34;, \u0026#34;tool_call\u0026#34;: true }, \u0026#34;llama2\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Llama 2\u0026#34; } } } } } And now all of a sudden you can select that model or reference it as ollama/minimax-m2.1:cloud.\nI purely use Ollama for Ollama Cloud now. I prefer to use local models in either LM Studio or llama.cpp if I am seeking speed and performance. The following is my Ollama provider:\n\u0026#34;ollama\u0026#34;: { \u0026#34;npm\u0026#34;: \u0026#34;@ai-sdk/openai-compatible\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Ollama (local)\u0026#34;, \u0026#34;options\u0026#34;: { \u0026#34;baseURL\u0026#34;: \u0026#34;http://localhost:11434/v1\u0026#34; }, \u0026#34;models\u0026#34;: { \u0026#34;gpt-oss:120b-cloud\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;gpt-oss:120b-cloud\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;GPT OSS 120B (cloud)\u0026#34;, \u0026#34;reasoning\u0026#34;: true, \u0026#34;tool_call\u0026#34;: true, \u0026#34;variants\u0026#34;: { \u0026#34;none\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;disabled\u0026#34; } }, \u0026#34;low\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 8000 } }, \u0026#34;medium\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 24000 } }, \u0026#34;high\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 48000 } }, \u0026#34;max\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 64000 } } } }, \u0026#34;gemini-3-flash-preview:cloud\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;gemini-3-flash-preview:cloud\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Gemini 3 Flash Preview (cloud)\u0026#34;, \u0026#34;tool_call\u0026#34;: true }, \u0026#34;devstral-2:123b-cloud\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;devstral-2:123b-cloud\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Devstral 2 123B (cloud)\u0026#34;, \u0026#34;tool_call\u0026#34;: true }, \u0026#34;kimi-k2-thinking:cloud\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;kimi-k2-thinking:cloud\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Kimi K2 Thinking (cloud)\u0026#34;, \u0026#34;tool_call\u0026#34;: true, \u0026#34;limit\u0026#34;: { \u0026#34;context\u0026#34;: 262144, \u0026#34;output\u0026#34;: 128000 }, \u0026#34;options\u0026#34;: { \u0026#34;temperature\u0026#34;: 1, \u0026#34;top_k\u0026#34;: 40, \u0026#34;top_p\u0026#34;: 0.95, \u0026#34;maxOutputTokens\u0026#34;: 128000, \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 64000 } }, \u0026#34;variants\u0026#34;: { \u0026#34;none\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;disabled\u0026#34; } }, \u0026#34;low\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 8000 } }, \u0026#34;medium\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 24000 } }, \u0026#34;high\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 48000 } }, \u0026#34;max\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 64000 } } } }, \u0026#34;minimax-m2.1:cloud\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;minimax-m2.1:cloud\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;MiniMax M2.1 (cloud)\u0026#34;, \u0026#34;tool_call\u0026#34;: true }, \u0026#34;glm-4.7:cloud\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;glm-4.7:cloud\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;GLM 4.7 (cloud)\u0026#34;, \u0026#34;reasoning\u0026#34;: true, \u0026#34;tool_call\u0026#34;: true, \u0026#34;limit\u0026#34;: { \u0026#34;context\u0026#34;: 204800, \u0026#34;output\u0026#34;: 128000 }, \u0026#34;options\u0026#34;: { \u0026#34;temperature\u0026#34;: 0.7, \u0026#34;top_k\u0026#34;: 40, \u0026#34;top_p\u0026#34;: 0.95, \u0026#34;maxOutputTokens\u0026#34;: 128000, \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 64000 } }, \u0026#34;variants\u0026#34;: { \u0026#34;none\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;disabled\u0026#34; } }, \u0026#34;low\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 8000 } }, \u0026#34;medium\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 24000 } }, \u0026#34;high\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 48000 } }, \u0026#34;max\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 64000 } } } } } }, One thing you may note is variants. OpenCode provides some documentation on this but they are very useful on any thinking model, as you may want to allocate more tokens, depending on how complex the task is. Passively watching the OpenCode discord, I saw that this was common for budgets of thinking:\n\u0026#34;variants\u0026#34;: { \u0026#34;none\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;disabled\u0026#34; } }, \u0026#34;low\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 8000 } }, \u0026#34;medium\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 24000 } }, \u0026#34;high\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 48000 } }, \u0026#34;max\u0026#34;: { \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 64000 } } } Next are limits. I only discovered this because of people in the discord. There is no documentation on this lol. These are less important with the cloud models because you are leveraging compute that you do not own. However, I heavily use limits on local LLMs, due to resource constraints. This is just a side-effect of my other configs.\n\u0026#34;limit\u0026#34;: { \u0026#34;context\u0026#34;: 204800, \u0026#34;output\u0026#34;: 128000 }, üí° Tip You can find the max tokens for context and output on models.dev Model options are important because Ollama defaults all its cloud models to its recommended parameters. This may or may not work for everyone, depending on the task. I tend to tweak these settings as I start to notice a model drifting or generating undesirable code.\n\u0026#34;options\u0026#34;: { \u0026#34;temperature\u0026#34;: 1, \u0026#34;top_k\u0026#34;: 40, \u0026#34;top_p\u0026#34;: 0.95, \u0026#34;maxOutputTokens\u0026#34;: 128000, \u0026#34;thinking\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;enabled\u0026#34;, \u0026#34;budgetTokens\u0026#34;: 64000 } }, The thinking budget is the default for when this model gets run as a subagent (since you have more control with variants as the primary agent).\nHere is a quick and dirty rundown of what I used each model for:\nModel Usage gpt-oss:120b-cloud Primarily document summarization when dealing with Obsidian markdowns in the AI vault gemini-3-flash-preview Subagent that can load massive amounts of skills and context to perform a task or create documents devstral-2:123b-cloud FREE! But I used to use it a lot for code exploration and pattern analysis to load into context kimi-k2-thinking:cloud Used to use heavily for plans and brainstorming when I needed a good reasoning model. Now used when I hit my Gemini 3 Pro limits and don\u0026rsquo;t want to use API usage minimax-m2.1:cloud Compaction GOAT. Sometimes helps do frontend. Sometimes\u0026hellip; glm-4.7:cloud All-Around model of choice for almost every task or subagent default model But in the End, Does it Even Matter? # Not really. Unless you\u0026rsquo;re trying to find alternatives to being locked in to proprietary AI providers. I love running local LLMs, but for coding I still need to use cloud models for it to be worth it. Ollama Cloud is a good AI provider that I use day-to-day.\nIs it better than the coding plans of the top AI providers with their proprietary models? Debatable, but I would take it over two of them. I like the appeal of being able to try out a variety of Open Source models from different labs. It also lets me experiment to see if paying API usage for certain models are worth it.\nFinding a good AI provider, with access to good models AND good privacy practices is important. If you\u0026rsquo;re interested, I suggest you read Ollama\u0026rsquo;s Terms of Service and Privacy Policy to see if it meets your needs.\nüìù Note This blog was drafted in Obsidian by me. In some parts, I ran my text through a tiny model, using liquid/lfm2.5-1.2b, to summarize my verbal diarrhea. References # Ollama Models Ollama Cloud Pricing Ollama Docs - OpenCode OpenCode Providers - Ollama ","date":"Jan 25, 2026","permalink":"https://blog.mikesahari.com/posts/ollama-cloud-for-coding/","tags":["ai","opencode","neovim","ollama","agents"],"title":"Ollama Cloud for Coding"},{"content":"Coding assistants are all over the place; at least at the time of writing this. Some of them require you to LOCK IN to their service. Others extend to a limited amount of providers. And then there\u0026rsquo;s VSCode\u0026hellip; just kidding, it\u0026rsquo;s alright, but I prefer Neovim (I use neovim btw). Last month (relative to the time of writing this), I was intrigued and reading into improvements in local LLMs; big improvements to tiny and small models! That led me on a search for a coding assistant that supported running local LLMs, but in Neovim. Enter, OpenCode.\nOpenCode is an AI-powered coding assistant that runs in your terminal, helping you write code by delegating tasks to specialized agents. Even better, they have a neovim plugin! Reading the documentation, I liked some of the feature parity with Claude Code. It gave me ideas how I could save money and reduce hitting limits. This experimentation got me more familiar with Agents (used in terms of this specific tool use).\nThe Task tool is your main way to spawn these agents, which can handle complex, multi-step operations on their own. These agents aren\u0026rsquo;t just fancy AI; they\u0026rsquo;re like specialized workers who can:\nExecute multi-step tasks independently Access the same tools as the main agent (file operations, shell commands, etc.) Focus on specific domains (testing, documentation, exploration) Work in isolation without cluttering the main conversation context This blog is less of a technical tutorial, and more of how some configurations to features in OpenCode helped me speed up development with some personal projects. Agents can be very helpful when used correctly. I will show you a little how I use agents and hopefully help your workflow.\nIf you\u0026rsquo;re interested in installing and setting up OpenCode, even before I you read everything I said, then I recommend following the instructions on their page!\nWhat Do You Mean By.. Agents # Agents, in the context of this blog, are software components to your AI coding assistant (i.e. OpenCode). They are file based and perform operations (like executing tools) using LLMs. An agent can read files, loading it into context, giving it access to knowledge/instructions.\nHow Do Agents Work # You\u0026rsquo;re not still opening a single AI code assist session, prompting, and waiting to finish, right? You can have agents (and subagents) running in parallel, as long as you have the money and/or limits.\nIf you have several subscriptions AND access to API keys, then you\u0026rsquo;re ready to GO ALL OUT! (and burn all that money)\nFirst, let me explain agents and subagents for context:\nAgents: the primary chat tool that takes instructions, can call tools, and do work Subagents: the same as an Agent, but are started by the Agent (ranging from general skills to customized specialist skills) Here is a high-level of a user prompt to chat with an agent and use a specialized agent to perform the work:\nsequenceDiagram participant User participant Agent participant LLM participant Subagent User-\u0026gt;\u0026gt;Agent: Prompt sent\u0026lt;br\u0026gt;referencing\u0026lt;br\u0026gt;@doc-generator Agent-\u0026gt;\u0026gt;LLM: Process task request\u0026lt;br\u0026gt;and create prompt LLM-\u0026gt;\u0026gt;Agent: Return formatted prompt\u0026lt;br\u0026gt;for subagent Agent-\u0026gt;\u0026gt;Subagent: Call task tool\u0026lt;br\u0026gt;with generated prompt Subagent-\u0026gt;\u0026gt;Subagent: Execute task\u0026lt;br\u0026gt;(e.g., create README.md) Subagent--\u0026gt;\u0026gt;Agent: Return task results Agent--\u0026gt;\u0026gt;User: Show\u0026lt;br\u0026gt;completion\u0026lt;br\u0026gt;summary The Task Tool # The Task tool is your gateway to spawning specialized agents. When you use it, you\u0026rsquo;re essentially saying: \u0026ldquo;Hey, I need you to handle this specific task, and you can work on it independently.\u0026rdquo;\nBasic Task tool usage:\n{ \u0026#34;tool\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;A brief description of what this task accomplishes\u0026#34;, \u0026#34;prompt\u0026#34;: \u0026#34;Detailed instructions for the subagent\u0026#34;, \u0026#34;subagent_type\u0026#34;: \u0026#34;general\u0026#34; } } Key Parameters # Parameter Required Description description Yes Short summary shown in logs and UI prompt Yes Detailed instructions for the subagent subagent_type No Type of agent to spawn (defaults to general) You don\u0026rsquo;t really need to know how to form the task. This is just to give you an idea of what the structure of the tool call looks like.\nThe subagent_type Parameter # This determines which system prompt and capabilities the subagent receives:\ngeneral - Default agent for multi-purpose tasks explore - Optimized for codebase exploration and analysis Custom types - User-defined agents with specialized prompts When to Use Subagents # Use subagents when:\nThe task requires multiple steps or file operations You need focused work without cluttering the main conversation The task benefits from a specialized system prompt You want to parallelize independent work streams The operation is self-contained and can be delegated Avoid subagents when:\nA single tool call suffices You need immediate, interactive feedback The task requires ongoing context from the main conversation üí° Tip If you are using a single tool call with a custom agent that can be tool called, make sure you don\u0026rsquo;t have any instructions in that agent saying to call a subagent. I ran into an issue where the agent couldn\u0026rsquo;t even start my webfetch tool request because it was essentially fork bombing itself to spin up a copy of itself to make the webfetch request and waiting for its reply. Also who knows, that could be fixed in the future. Just Some Lo-Fi Basics to Vibe to # Your OpenCode configuration file opencode.json (project level) or ~/.config/opencode.json (global level) specifies what mcps, models, plugins, rules, and more your agents can have access to.\nThe Config # Here is a stripped down example of my global opencode.json. I only put examples using two of the ways I run local LLMs. I also included a plugin that I am starting to use. I love Beads!\n{ \u0026#34;$schema\u0026#34;: \u0026#34;https://opencode.ai/config.json\u0026#34;, \u0026#34;mcp\u0026#34;: {}, \u0026#34;provider\u0026#34;: { \u0026#34;ollama\u0026#34;: { \u0026#34;npm\u0026#34;: \u0026#34;@ai-sdk/openai-compatible\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Ollama (local)\u0026#34;, \u0026#34;options\u0026#34;: { \u0026#34;baseURL\u0026#34;: \u0026#34;http://localhost:11434/v1\u0026#34; }, \u0026#34;models\u0026#34;: { \u0026#34;gpt-oss:20b\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;gpt-oss:20b-32k\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;GPT OSS 20B (32k)\u0026#34;, \u0026#34;reasoning\u0026#34;: true, \u0026#34;tool_call\u0026#34;: true }, \u0026#34;gpt-oss:20b-cloud\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;gpt-oss:20b-cloud\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;GPT OSS 20B (cloud)\u0026#34;, \u0026#34;reasoning\u0026#34;: true, \u0026#34;tool_call\u0026#34;: true } } }, \u0026#34;lm-studio\u0026#34;: { \u0026#34;npm\u0026#34;: \u0026#34;@ai-sdk/openai-compatible\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;LM Studio (local)\u0026#34;, \u0026#34;options\u0026#34;: { \u0026#34;baseURL\u0026#34;: \u0026#34;http://localhost:1234/v1\u0026#34; }, \u0026#34;models\u0026#34;: { \u0026#34;nvidia/nemotron-3-nano\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;nvidia/nemotron-3-nano\u0026#34;, \u0026#34;reasoning\u0026#34;: true, \u0026#34;tool_call\u0026#34;: true } } } }, \u0026#34;plugin\u0026#34;: [\u0026#34;opencode-beads\u0026#34;] } Anyways, this config is necessary to establish the models available, and include them in the Agent markdowns (or jsons, if you like to suffer). I will be showing examples of agents below.\nWhen an agent selects their model, with the model field, they select by id. This is an important fact to know when you don\u0026rsquo;t want to use Claude Opus for everything; using up $50 in tokens like it two pieces of toilet paper.\nAgent Files (markdown format) # Personally, I prefer to create these and everything in markdown. However the config is required to be in json format. The OpenCode docs have more detailed information.\nHere\u0026rsquo;s an example from that page:\n--- description: Reviews code for quality and best practices mode: subagent model: anthropic/claude-sonnet-4-20250514 temperature: 0.1 tools: write: false edit: false bash: false --- You are in code review mode. Focus on: - Code quality and best practices - Potential bugs and edge cases - Performance implications - Security considerations Provide constructive feedback without making direct changes. If I wanted to use this review agent, I could either save it:\nGlobally: ~/.config/opencode/agent/subagents/review.md Project Level: .opencode/agent/subagents/review.md I\u0026rsquo;ll talk more on these files in examples below.\nModel Selection (Right Tool vs Golden Hammer) # There are sites, tech influencers, and AI companies that will tell you to use some model. I don\u0026rsquo;t think it is even worth mentioning what models I prefer. Today\u0026rsquo;s preferred LLM is replaced with the newest model after a couple months; trained on fresh data and probably with some new architecture.\nWherever I learn about the model, I look up models on models.dev. From there, I determine:\nDoes this model support tool calling? Is this model a reasoning model? What inputs are we looking at (e.g. text, image, audio, voice)? Cost?? üëÄüëÄüëÄüëÄ What is the context limit? (I\u0026rsquo;m looking for something with higher limits) What is the output limit? (Lets me plan on how else to use them if the limit is too low) What is the knowledge cut off date? After examining these, I develop a better idea on how to use the model.\nTemperature Settings # I think this is very important for creating your agents. OpenCode includes details about temperature, so consider reading it if you feel inclined.\nThis blurb here is what I find important.\n0.0-0.2: Very focused and deterministic responses, ideal for code analysis and planning 0.3-0.5: Balanced responses with some creativity, good for general development tasks 0.6-1.0: More creative and varied responses, useful for brainstorming and exploration I tend to keep the temperature lower, but that is how I use code assist.\nSystem Prompt Writing Tips # When writing system prompts for custom agents:\nBe specific - Define exact behaviors and output formats Include examples - Show the agent what good output looks like Set boundaries - Clarify what the agent should NOT do Define structure - Specify headers, formatting, and organization Include domain knowledge - Embed relevant conventions and standards Practical Examples From Experience # Example 1: Obsidian Note Writer Agent # An agent specialized for creating well-structured Obsidian notes with proper frontmatter, tags, and wiki-links.\nAgent Definition # This is my obsidian-writer agent. Because it has no mode specified, I can use it as both as the primary agent and as a subagent. I gave it access to tools, but then restricted the permissions to be more fine-grained. I will not deal with another breakout session.. ever again!\nIf you didn\u0026rsquo;t know, I like to use Obsidian (btw). I store my notes, code snippets, ideas, stories, system designs, reading list links, and pretty offload all my cognitive knowledge into vaults.\nI like to use this agent to either help add information or summarize raw links that I throw into a blank markdown. I also like using it to help tag quick paste dump notes I create. It also helps me create templates!\n--- name: obsidian-writer description: \u0026gt;- Use this agent when the user needs help creating or improving Obsidian notes, templates, or documentation. temperature: 0.0 tools: read: true edit: true write: true grep: true glob: true bash: false patch: true webfetch: true permissions: bash: \u0026#39;rm -rf *\u0026#39;: \u0026#39;deny\u0026#39; \u0026#39;sudo *\u0026#39;: \u0026#39;deny\u0026#39; read: \u0026#39;**/secret_dir/**\u0026#39;: \u0026#39;deny\u0026#39; edit: \u0026#39;**/secret_dir/**\u0026#39;: \u0026#39;deny\u0026#39; \u0026#39;**/*.env*\u0026#39;: \u0026#39;deny\u0026#39; \u0026#39;.git/**\u0026#39;: \u0026#39;deny\u0026#39; write: \u0026#39;**/secret_dir/**\u0026#39;: \u0026#39;deny\u0026#39; grep: \u0026#39;**/secret_dir/**\u0026#39;: \u0026#39;deny\u0026#39; glob: \u0026#39;**/secret_dir/**\u0026#39;: \u0026#39;deny\u0026#39; patch: \u0026#39;**/secret_dir/**\u0026#39;: \u0026#39;deny\u0026#39; --- You are an Obsidian Documentation Specialist. Your role is to help users create, refine, and organize Markdown documents within an Obsidian vault. You should: 1. Understand Obsidian conventions: frontmatter, internal links, tags, backlinks, templates, and vault structure. 2. Ask clarifying questions if the user‚Äôs request is ambiguous or incomplete. 3. Propose a clear structure: title, headings, metadata, content sections, and placeholders. 4. Generate clean Markdown with proper syntax, including links, tags, and YAML frontmatter when needed. 5. Suggest relevant tags, file paths, and linking strategies to maximize knowledge graph connectivity. 6. Offer reusable templates for common note types (meeting notes, project plans, literature reviews, daily journals, etc.). 7. Verify that the output follows Obsidian best practices and is ready to paste into the vault. 8. If the user requests a template, provide a skeleton with placeholders and instructions on how to fill it. 9. When uncertain, ask for more context before producing the final output. 10. Output should be plain Markdown text; do not wrap it in code fences unless the user explicitly asks for them. You should be proactive: if you notice missing metadata or potential link opportunities, suggest them. You should self‚Äëverify by checking that all links are syntactically correct and that the Markdown renders correctly in Obsidian. If you detect an error, correct it before responding. Example Usage # Prompt to invoke the agent:\nUse the task tool with subagent @obsidian-writer to create a note about Kubernetes ConfigMaps and Secrets. Webfetch the latest version docs. Include practical examples, best practices for secret management, and links to related Kubernetes concepts. Save it to /path/to/vault/DevOps/Kubernetes ConfigMaps and Secrets.md Expected output structure:\n--- tags: - kubernetes - devops - secrets-management - configmaps date: 2025-01-15 status: complete --- # Kubernetes ConfigMaps and Secrets Brief introduction to configuration management in Kubernetes... ## Overview [[Kubernetes]] provides two primary resources for managing configuration... ## ConfigMaps ### Creating ConfigMaps ... ## Secrets ### Types of Secrets ... ## Best Practices \u0026gt; **Security Note:** Never commit secrets to version control... ## Related Notes - [[Kubernetes Deployments]] - [[RBAC in Kubernetes]] - [[Helm Values and Secrets]] Example 2: The Go Pro # A subagent for working go projects. This is one of my specialist subagents that requires context instructions. When I used this (before skills got released), I found that the generic coding subagent kept using deprecated packages, and would keep WASTING MY CLOUD CREDITS on implementing whatever Go 1.15 code the model had been trained on\u0026hellip;\nAgent Definition # I have temperature set to 0.2 because I\u0026rsquo;m pretty explicit with some of the implementations, which are put as guidelines and read as context by the Agent I am talking to, and then sent to the golang-pro. If you don\u0026rsquo;t know Go, you may want to raise this temperature to see if that helps.\n--- name: golang-pro description: Master Go 1.24+ with modern patterns, advanced concurrency, performance optimization, and production-ready microservices. Expert in the latest Go ecosystem including generics, workspaces, and cutting-edge frameworks. Use PROACTIVELY for Go development, architecture design, or performance optimization. mode: subagent temperature: 0.2 tools: read: true edit: true write: true grep: true glob: true bash: false patch: true skill: true webfetch: true permissions: bash: \u0026#39;*\u0026#39;: \u0026#39;deny\u0026#39; edit: \u0026#39;**/*.env*\u0026#39;: \u0026#39;deny\u0026#39; \u0026#39;**/*.key\u0026#39;: \u0026#39;deny\u0026#39; \u0026#39;**/*.secret\u0026#39;: \u0026#39;deny\u0026#39; \u0026#39;node_modules/**\u0026#39;: \u0026#39;deny\u0026#39; \u0026#39;.git/**\u0026#39;: \u0026#39;deny\u0026#39; # Uncomment and replace model if you don\u0026#39;t want the default model being used #model: \u0026#39;\u0026lt;provider-id\u0026gt;/\u0026lt;model-id\u0026gt;\u0026#39; --- ## Purpose Expert Go developer mastering **Go 1.24+** features, modern development practices, and building **scalable, high-performance, and maintainable** applications. Deep knowledge of **concurrent programming, microservices architecture, and the modern Go ecosystem**, with a focus on **idiomatic, secure, and observable** systems. ## Capabilities ### **Modern Go Language Features (1.24+)** - **Go 1.24+ features**: Range over functions, for-loop improvements, and compiler optimizations - **Generics (type parameters)**: Type-safe, reusable code with advanced use cases - **Go workspaces**: Multi-module development and dependency management - **Context package**: Cancellation, timeouts, and structured concurrency - **Embed directive**: Embedding files, templates, and assets into binaries - **Error handling**: Wrapping, `errors.Is`, `errors.As`, and `slog` for structured error logging - **Memory management**: Garbage collector tuning, arena allocation (Go 1.24+), and memory profiling - **Reflection and unsafe**: Advanced use cases and performance-critical optimizations ### **Concurrency \u0026amp; Parallelism Mastery** - **Goroutine lifecycle**: Best practices for spawning, managing, and terminating goroutines - **Channel patterns**: Fan-in, fan-out, worker pools, pipelines, and backpressure handling - **Select statements**: Non-blocking operations and advanced synchronization - **Context cancellation**: Graceful shutdown, request-scoped values, and propagation - **Sync package**: Mutexes, `sync.WaitGroup`, `sync.Once`, and `sync.Pool` for object reuse - **Lock-free programming**: Atomic operations and memory model compliance - **Race detection**: Static analysis and runtime race detection tools ### **Performance \u0026amp; Optimization** - **Profiling**: CPU, memory, and block profiling with `pprof` and `go tool trace` - **Benchmarking**: Data-driven optimization and performance regression detection - **Memory optimization**: Leak detection, heap analysis, and garbage collection tuning - **I/O-bound optimization**: Connection pooling, batching, and async I/O - **CPU-bound optimization**: Parallelism, SIMD, and assembly integration - **Caching strategies**: In-memory caches, LRU, and distributed caching ### **Modern Go Architecture Patterns** - **Clean architecture**: Hexagonal architecture, ports/adapters, and domain-driven design - **Microservices**: Service decomposition, gRPC, REST, and event-driven communication - **Event sourcing/CQRS**: Event stores, projections, and snapshot strategies - **Dependency injection**: `wire` framework and manual DI for testability - **Plugin architectures**: Dynamic loading and extensibility ### **Web Services \u0026amp; APIs** - **HTTP servers**: `net/http`, `Fiber`, `Echo`, and middleware patterns - **gRPC**: Protocol buffers, streaming, interceptors, and load balancing - **GraphQL**: Schema design, resolvers, and performance optimization - **WebSockets**: Real-time communication and connection management - **Authentication**: JWT, OAuth2, and OpenID Connect - **Rate limiting**: Token bucket, leaky bucket, and circuit breakers ### **Database \u0026amp; Persistence** - **SQL databases**: `database/sql`, `GORM`, connection pooling, and transaction management - **NoSQL**: MongoDB, Redis, DynamoDB, and optimized query patterns - **Migrations**: Schema versioning and zero-downtime deployments - **Testing**: Mock databases, test containers, and integration testing ### **Testing \u0026amp; Quality Assurance** - **Table-driven tests**: Comprehensive test coverage and edge-case handling - **Benchmarking**: Performance testing and regression detection - **Integration testing**: Test containers and environment isolation - **Mocking**: `gomock`, `testify/mock`, and interface-based mocking - **Property-based testing**: Hypothesis testing with `gopter` ### **DevOps \u0026amp; Production Deployment** - **Containerization**: Multi-stage Docker builds and distroless images - **Kubernetes**: Deployments, services, and observability - **Observability**: OpenTelemetry, Prometheus, and structured logging with `slog` - **CI/CD**: Go modules, versioning, and automated pipelines - **Monitoring**: Metrics, tracing, and alerting for production systems ### **Modern Go Tooling** - **Go modules**: Dependency management and versioning - **Go workspaces**: Multi-module projects and local development - **Static analysis**: `golangci-lint`, `staticcheck`, and custom linters - **Code generation**: `go generate`, `stringer`, and protobuf compilation - **Hot reloading**: `Air` and live-reload workflows - **Task automation**: `Makefile`, `Just`, and custom scripts ### **Security \u0026amp; Best Practices** - **Secure coding**: Input validation, sanitization, and vulnerability prevention - **Cryptography**: TLS, encryption, and key management - **Secret management**: Vault, environment variables, and secure storage - **Compliance**: Audit trails, logging, and GDPR/CCPA readiness ## Behavioral Traits - **Idiomatic Go**: Follows _Effective Go_ and community best practices - **Simplicity**: Prioritizes readability and maintainability over cleverness - **Concurrency safety**: Race-free design and proper synchronization - **Explicit error handling**: No `panic/recover` in business logic - **Testing culture**: High coverage, table-driven tests, and property-based checks - **Performance awareness**: Measures before optimizing, avoids premature optimization - **Documentation**: Clear code, comments, and architecture decisions - **Collaboration**: Team-friendly code reviews and pair programming ## Knowledge Base - **Go 1.24+**: Language features, compiler improvements, and runtime optimizations - **Concurrency**: Patterns, pitfalls, and synchronization primitives - **Microservices**: Cloud-native design, service mesh, and resilience - **Performance**: Profiling, benchmarking, and optimization techniques - **Observability**: Metrics, logs, and traces for production systems - **Security**: OWASP Top 10, cryptography, and secure defaults - **DevOps**: CI/CD, Kubernetes, and infrastructure as code ## Response Approach 1. **Analyze requirements** for Go-specific solutions and trade-offs. 2. **Design concurrent systems** with proper synchronization and cancellation. 3. **Implement clean interfaces** and composition-based architecture. 4. **Include structured error handling** with context and wrapping. 5. **Write extensive tests** (unit, integration, benchmark, and property-based). 6. **Optimize for performance** using profiling and data-driven decisions. 7. **Document deployment** strategies for scalability and observability. 8. **Recommend modern tooling** (e.g., `slog`, `otel`, `goreleaser`). ## Example Interactions - _\u0026#34;Design a high-throughput worker pool with graceful shutdown and backpressure.\u0026#34;_ - _\u0026#34;Optimize this Go service for lower latency using arena allocation (Go 1.24+).\u0026#34;_ - _\u0026#34;Implement a gRPC service with OpenTelemetry tracing and rate limiting.\u0026#34;_ - _\u0026#34;Debug a memory leak in a long-running Go application using `pprof`.\u0026#34;_ - _\u0026#34;Set up a Go project with dependency injection, testing, and CI/CD.\u0026#34;_ - _\u0026#34;Secure a Go API against OWASP Top 10 vulnerabilities.\u0026#34;_ Now just remember to update this whenever trying to enforce the latest Go features. Or consider fine-tuning a model purely on Go training data. Wouldn\u0026rsquo;t that be a sight to see\u0026hellip;\nFrom here on out, I will not be including expected outputs. Model and temperature play into all of these examples, so it\u0026rsquo;s not worth putting an output that is not reproducible.\nExample Usage # Prompt to invoke the agent:\nUse the task tool with subagent @golang-pro to create a feature for rate limiting in my API using the token bucket algorithm. Example 3: Unit Test Writer Agent # A subagent that generates comprehensive unit tests for code, supporting multiple languages. This subagent is super useful to catch issues and errors in generated code, AND in ensuring that your new requested feature doesn\u0026rsquo;t break the whole app. It is like patting your pockets to make sure you have your wallet, keys, and phone before leaving the house.\nAgent Definition # If you look tester.md, you\u0026rsquo;ll notice that the instructions are very general. This is intended. The tester subagent has access to skills. Each programming language that I use, I create a skill to assist it with unit tests and examples (e.g. python-unit-tests, go-unit-tests, typescript-unit-tests, etc). This is great because now I do not need to make a subagent for every single language, or depend on a model having the training data of the language (soon Zig\u0026hellip; soon..), or have to keep performing webfetch calls to pull relevant information.\nüìù Note I have not included my skills in this blog. They are still being tested and refined. I may post some examples if I make a blog post about them. ~/.config/opencode/agent/subagents/code/tester.md\n--- name: tester description: Test authoring and TDD agent mode: subagent temperature: 0.1 tools: read: true grep: true glob: true edit: true write: true bash: true skill: true permissions: bash: \u0026#39;rm -rf *\u0026#39;: \u0026#39;ask\u0026#39; \u0026#39;sudo *\u0026#39;: \u0026#39;deny\u0026#39; edit: \u0026#39;**/*.env*\u0026#39;: \u0026#39;deny\u0026#39; \u0026#39;**/*.key\u0026#39;: \u0026#39;deny\u0026#39; \u0026#39;**/*.secret\u0026#39;: \u0026#39;deny\u0026#39; # Uncomment and replace model if you don\u0026#39;t want the default model being used #model: \u0026#39;\u0026lt;provider-id\u0026gt;/\u0026lt;model-id\u0026gt;\u0026#39; --- # Write Test Agent Responsibilities: - The objective, break it down into clear, testable behaviors. - The objective behavior, create two tests: 1. A positive test to verify correct functionality (success case). 2. A negative test to verify failure or improper input is handled (failure/breakage case). - The test, include a comment explaining how it meets the objective. - Use the Arrange-Act-Assert pattern for all tests. - Mock all external dependencies and API calls. - Ensure tests cover acceptance criteria, edge cases, and error handling. - Author and run tests for the code before handoff. Workflow: 1. Propose a test plan: - The objective, state the behaviors to be tested. - The objective behavior, describe the positive and negative test cases, including expected results and how they relate to the objective. - Request approval before implementation. 2. Implement the approved tests, run the relevant subset, and report succinct pass/fail results. Rules: - The objective must have at least one positive and one negative test, each with a clear comment linking it to the objective. - Favor deterministic tests; avoid network and time flakiness. - Run related tests after edits and fix lints before handoff. ## Quick Reference **Golden Rule**: If you can\u0026#39;t test it easily, refactor it **AAA Pattern**: Arrange ‚Üí Act ‚Üí Assert **Test** (‚úÖ DO): - Happy path, edge cases, error cases - Business logic, public APIs **Don\u0026#39;t Test** (‚ùå DON\u0026#39;T): - Third-party libraries, framework internals - Simple getters/setters, private details **Coverage**: Critical (100%), High (90%+), Medium (80%+) Example Usage - Go # Prompt:\nUse the task tool with subagent @tester to generate comprehensive unit tests for the user service in internal/services/user.go. Include tests for all public methods, error cases, and use table-driven tests. Save to internal/services/user_test.go Agent Tool Calling:\nAdd the following to your project AGENTS.md:\nWhen adding or editing code, use @tester to generate comprehensive unit tests. Example Usage - Python # Prompt:\nUse the task tool with subagent @tester to generate pytest tests for the data processor in src/data_processor.py. Include fixtures, parametrized tests, and mock external API calls. Agent Tool Calling:\nAdd the following to your project AGENTS.md:\nWhen adding or editing code, use @tester to generate comprehensive unit tests. Example 4: Documentation Generator Agent # A subagent for generating code documentation, README files, and API docs.\nI used to handcraft well thought out documents for codebases, for humans. But then I learned that not all engineers enjoy reading technical documents, so I started drawing pictures. Now, I have subagents generate documentation for you, dear AI reader.\nAgent Definition # The following is an example of my global doc-generator subagent. It is super basic, but that\u0026rsquo;s the point. I just need a model with a big enough context window to know how to document. I also made it a subagent because I want primary agents to feed it context.\nI find that a temperature of 0.1 or 0.2 works best for me.\n~/.config/opencode/agent/subagents/core/doc-generator.md\n--- name: doc-generator description: Documentation authoring agent mode: subagent temperature: 0.2 tools: read: true grep: true glob: true edit: true write: true bash: false permissions: bash: \u0026#39;*\u0026#39;: \u0026#39;deny\u0026#39; edit: \u0026#39;plan/**/*.md\u0026#39;: \u0026#39;allow\u0026#39; \u0026#39;**/*.md\u0026#39;: \u0026#39;allow\u0026#39; \u0026#39;**/*.env*\u0026#39;: \u0026#39;deny\u0026#39; \u0026#39;**/*.key\u0026#39;: \u0026#39;deny\u0026#39; \u0026#39;**/*.secret\u0026#39;: \u0026#39;deny\u0026#39; # Uncomment and replace model if you don\u0026#39;t want the default model being used #model: \u0026#39;\u0026lt;provider-id\u0026gt;/\u0026lt;model-id\u0026gt;\u0026#39; --- # Documentation Agent Responsibilities: - Create/update README, specs, and developer docs - Maintain consistency with naming conventions and architecture decisions - Generate concise, high-signal docs; prefer examples and short lists Workflow: 1. Propose what documentation will be added/updated and ask for approval. 2. Apply edits and summarize changes. Constraints: - No bash. Only edit markdown and docs. Example Usage # Direct Prompt:\nUse the task tool with subagent @doc-generator to create a comprehensive README.md for the CLI tool in this project. Include installation instructions, usage examples for all commands, configuration options, and a quick reference table. Agent Tool Calling:\nAdd the following to your project AGENTS.md:\nWhenever you make critical changes to the repository, call the @doc-generator to either update the README.md or the relevant existing doc, under `docs/`. If it does not exist, ask the user if they want you to create one. Give the subagent all the relevant information needed to document the subject effectively. Best Practices # When to Use Agents vs Direct Tool Calls # Here are some scenarios and recommendations on when you consider instructing an Agent to call another Agent, or if you should just use the primary Agent.\nScenario Recommendation Single file read/write Prompt with direct tool call Multi-file refactoring Agent call Subagent(s) Quick search Neither; use fzf or grep/ripgrep. You\u0026rsquo;re human lol Comprehensive codebase analysis Agent (explore type with large context window) Simple question Simple prompt Complex feature implementation Agent call Subagent(s) Running a single command Let Agent and/or Subagents tool call Writing Effective Agent Prompts # Be Specific About Output Bad: \u0026#34;Write some tests\u0026#34; Good: \u0026#34;Write pytest unit tests for the UserService class, including tests for authentication, authorization, and error handling. Use fixtures for database setup and mock external APIs.\u0026#34; Provide Context Bad: \u0026#34;Where tests\u0026#34; Good: \u0026#34;The project uses Go 1.24, follows clean architecture, and uses testify for assertions. Tests should be in the same package with _test.go suffix.\u0026#34; Specify File Locations Bad: \u0026#34;You know me. Do that thing in my mind palace\u0026#34; Good: \u0026#34;Read the source from internal/services/user.go and save tests to internal/services/user_test.go\u0026#34; Include Constraints Bad: \u0026#34;Tests now\u0026#34; Good: \u0026#34;Do not modify existing tests. Only add new test cases for the recently added ValidateEmail method.\u0026#34; Misc Tips # I found that it generally takes a couple of additional prompts of, \u0026ldquo;Are you sure you\u0026rsquo;re finished? I think you should call the @golang-pro and code review yourself.\u0026rdquo; or \u0026ldquo;I\u0026rsquo;m linting the code manually and I\u0026rsquo;m seeing a lot of ignored return. Have the @golang-pro run a lint and task a code review.\u0026rdquo;\nAssume that the Agent did things 60-80% correctly.. just like that coworker who knows just enough to be dangerous, or the one who submits a vibe coded PR full of one-shot attempts and expects you to prompt fixes. In my setup, I like to review the changes because it tells me where I can be more clear with instructions, where I can provide examples, and if there are any skills I can build to improve the process. From there, agents and subagents can use my refinements to enhance or fix the code generated by the previous agents.\nSummary # OpenCode\u0026rsquo;s agent system provides a powerful way to delegate complex tasks to specialized subagents. Key takeaways:\nUse built-in subagents (general, explore) for common tasks Create custom subagents for domain-specific work Write detailed system prompts with examples Combine agents for complex workflows Store agent configurations in opencode.json üìù Note This blog was drafted using an Agent with context from Obsidian notes. It took the local LLM a little under 20 mins to create a draft. I also used it for doing spellchecking and basic grammar analysis, assuring it, \u0026ldquo;No, don\u0026rsquo;t correct that. That is intended.\u0026rdquo; I have spent HOURS artisian handcraft editing, adding supplimentary text, creating memes, pulling snippets, and inserting content into finishing the blog. Do with that what you will. References # OpenCode docs OpenCode neovim My Neovim Config Models.Dev ","date":"Jan 2, 2026","permalink":"https://blog.mikesahari.com/posts/coding-with-opencode/","tags":["go","ai","opencode","neovim","documentation","agents"],"title":"Coding With Opencode"},{"content":"Hello, Gophers! Welcome to Part 2 of Data Structures and Algorithms. If you\u0026rsquo;ve missed Part 1 on Big O, you can read it here.\nData structures form the foundation of computer science‚Äîthey\u0026rsquo;re how we organize, store, and manipulate information in ways that mirror how we think and solve problems. Far beyond mere implementation details, these abstractions shape how we conceptualize computational challenges. Whether you\u0026rsquo;re building a search engine indexing billions of webpages, an operating system managing memory resources, or a mobile app tracking user interactions, choosing the right data structure can mean the difference between a solution that scales gracefully and one that becomes that legacy tech debt app that engineers share stories about, blaming the original designer (you know who you are).\nAcross every programming language and problem domain, the core principles of data organization remain the same: we seek the optimal balance between time efficiency, memory usage, and conceptual clarity. Master these fundamentals, and you gain the power to solve problems not just in Go, but in any computational context.\nLet\u0026rsquo;s explore the essential data structures (in Go), to understand their inner workings, and learn exactly when to use each one to enhance your code. Please note that code examples are meant for readability and not the most optimized leetcode examples.\nüí° Tip This guide assumes you\u0026rsquo;re familiar with Go basics and looking to level up your data structure knowledge. If you\u0026rsquo;re new to Go, check out the official Go tour first! In addition, check out my blogs on Go Fundamentals. Understanding Big O: The Language of Performance # Before we can dive into specific data structures, we need to review what we know of Big O.\nAt its core, Big O measures how operation count scales as data size increases:\nflowchart LR A[\u0026#34;O(1): Constant\u0026#34;] --\u0026gt; B[\u0026#34;O(log n): Logarithmic\u0026#34;] B --\u0026gt; C[\u0026#34;O(n): Linear\u0026#34;] C --\u0026gt; D[\u0026#34;O(n log n): Linearithmic\u0026#34;] D --\u0026gt; E[\u0026#34;O(n¬≤): Quadratic\u0026#34;] E --\u0026gt; F[\u0026#34;O(2^n): Exponential\u0026#34;] style A fill:#4CAF50,stroke:#388E3C,color:#E8F5E9 style B fill:#2196F3,stroke:#1976D2,color:#E3F2FD style C fill:#FFC107,stroke:#FFA000,color:#FFF8E1 style D fill:#FF9800,stroke:#F57C00,color:#FFF3E0 style E fill:#F44336,stroke:#D32F2F,color:#FFEBEE style F fill:#9C27B0,stroke:#7B1FA2,color:#F3E5F5 Here\u0026rsquo;s what these notations mean in practical terms:\nNotation Name Technical Impact O(1) Constant Operation count doesn\u0026rsquo;t increase with data size O(log n) Logarithmic Operation count increases logarithmically (very slowly) O(n) Linear Operation count increases proportionally to data size O(n log n) Linearithmic Common in efficient sorting algorithms O(n¬≤) Quadratic Operation count increases with the square of data size O(2^n) Exponential Operation count doubles with each new element Now that we have our performance vocabulary sorted out, let\u0026rsquo;s see how these concepts apply to real Go data structures!\nArrays and Slices: The Foundation of Sequential Data # Our first stop in the Go data structure tour is the humble array and its flexible cousin, the slice. These are the workhorses of Go programming, and understanding their little nuances are essential for writing performant code.\nIn Go, arrays and slices represent contiguous memory blocks that enable extremely fast indexed access. While arrays have fixed sizes determined at compile time, slices provide dynamic sizing with three key components: a pointer to the underlying array, a length, and a capacity.\nHere\u0026rsquo;s how to declare them:\n// Fixed-size array (size is part of the type) fixed := [5]int{1, 2, 3, 4, 5} // Dynamic slices with make dynamicWithCapacity := make([]int, 0, 5) // Length 0, capacity 5 dynamicWithLength := make([]int, 5) // Length 5, capacity 5 The three-part structure of slices (pointer, length, capacity) looks like this:\ngraph TD A[Slice Header] --\u0026gt; B[Pointer to Array] A --\u0026gt; C[Length] A --\u0026gt; D[Capacity] B --\u0026gt; E[Underlying Array] style A fill:#1a237e,stroke:#3949ab,color:#e8eaf6 style B fill:#004d40,stroke:#00796b,color:#e0f2f1 style C fill:#004d40,stroke:#00796b,color:#e0f2f1 style D fill:#004d40,stroke:#00796b,color:#e0f2f1 style E fill:#311b92,stroke:#5e35b1,color:#ede7f6 Technical Performance Analysis # Here\u0026rsquo;s a detailed breakdown of array/slice operation complexity:\nOperation Time Complexity Technical Explanation Access by index O(1) Direct memory address calculation via base address + (index * element_size) Search (unsorted) O(n) Requires sequential examination of each element until target is found Append O(1) amortized Fast when capacity is available; requires O(n) reallocation when capacity is exceeded Insert at middle O(n) Requires shifting all elements after insertion point Delete O(n) Requires shifting all elements after deletion point Practical Examples # Let\u0026rsquo;s explore two practical examples that demonstrate the most common slice operations:\nExample 1: Dynamic Collection with Append # Here\u0026rsquo;s a simple score tracker that uses slice append operations:\n// ScoreTracker keeps track of a series of scores with unlimited capacity type ScoreTracker struct { scores []int } // NewScoreTracker creates a new tracker with initial capacity func NewScoreTracker(initialCapacity int) *ScoreTracker { return \u0026amp;ScoreTracker{ scores: make([]int, 0, initialCapacity), } } // AddScore appends a new score to the collection - O(1) amortized func (st *ScoreTracker) AddScore(score int) { st.scores = append(st.scores, score) } // AverageScore calculates the average of all scores - O(n) func (st *ScoreTracker) AverageScore() float64 { if len(st.scores) == 0 { return 0 } sum := 0 for _, score := range st.scores { sum += score } return float64(sum) / float64(len(st.scores)) } // Example usage: func main() { tracker := NewScoreTracker(10) // Start with capacity for 10 scores // Add some scores (using O(1) amortized append operations) tracker.AddScore(85) tracker.AddScore(92) tracker.AddScore(78) tracker.AddScore(95) fmt.Printf(\u0026#34;Average score: %.2f\\n\u0026#34;, tracker.AverageScore()) } This example demonstrates the efficient append operation:\n// O(1) amortized time complexity func (st *ScoreTracker) AddScore(score int) { st.scores = append(st.scores, score) } Example 2: Fixed-Size Collection with Insertions # For contrast, here\u0026rsquo;s an example that uses a fixed-size array and requires element shifting:\n// TopScores maintains a fixed-size sorted list of the highest scores type TopScores struct { scores [5]int // Fixed-size array of top 5 scores (highest first) } // Initialize with zeros func NewTopScores() *TopScores { return \u0026amp;TopScores{} } // TryAddScore adds a score if it\u0026#39;s high enough to make the top 5 - O(n) func (ts *TopScores) TryAddScore(newScore int) bool { // Find position where this score belongs (if any) pos := -1 for i, score := range ts.scores { if newScore \u0026gt; score { pos = i break } } // If not in top 5, we\u0026#39;re done if pos == -1 { return false } // Shift lower scores down (this is an O(n) operation) for i := len(ts.scores) - 1; i \u0026gt; pos; i-- { ts.scores[i] = ts.scores[i-1] } // Insert the new score ts.scores[pos] = newScore return true } // Example usage: func main() { topScores := NewTopScores() // Add some scores (each requires O(n) operations when shifting is needed) topScores.TryAddScore(85) topScores.TryAddScore(92) topScores.TryAddScore(78) topScores.TryAddScore(95) topScores.TryAddScore(88) // Try adding a score too low to make the cut wasAdded := topScores.TryAddScore(70) if !wasAdded { fmt.Println(\u0026#34;Score 70 didn\u0026#39;t make the top 5\u0026#34;) } fmt.Println(\u0026#34;Top scores:\u0026#34;, topScores.scores) } üìå Important The amortized O(1) complexity of append() comes from the reallocation strategy. When capacity is exceeded, Go allocates a new underlying array with approximately double the capacity. This O(n) operation happens infrequently enough that when averaged across many append operations, the effective cost approaches O(1) per operation. Optimal Usage Scenarios # Arrays and slices are ideal when:\nRandom access by index is the primary operation Data is processed sequentially from start to finish Cache locality provides performance benefits Insertion and deletion operations at the middle are infrequent But what if you need frequent insertions and deletions at arbitrary positions? That\u0026rsquo;s where our next data structure comes into play..\nLinked Lists: The Chain of Nodes # So arrays and slices are great when you need fast random access, but they fall apart when you\u0026rsquo;re constantly inserting and removing elements in the middle. Enter linked lists - the data structure that laughs in the face of insertion complexity (hue hue hue).\nLinked lists represent a fundamental departure from array-based structures. Instead of contiguous memory, linked lists consist of individual nodes where each node contains both data and a reference to the next node in the sequence.\ntype Node struct { Value int Next *Node } type LinkedList struct { Head *Node Length int } A linked list\u0026rsquo;s structural organization looks like this:\ngraph LR Head --\u0026gt; A[\u0026#34;Node (data + next)\u0026#34;] A --\u0026gt; B[\u0026#34;Node (data + next)\u0026#34;] B --\u0026gt; C[\u0026#34;Node (data + next)\u0026#34;] C --\u0026gt; D[\u0026#34;Node (data + next)\u0026#34;] D --\u0026gt; Tail style Head fill:#b71c1c,stroke:#e53935,color:#ffebee style A fill:#004d40,stroke:#00796b,color:#e0f2f1 style B fill:#004d40,stroke:#00796b,color:#e0f2f1 style C fill:#004d40,stroke:#00796b,color:#e0f2f1 style D fill:#004d40,stroke:#00796b,color:#e0f2f1 style Tail fill:#880e4f,stroke:#d81b60,color:#fce4ec Technical Performance Analysis # Here\u0026rsquo;s a detailed breakdown of linked list operation complexity:\nOperation Time Complexity Technical Explanation Access by index O(n) Requires traversing the list from head to desired position Search O(n) Requires examining each node sequentially Insert at beginning O(1) Only requires updating the head pointer and one node Insert at end O(n) or O(1) O(n) with only head pointer (requires traversal), O(1) with tail pointer Delete O(n) Requires finding the node and updating pointers Practical Example: Linked List Operations # Let\u0026rsquo;s implement a basic linked list with its core operations:\n// Create a new linked list func NewLinkedList() *LinkedList { return \u0026amp;LinkedList{ Head: nil, Length: 0, } } // Insert at beginning - O(1) time complexity func (l *LinkedList) InsertAtBeginning(val int) { newNode := \u0026amp;Node{ Value: val, Next: l.Head, } l.Head = newNode l.Length++ } // Insert at end - O(n) time complexity without tail pointer func (l *LinkedList) InsertAtEnd(val int) { newNode := \u0026amp;Node{ Value: val, Next: nil, } // If list is empty, new node becomes the head if l.Head == nil { l.Head = newNode } else { // Traverse to the last node current := l.Head for current.Next != nil { current = current.Next } // Link the last node to the new node current.Next = newNode } l.Length++ } // Search for a value - O(n) time complexity func (l *LinkedList) Search(val int) bool { current := l.Head for current != nil { if current.Value == val { return true } current = current.Next } return false } // Delete a node with given value - O(n) time complexity func (l *LinkedList) Delete(val int) bool { // If list is empty if l.Head == nil { return false } // If head is the target if l.Head.Value == val { l.Head = l.Head.Next l.Length-- return true } // Search for the value in the rest of the list current := l.Head for current.Next != nil \u0026amp;\u0026amp; current.Next.Value != val { current = current.Next } // If value was found if current.Next != nil { current.Next = current.Next.Next l.Length-- return true } return false } // Example usage func main() { list := NewLinkedList() // Add some values list.InsertAtBeginning(10) // List: 10 list.InsertAtBeginning(20) // List: 20 -\u0026gt; 10 list.InsertAtEnd(30) // List: 20 -\u0026gt; 10 -\u0026gt; 30 // Search for values fmt.Println(\u0026#34;Contains 20:\u0026#34;, list.Search(20)) // true fmt.Println(\u0026#34;Contains 25:\u0026#34;, list.Search(25)) // false // Delete a value list.Delete(10) // List: 20 -\u0026gt; 30 // Print the list current := list.Head for current != nil { fmt.Printf(\u0026#34;%d -\u0026gt; \u0026#34;, current.Value) current = current.Next } fmt.Println(\u0026#34;nil\u0026#34;) } Let\u0026rsquo;s examine the insert at beginning operation, which showcases the linked list\u0026rsquo;s strength:\n// Insert at beginning - O(1) time complexity func (l *LinkedList) InsertAtBeginning(val int) { newNode := \u0026amp;Node{ Value: val, Next: l.Head, // Point to current head } l.Head = newNode // Update head to the new node l.Length++ } This operation is constant time (O(1)) because it requires only a fixed number of steps regardless of the list size:\nCreate a new node Point the new node\u0026rsquo;s Next to the current head Update the head pointer to the new node Increment the length counter Real-world application: Transaction History # To see how linked lists can be useful in practical applications, let\u0026rsquo;s look at a transaction history implementation:\n// Transaction represents a single financial transaction type Transaction struct { ID string Amount float64 Description string Timestamp time.Time Next *Transaction // Pointer to the next transaction } // TransactionHistory manages a linked list of transactions type TransactionHistory struct { Head *Transaction Size int } // AddTransaction adds a new transaction to the beginning (most recent first) - O(1) func (th *TransactionHistory) AddTransaction(amount float64, desc string) string { // Generate a transaction ID id := generateID() // Create a new transaction newTransaction := \u0026amp;Transaction{ ID: id, Amount: amount, Description: desc, Timestamp: time.Now(), Next: th.Head, // Point to current head (same pattern as our generic linked list) } // Update the head th.Head = newTransaction th.Size++ return id } // Helper function (in a real implementation, this would be more sophisticated) func generateID() string { return fmt.Sprintf(\u0026#34;TX-%d\u0026#34;, time.Now().UnixNano()) } Notice that the AddTransaction method follows the exact same pattern as our InsertAtBeginning method from the generic linked list - it\u0026rsquo;s an O(1) operation that makes linked lists particularly well-suited for this kind of application.\nTechnical Implementation Considerations # When implementing linked lists in Go, consider these technical aspects:\nMemory Management: Each node requires additional memory for pointers (8 bytes per pointer on 64-bit systems) Cache Locality: Nodes can be scattered throughout memory, reducing cache efficiency Tail Pointers: Adding a tail pointer transforms end insertions from O(n) to O(1) Doubly-Linked Variants: Adding previous pointers enables backwards traversal at the cost of additional memory üí° Tip For specialized linked list needs, consider using the container/list package from the standard library, which provides a doubly-linked list implementation with constant-time insertions and deletions. But wait, what if we need fast lookups by a specific identifier rather than by position? That\u0026rsquo;s when we need to reach for a different tool.\nHash Tables (Maps in Go): Key-Value Access Masters # When you need lightning-fast lookups by key, hash tables are your best friend. Forget about traversing through elements one by one - hash tables use mathematical magic to zoom directly to the value you need.\nHash tables provide exceptional key-value lookup performance through a clever mathematical trick: they convert keys into array indices using a hash function. Go implements hash tables as the built-in map type.\n// Creating an empty map ages := make(map[string]int) // (Alternatively) Creating with initial values ages := map[string]int{ \u0026#34;Argo\u0026#34;: 32, \u0026#34;Bumpkin\u0026#34;: 28, \u0026#34;Cassandra\u0026#34;: 45, } Hash tables achieve their speed through a clever combination of arrays and hash functions:\nA hash function converts your key into a number (the hash code) This hash code is used to determine the index in an underlying array (the bucket) The key-value pair is stored at that location When looking up a value, the same hash function is applied to find the bucket graph TD A[\u0026#34;Key (e.g., \u0026#39;Argo\u0026#39;)\u0026#34;] --\u0026gt; B[\u0026#34;Hash Function\u0026#34;] B --\u0026gt; C[\u0026#34;Hash Code (e.g., 5234)\u0026#34;] C --\u0026gt; D[\u0026#34;Bucket Index (e.g., 42)\u0026#34;] D --\u0026gt; E[\u0026#34;Bucket in Underlying Array\u0026#34;] E --\u0026gt; F[\u0026#34;Key-Value Pair (\u0026#39;Argo\u0026#39;: 32)\u0026#34;] style A fill:#1a237e,stroke:#3949ab,color:#e8eaf6 style B fill:#b71c1c,stroke:#e53935,color:#ffebee style C fill:#004d40,stroke:#00796b,color:#e0f2f1 style D fill:#004d40,stroke:#00796b,color:#e0f2f1 style E fill:#311b92,stroke:#5e35b1,color:#ede7f6 style F fill:#880e4f,stroke:#d81b60,color:#fce4ec Technical Performance Analysis # Operation Average Time Worst Case Technical Explanation Access O(1) O(n) Direct bucket access via hash; worst case occurs with many collisions Insert O(1) O(n) Direct bucket placement; worst case requires traversing a collision chain Delete O(1) O(n) Direct bucket access; worst case requires traversing a collision chain Practical Example: User Age Lookup # Let\u0026rsquo;s build a simple system to store and retrieve user ages:\n// Creating a map to store user ages func NewUserAgeSystem() map[string]int { return make(map[string]int) } // Add or update a user\u0026#39;s age func AddUser(users map[string]int, name string, age int) { users[name] = age } // Get a user\u0026#39;s age with error handling func GetUserAge(users map[string]int, name string) (int, bool) { age, exists := users[name] return age, exists } // Example usage: func main() { userAges := NewUserAgeSystem() // Add some users AddUser(userAges, \u0026#34;Argo\u0026#34;, 32) AddUser(userAges, \u0026#34;Bumpkin\u0026#34;, 28) AddUser(userAges, \u0026#34;Cassandra\u0026#34;, 45) // Retrieve and display Argo\u0026#39;s age if age, exists := GetUserAge(userAges, \u0026#34;Argo\u0026#34;); exists { fmt.Printf(\u0026#34;Argo is %d years old\\n\u0026#34;, age) } else { fmt.Println(\u0026#34;Argo not found in the system\u0026#34;) } // Try to get a non-existent user if age, exists := GetUserAge(userAges, \u0026#34;Mahindra\u0026#34;); exists { fmt.Printf(\u0026#34;Mahindra is %d years old\\n\u0026#34;, age) } else { fmt.Println(\u0026#34;Mahindra not found in the system\u0026#34;) } // Update Bumpkin\u0026#39;s age AddUser(userAges, \u0026#34;Bumpkin\u0026#34;, 29) // Bumpkin aged because of a birthday // Remove Cassandra from the system delete(userAges, \u0026#34;Cassandra\u0026#34;) } This example directly matches the basic map operations:\n// Insert or update - O(1) average case userAges[\u0026#34;Argo\u0026#34;] = 32 // Access with existence check - O(1) average case age, exists := userAges[\u0026#34;Bumpkin\u0026#34;] // Delete - O(1) average case delete(userAges, \u0026#34;Cassandra\u0026#34;) Technical Implementation Details # Go\u0026rsquo;s map implementation includes several sophisticated features:\nDynamic Resizing: Maps automatically grow when they become too full, keeping operations fast Good Hash Distribution: Go uses high-quality hash functions to minimize collisions Memory Efficiency: The implementation balances memory usage with performance Zero Values: Accessing a non-existent key returns the zero value for that type üìù Note Maps in Go are unordered collections. When you iterate through a map using a for-range loop, the elements appear in a random order. This randomization is deliberate to prevent developers from relying on any specific order. If you need ordered elements, you\u0026rsquo;ll need to pair your map with a separate slice to track insertion order. Maps excel at key-based lookups, but what if we need both fast lookups and a specific ordering? That\u0026rsquo;s where our next data structure comes in.\nBinary Trees: Hierarchical Ordered Data # Have you ever needed to both lookup data quickly AND maintain a specific order? Enter binary trees - the elegant data structure that lets you have your cake and eat it too (at least most of the time).\nBinary trees organize data in a hierarchical structure where each node has at most two children. Binary Search Trees (BSTs) enforce an ordering: values in left subtrees are smaller than the node\u0026rsquo;s value, while values in right subtrees are larger.\ntype TreeNode struct { Value int Left *TreeNode Right *TreeNode } type BinarySearchTree struct { Root *TreeNode } The hierarchical structure of a balanced binary search tree looks like this:\ngraph TD A[8] --\u0026gt; B[3] A --\u0026gt; C[10] B --\u0026gt; D[1] B --\u0026gt; E[6] C --\u0026gt; F[9] C --\u0026gt; G[14] style A fill:#1a237e,stroke:#3949ab,color:#e8eaf6 style B fill:#004d40,stroke:#00796b,color:#e0f2f1 style C fill:#004d40,stroke:#00796b,color:#e0f2f1 style D fill:#311b92,stroke:#5e35b1,color:#ede7f6 style E fill:#311b92,stroke:#5e35b1,color:#ede7f6 style F fill:#311b92,stroke:#5e35b1,color:#ede7f6 style G fill:#311b92,stroke:#5e35b1,color:#ede7f6 Technical Performance Analysis # The performance characteristics of binary search trees depend critically on their balance:\nOperation Balanced Tree Unbalanced Tree Technical Explanation Search O(log n) O(n) Eliminates half the remaining nodes at each step when balanced Insert O(log n) O(n) Requires finding the correct leaf position Delete O(log n) O(n) Requires finding node and potentially restructuring Basic BST Implementation # Let\u0026rsquo;s implement a basic Binary Search Tree with core operations:\n// Create a new BST func NewBinarySearchTree() *BinarySearchTree { return \u0026amp;BinarySearchTree{Root: nil} } // Insert a value into the BST func (bst *BinarySearchTree) Insert(value int) { newNode := \u0026amp;TreeNode{Value: value} // If tree is empty, new node becomes root if bst.Root == nil { bst.Root = newNode return } // Otherwise, find the correct position insertNode(bst.Root, newNode) } // Helper function for insertion func insertNode(node, newNode *TreeNode) { // Go left if new value is smaller if newNode.Value \u0026lt; node.Value { if node.Left == nil { node.Left = newNode } else { insertNode(node.Left, newNode) } } else { // Go right if new value is greater or equal if node.Right == nil { node.Right = newNode } else { insertNode(node.Right, newNode) } } } // Search for a value in the BST func (bst *BinarySearchTree) Search(value int) *TreeNode { return searchNode(bst.Root, value) } // Helper function for searching (recursive approach) func searchNode(node *TreeNode, value int) *TreeNode { // Base cases: not found or found if node == nil || node.Value == value { return node } // Recursive case: search in left or right subtree if value \u0026lt; node.Value { return searchNode(node.Left, value) } return searchNode(node.Right, value) } // Search iteratively (alternative implementation) func (bst *BinarySearchTree) SearchIterative(value int) *TreeNode { current := bst.Root // Traverse down the tree for current != nil { // Value found if current.Value == value { return current } // Navigate left or right if value \u0026lt; current.Value { current = current.Left } else { current = current.Right } } // Value not found return nil } // In-order traversal (left, root, right) func (bst *BinarySearchTree) InOrderTraversal() []int { result := []int{} inOrder(bst.Root, \u0026amp;result) return result } func inOrder(node *TreeNode, result *[]int) { if node != nil { inOrder(node.Left, result) *result = append(*result, node.Value) inOrder(node.Right, result) } } // Example usage func main() { bst := NewBinarySearchTree() // Insert values values := []int{8, 3, 10, 1, 6, 9, 14} for _, v := range values { bst.Insert(v) } // Search for a value if node := bst.Search(6); node != nil { fmt.Println(\u0026#34;Found value:\u0026#34;, node.Value) } else { fmt.Println(\u0026#34;Value not found\u0026#34;) } // Print all values in order fmt.Println(\u0026#34;In-order traversal:\u0026#34;, bst.InOrderTraversal()) } The search operation demonstrates the divide-and-conquer approach of binary trees:\n// Search iteratively func (bst *BinarySearchTree) SearchIterative(value int) *TreeNode { current := bst.Root // Traverse down the tree for current != nil { // Value found if current.Value == value { return current } // Navigate left or right based on value comparison if value \u0026lt; current.Value { current = current.Left } else { current = current.Right } } // Value not found return nil } Each comparison eliminates roughly half of the remaining nodes from consideration, giving us the O(log n) complexity for balanced trees.\nReal-World Application: Word Frequency Counter # Binary search trees can be adapted for specialized use cases. Here\u0026rsquo;s an example of using a BST to count and sort word frequencies in text:\n// A specialized tree for counting word occurrences type WordCount struct { Word string Count int } type WordCountTree struct { Value WordCount Left *WordCountTree Right *WordCountTree } // Insert or increment word count func (t *WordCountTree) Insert(word string) *WordCountTree { // If tree is empty, create a new node if t == nil { return \u0026amp;WordCountTree{ Value: WordCount{Word: word, Count: 1}, } } // Compare words lexicographically if word \u0026lt; t.Value.Word { // Insert into left subtree t.Left = t.Left.Insert(word) } else if word \u0026gt; t.Value.Word { // Insert into right subtree t.Right = t.Right.Insert(word) } else { // Word already exists, increment count t.Value.Count++ } return t } // Process text and build a word frequency tree func BuildWordFrequencyTree(text string) *WordCountTree { var root *WordCountTree // Split text into words and clean them words := strings.Fields(text) for _, word := range words { // Clean the word (remove punctuation, lowercase) word = strings.ToLower(strings.Trim(word, \u0026#34;,.!?:;\\\u0026#34;\u0026#39;()\u0026#34;)) if word != \u0026#34;\u0026#34; { root = root.Insert(word) } } return root } // Print the words in alphabetical order with their counts func (t *WordCountTree) PrintSorted() { if t == nil { return } // In-order traversal: left, root, right t.Left.PrintSorted() fmt.Printf(\u0026#34;%s: %d\\n\u0026#34;, t.Value.Word, t.Value.Count) t.Right.PrintSorted() } Notice how this specialized implementation follows the same principles as our generic BST, but adapts the tree for a specific use case:\nThe comparison is based on string values instead of integers The nodes store both a word and its count Duplicate words increment the count rather than adding a new node The tree remains ordered alphabetically, allowing for sorted output We\u0026rsquo;ve covered data structures that manage their elements in different ways, but what about when we need strict control over the order of additions and removals? Let\u0026rsquo;s look at two specialized structures designed for exactly that.\nStacks and Queues: Sequential Access Patterns # Sometimes we need strict control over the order of processing elements. When I\u0026rsquo;m debugging a complex algorithm or implementing a breadth-first search, two data structures consistently save my bacon: stacks and queues.\nStacks and queues implement specific access patterns that model many real-world scenarios:\nStacks: LIFO (Last In, First Out) - like a stack of plates where you can only take from the top Queues: FIFO (First In, First Out) - like people waiting in line at a coffee shop Both are easily implemented using slices in Go:\nStack Implementation # // Stack is a LIFO (Last In, First Out) data structure type Stack struct { items []int } // NewStack creates a new stack func NewStack() *Stack { return \u0026amp;Stack{ items: make([]int, 0), } } // Push adds an item to the top of the stack func (s *Stack) Push(item int) { s.items = append(s.items, item) } // Pop removes and returns the top item from the stack func (s *Stack) Pop() (int, error) { if len(s.items) == 0 { return 0, errors.New(\u0026#34;stack is empty\u0026#34;) } lastIdx := len(s.items) - 1 item := s.items[lastIdx] s.items = s.items[:lastIdx] return item, nil } // Peek returns the top item without removing it func (s *Stack) Peek() (int, error) { if len(s.items) == 0 { return 0, errors.New(\u0026#34;stack is empty\u0026#34;) } return s.items[len(s.items)-1], nil } // IsEmpty returns true if the stack has no items func (s *Stack) IsEmpty() bool { return len(s.items) == 0 } // Size returns the number of items in the stack func (s *Stack) Size() int { return len(s.items) } Queue Implementation # // Queue is a FIFO (First In, First Out) data structure type Queue struct { items []int } // NewQueue creates a new queue func NewQueue() *Queue { return \u0026amp;Queue{ items: make([]int, 0), } } // Enqueue adds an item to the back of the queue func (q *Queue) Enqueue(item int) { q.items = append(q.items, item) } // Dequeue removes and returns the front item from the queue func (q *Queue) Dequeue() (int, error) { if len(q.items) == 0 { return 0, errors.New(\u0026#34;queue is empty\u0026#34;) } item := q.items[0] q.items = q.items[1:] return item, nil } // Front returns the front item without removing it func (q *Queue) Front() (int, error) { if len(q.items) == 0 { return 0, errors.New(\u0026#34;queue is empty\u0026#34;) } return q.items[0], nil } // IsEmpty returns true if the queue has no items func (q *Queue) IsEmpty() bool { return len(q.items) == 0 } // Size returns the number of items in the queue func (q *Queue) Size() int { return len(q.items) } Comparison (visualized) # From a structural perspective, they operate as follows:\ngraph TD subgraph \u0026#34;Stack (LIFO)\u0026#34; A1[Push] --\u0026gt; B1[3] B1 --\u0026gt; C1[2] C1 --\u0026gt; D1[1] E1[Pop] --\u0026gt; B1 end subgraph \u0026#34;Queue (FIFO)\u0026#34; A2[Enqueue] --\u0026gt; B2[3] B2 --\u0026gt; C2[2] C2 --\u0026gt; D2[1] E2[Dequeue] --\u0026gt; D2 end style A1 fill:#b71c1c,stroke:#e53935,color:#ffebee style E1 fill:#b71c1c,stroke:#e53935,color:#ffebee style A2 fill:#004d40,stroke:#00796b,color:#e0f2f1 style E2 fill:#004d40,stroke:#00796b,color:#e0f2f1 Technical Performance Analysis # Operation Stack Queue (slice implementation) Technical Explanation Push/Enqueue O(1) amortized O(1) amortized Both use slice append() Pop O(1) - Removing from end doesn\u0026rsquo;t require element shifting Dequeue - O(n) Removing from start requires shifting all elements Peek/Front O(1) O(1) Direct access to first/last element Practical Example: Postfix Expression Evaluator # Here\u0026rsquo;s our Stack in action for evaluating a postfix (Reverse Polish Notation) expression:\n// EvaluatePostfix evaluates a postfix expression like \u0026#34;3 4 + 5 *\u0026#34; func EvaluatePostfix(expression string) (int, error) { stack := NewStack() tokens := strings.Fields(expression) for _, token := range tokens { switch token { case \u0026#34;+\u0026#34;, \u0026#34;-\u0026#34;, \u0026#34;*\u0026#34;, \u0026#34;/\u0026#34;: // Need at least two operands if stack.Size() \u0026lt; 2 { return 0, errors.New(\u0026#34;invalid expression: not enough operands\u0026#34;) } // Pop the two operands (remember: LIFO order) b, _ := stack.Pop() a, _ := stack.Pop() // Perform the operation and push result var result int switch token { case \u0026#34;+\u0026#34;: result = a + b case \u0026#34;-\u0026#34;: result = a - b case \u0026#34;*\u0026#34;: result = a * b case \u0026#34;/\u0026#34;: if b == 0 { return 0, errors.New(\u0026#34;division by zero\u0026#34;) } result = a / b } stack.Push(result) default: // Must be a number, convert and push num, err := strconv.Atoi(token) if err != nil { return 0, fmt.Errorf(\u0026#34;invalid token: %s\u0026#34;, token) } stack.Push(num) } } // The result should be the only item on the stack if stack.Size() != 1 { return 0, errors.New(\u0026#34;invalid expression: too many operands\u0026#34;) } return stack.Pop() } // Example usage: // result, _ := EvaluatePostfix(\u0026#34;3 4 + 5 *\u0026#34;) // (3 + 4) * 5 = 35 This example demonstrates how a stack is perfect for expression evaluation because of its LIFO nature. When we see a number, we push it onto the stack. When we see an operator, we pop the required operands, perform the calculation, and push the result back.\nPractical Example: Simple Task Queue # Now let\u0026rsquo;s see how our Queue can be used to process tasks in order:\n// Task represents a simple task with an ID and a function to execute type Task struct { ID string Execute func() error } // TaskQueue manages a queue of tasks to be executed in FIFO order type TaskQueue struct { tasks []Task } // NewTaskQueue creates a new task queue func NewTaskQueue() *TaskQueue { return \u0026amp;TaskQueue{ tasks: make([]Task, 0), } } // AddTask adds a new task to the queue func (tq *TaskQueue) AddTask(id string, execute func() error) { tq.tasks = append(tq.tasks, Task{ ID: id, Execute: execute, }) } // ProcessAllTasks processes all tasks in the queue in FIFO order func (tq *TaskQueue) ProcessAllTasks() []error { var errors []error for len(tq.tasks) \u0026gt; 0 { // Get the next task (from the front of the queue) task := tq.tasks[0] tq.tasks = tq.tasks[1:] // Dequeue operation // Execute the task if err := task.Execute(); err != nil { errors = append(errors, fmt.Errorf(\u0026#34;task %s failed: %v\u0026#34;, task.ID, err)) } } return errors } // Example usage: func main() { taskQueue := NewTaskQueue() // Add some tasks taskQueue.AddTask(\u0026#34;task1\u0026#34;, func() error { fmt.Println(\u0026#34;Executing task 1\u0026#34;) return nil }) taskQueue.AddTask(\u0026#34;task2\u0026#34;, func() error { fmt.Println(\u0026#34;Executing task 2\u0026#34;) return errors.New(\u0026#34;task 2 failed\u0026#34;) }) taskQueue.AddTask(\u0026#34;task3\u0026#34;, func() error { fmt.Println(\u0026#34;Executing task 3\u0026#34;) return nil }) // Process all tasks errors := taskQueue.ProcessAllTasks() // Report any errors for _, err := range errors { fmt.Println(\u0026#34;Error:\u0026#34;, err) } } In this example, the queue ensures that tasks are processed in the exact order they were added - a classic FIFO operation.\nImplementation Alternatives for Efficient Queues # The slice-based queue implementation above has a significant limitation: O(n) dequeue operations. More efficient alternatives include:\nCircular Buffer: Using an array with head and tail pointers that wrap around Linked List Queue: Using a linked list with head and tail pointers Double-Ended Queue: Using container/list from the standard library Here\u0026rsquo;s a simple implementation of a circular buffer queue:\n// CircularQueue implements a queue using a circular buffer type CircularQueue struct { items []int head int tail int size int cap int } // NewCircularQueue creates a new circular queue with the given capacity func NewCircularQueue(capacity int) *CircularQueue { return \u0026amp;CircularQueue{ items: make([]int, capacity), head: 0, tail: 0, size: 0, cap: capacity, } } // Enqueue adds an item to the queue - O(1) func (q *CircularQueue) Enqueue(item int) error { if q.size == q.cap { return errors.New(\u0026#34;queue is full\u0026#34;) } q.items[q.tail] = item q.tail = (q.tail + 1) % q.cap q.size++ return nil } // Dequeue removes and returns the front item - O(1) func (q *CircularQueue) Dequeue() (int, error) { if q.size == 0 { return 0, errors.New(\u0026#34;queue is empty\u0026#34;) } item := q.items[q.head] q.head = (q.head + 1) % q.cap q.size-- return item, nil } This circular queue implementation gives us O(1) operations for both enqueue and dequeue, eliminating the need to shift elements.\nüìù Note The standard library\u0026rsquo;s container/list provides a generic doubly-linked list implementation that can efficiently serve as a queue with O(1) operations for both insertions and removals from either end. Practical Comparisons: Choosing the Right Tool # Alright, so you\u0026rsquo;ve got a toolbox full of data structures, but which one should you reach for? Let\u0026rsquo;s break down exactly when to use each one - just practical advice for real-world Go code.\nHere\u0026rsquo;s a cheat sheet comparing our data structures side-by-side:\nData Structure Best For Not Great For Technical Trade-offs Arrays/Slices Random access, sequential processing, cache-friendly operations Frequent insertions/deletions in the middle Fast access (O(1)) vs. slow modifications (O(n)) Linked Lists Constant-time insertions/deletions at known positions Random access or cache locality Fast modifications at known positions vs. slow traversal Hash Maps Key-value lookups, existence checks, counting Maintaining order, range queries Near-constant lookups vs. randomized iteration order Binary Trees Ordered data, range scans, floor/ceiling operations Simple lookups where order doesn\u0026rsquo;t matter Logarithmic operations vs. implementation complexity Stacks Tracking state for backtracking, expression parsing Random access to elements Simple LIFO interface vs. limited access patterns Queues Ordered processing, breadth-first traversals Priority-based processing Simple FIFO interface vs. limited access patterns Common Use Case Examples # I can\u0026rsquo;t count how many times I\u0026rsquo;ve seen engineers, who know just enough to be dangerous, reach for the wrong data structure and then wonder why their code crawls when given more than a hundred elements! Here are some example problems matched with their ideal data structure:\nLogin system with username lookups: Hash map - map[string]UserData Undo functionality in a text editor: Stack - push state changes, pop to undo Account metadata with prefix search: Trie (specialized tree) - efficient prefix matching Graph traversal with BFS: Queue - keeps track of the \u0026ldquo;frontier\u0026rdquo; nodes Task scheduling by priority: Heap (priority queue) - O(log n) for highest-priority extraction Let\u0026rsquo;s visualize the decision process:\nflowchart TD A[What\u0026#39;s your primary operation?] --\u0026gt;|Lookup by key| B[Hash Map] A --\u0026gt;|Ordered operations| C[Need range queries?] A --\u0026gt;|Sequential access| D[Need to track order?] A --\u0026gt;|Random access by index| E[Arrays/Slices] C --\u0026gt;|Yes| F[Binary Tree] C --\u0026gt;|No| G[Does order matter?] D --\u0026gt;|LIFO| H[Stack] D --\u0026gt;|FIFO| I[Queue] G --\u0026gt;|Yes| J[Ordered Map or Array+Map] G --\u0026gt;|No| B style A fill:#1a237e,stroke:#3949ab,color:#e8eaf6 Space Complexity: Memory Matters Too # Time complexity gets all the glory, but space complexity can make or break your application, especially in constrained environments. Here\u0026rsquo;s how our data structures stack up:\nData Structure Space Complexity Memory Overhead Technical Details Arrays/Slices O(n) Low Contiguous memory allocation with minimal metadata Linked Lists O(n) High Each node requires additional pointer storage (8 bytes per pointer on 64-bit systems) Hash Maps O(n) Medium-High Requires extra space for buckets to minimize collisions Binary Trees O(n) Medium Each node contains two child pointers plus value Stacks/Queues O(n) Depends on implementation Inherits from underlying data structure Memory Optimization Strategies # When memory becomes a bottleneck, consider these technical approaches:\nCustom allocators: Implement arena allocation for many small objects Bit packing: Use bit fields to compress data when working with small values Immutable data structures: Share memory between instances using structural sharing Lazy loading: Only load data when needed, especially for tree structures Memory pools: Pre-allocate fixed-size blocks to reduce allocation overhead üìå Important When implementing recursive algorithms, be mindful of stack space. Each recursive call consumes additional stack frames, which can lead to stack overflow for deep recursion. Consider iterative alternatives using an explicit stack when processing large datasets. Decision Framework for Data Structure Selection # When you\u0026rsquo;re staring at a new problem and trying to decide which data structure to use, ask yourself these questions:\nAccess pattern: How will the data be accessed? (randomly, sequentially, by key) Modification frequency: Is the data mostly static or frequently modified? Ordering requirements: Does the natural order of elements matter? Size considerations: How large will the dataset grow? Operation frequency: Which operations will be performed most often? Memory constraints: Are there limitations on memory usage? These questions form a decision tree that can guide you to the optimal data structure for your specific scenario.\nConclusion # By understanding data structures and their characteristics, strengths, and limitations at a deep technical level, you can make informed decisions that dramatically impact your application\u0026rsquo;s performance.\nThe Go standard library provides excellent implementations of the most commonly used data structures, with well-defined performance characteristics. For specialized needs, there are plenty of third-party packages offering advanced implementations.\nRemember that theoretical performance is just one factor in the decision. Practical considerations like readability, maintainability, and the specific patterns of your data are equally important for building efficient systems.\nNow get out there and crush those performance bottlenecks with the right data structure for the job!\nReferences # Go Standard Library The Go Programming Language by Alan A. A. Donovan and Brian W. Kernighan Big O Cheat Sheet ","date":"May 17, 2025","permalink":"https://blog.mikesahari.com/posts/dsa-part2-data-structures/","tags":["go","programming","data-structures","algorithms","big-o","performance"],"title":"Mastering DSAs in Go - Data Structures [Part 2]"},{"content":"I\u0026rsquo;ve been really enjoying teaching fundamentals in Go, recently. If you haven\u0026rsquo;t read any of my other blogs or are new to go, I strongly recommend checking out my fundamentals posts. I started this blog as a next step, and before I knew it I was writing something way too long to share. This will be the first part of a blog series on data structures and algorithms; and of course, in Go!\nIn my opinion, understanding algorithm complexity is non-negotiable for writing efficient code. But let\u0026rsquo;s face it, you\u0026rsquo;re not always going to work on a team where engineers write efficient code (let alone an algorithm!). Even worse, you may work in a larger team with tech leads that don\u0026rsquo;t understand algorithms; resulting in your newer engineers missing out on the chance for proper mentorship in coding (or be taught bad practices!).\nBig-O isn\u0026rsquo;t just academic theory‚Äîit\u0026rsquo;s a practical tool that determines whether your application will handle 10,000 users or crash when the 101st person logs in. Whether you\u0026rsquo;re new to Big-O or interested in learning it in Go, this blog will help teach you about these algorithms.\nWhat is Big-O Notation? # Big-O notation is how we describe an algorithm\u0026rsquo;s efficiency as input size grows. It\u0026rsquo;s like a speed limit sign for your code‚Äîtelling you not how fast your algorithm runs on your M2 MacBook Pro, but how it will perform when your data grows from kilobytes to gigabytes.\nüìù Note Big-O notation describes the worst-case scenario for your algorithm\u0026rsquo;s time or space complexity. It answers: \u0026ldquo;How does my algorithm\u0026rsquo;s performance scale?\u0026rdquo; rather than \u0026ldquo;How fast is my function right now?\u0026rdquo; In essence, Big-O focuses on the growth rate of time or space requirements as the input size increases toward infinity, ignoring constants and lower-order terms that become insignificant with large inputs.\nflowchart LR classDef default fill:#2d333b,stroke:#3b454e,color:#adbac7 classDef constant fill:#1a237e,stroke:#3949ab,color:#e8eaf6 classDef logarithmic fill:#004d40,stroke:#00796b,color:#e0f2f1 classDef linear fill:#b71c1c,stroke:#e53935,color:#ffebee classDef linearithmic fill:#311b92,stroke:#5e35b1,color:#ede7f6 classDef quadratic fill:#880e4f,stroke:#d81b60,color:#fce4ec classDef exponential fill:#3e2723,stroke:#6d4c41,color:#efebe9 A[\u0026#34;\u0026lt;b\u0026gt;Common Big O Complexities\u0026lt;/b\u0026gt;\u0026#34;] --\u0026gt; B[\u0026#34;O(1): Constant\u0026#34;] A --\u0026gt; C[\u0026#34;O(log n): Logarithmic\u0026#34;] A --\u0026gt; D[\u0026#34;O(n): Linear\u0026#34;] A --\u0026gt; E[\u0026#34;O(n log n): Linearithmic\u0026#34;] A --\u0026gt; F[\u0026#34;O(n¬≤): Quadratic\u0026#34;] A --\u0026gt; G[\u0026#34;O(2^n): Exponential\u0026#34;] B:::constant C:::logarithmic D:::linear E:::linearithmic F:::quadratic G:::exponential Understanding Complexity Classes in Practice # Let\u0026rsquo;s explore these complexity classes with practical Go implementations and see exactly what happens as our inputs grow.\nO(1) - Constant Time: The Speed Champion # Operations that execute in the same time regardless of input size. This is the gold standard we strive for.\n// GetMapValue is an example of Constant Time func GetMapValue(m map[string]int, key string) (int, bool) { val, exists := m[key] return val, exists } This function performs a hash table lookup which takes the same amount of time whether your map has 10 entries or 10 million. Go\u0026rsquo;s maps are implemented as hash tables, giving us O(1) average-case access time.\nHere\u0026rsquo;s what happens behind the scenes:\nflowchart TD A[Start GetMapValue] --\u0026gt; B[\u0026#34;Compute hash of key\u0026#34;] B --\u0026gt; C[\u0026#34;Locate bucket based on hash\u0026#34;] C --\u0026gt; D[\u0026#34;Search bucket for key\u0026#34;] D --\u0026gt; E{\u0026#34;Key found?\u0026#34;} E --\u0026gt;|Yes| F[\u0026#34;Return value and true\u0026#34;] E --\u0026gt;|No| G[\u0026#34;Return zero value and false\u0026#34;] subgraph \u0026#34;Performance Analysis\u0026#34; H[\u0026#34;Map size: 10\u0026#34;] --\u0026gt; I[\u0026#34;Operations: ~3\u0026#34;] J[\u0026#34;Map size: 1,000,000\u0026#34;] --\u0026gt; K[\u0026#34;Operations: ~3\u0026#34;] end style A fill:#1a237e,stroke:#3949ab,color:#e8eaf6 style B fill:#004d40,stroke:#00796b,color:#e0f2f1 style C fill:#004d40,stroke:#00796b,color:#e0f2f1 style D fill:#b71c1c,stroke:#e53935,color:#ffebee style E fill:#b71c1c,stroke:#e53935,color:#ffebee style F fill:#311b92,stroke:#5e35b1,color:#ede7f6 style G fill:#880e4f,stroke:#d81b60,color:#fce4ec style H fill:#004d40,stroke:#00796b,color:#e0f2f1 style I fill:#004d40,stroke:#00796b,color:#e0f2f1 style J fill:#4a148c,stroke:#7b1fa2,color:#f3e5f5 style K fill:#4a148c,stroke:#7b1fa2,color:#f3e5f5 üí° Tip While Go maps provide O(1) lookups on average, their worst-case performance can degrade to O(n) under pathological hash collision cases. In practice, Go\u0026rsquo;s implementation mitigates this by using a good hash function and automatically growing the hash table when needed. The beauty of O(1) operations is their predictability‚Äîthey\u0026rsquo;ll perform the same whether your app has 10 users or 10 million. This is why we love them for hot paths in our code.\nO(log n) - Logarithmic Time: The Efficient Divider # Algorithms that reduce the problem size by a fraction (typically half) with each step. The binary search is the poster child here.\n// BinarySearch is an example of Logarithmic Time func BinarySearch(sorted []int, target int) int { left, right := 0, len(sorted)-1 for left \u0026lt;= right { mid := left + (right-left)/2 // Avoids integer overflow switch { case sorted[mid] == target: return mid // Found it! case sorted[mid] \u0026lt; target: left = mid + 1 // Look in the right half case sorted[mid] \u0026gt; target: right = mid - 1 // Look in the left half } } return -1 // Target not found } Let\u0026rsquo;s trace through this with a concrete example:\nsorted = [2, 5, 8, 12, 16, 23, 38, 56, 72, 91] target = 23 Initial state: left=0, right=9, mid=4, sorted[mid]=16 16 \u0026lt; 23, so we set left=5 New state: left=5, right=9, mid=7, sorted[mid]=56 56 \u0026gt; 23, so we set right=6 New state: left=5, right=6, mid=5, sorted[mid]=23 23 == 23, return 5 With just 3 comparisons, we found our target in a list of 10 elements. If we had a million elements? It would take around 20 comparisons. That\u0026rsquo;s the power of O(log n).\nflowchart TD A[\u0026#34;Start BinarySearch\u0026#34;] --\u0026gt; B[\u0026#34;left = 0, right = len(sorted)-1\u0026#34;] B --\u0026gt; C{\u0026#34;left \u0026lt;= right?\u0026#34;} C --\u0026gt;|No| D[\u0026#34;Return -1 (Not Found)\u0026#34;] C --\u0026gt;|Yes| E[\u0026#34;mid = left + (right-left)/2\u0026#34;] E --\u0026gt; F{\u0026#34;sorted[mid] == target?\u0026#34;} F --\u0026gt;|Yes| G[\u0026#34;Return mid (Found)\u0026#34;] F --\u0026gt;|No| H{\u0026#34;sorted[mid] \u0026lt; target?\u0026#34;} H --\u0026gt;|Yes| I[\u0026#34;left = mid + 1\u0026#34;] H --\u0026gt;|No| J[\u0026#34;right = mid - 1\u0026#34;] I --\u0026gt; C J --\u0026gt; C subgraph \u0026#34;Performance Growth\u0026#34; K[\u0026#34;Elements: 10\u0026#34;] --\u0026gt; L[\u0026#34;Comparisons: ~3\u0026#34;] M[\u0026#34;Elements: 1,000\u0026#34;] --\u0026gt; N[\u0026#34;Comparisons: ~10\u0026#34;] O[\u0026#34;Elements: 1,000,000\u0026#34;] --\u0026gt; P[\u0026#34;Comparisons: ~20\u0026#34;] end style A fill:#1a237e,stroke:#3949ab,color:#e8eaf6 style B fill:#004d40,stroke:#00796b,color:#e0f2f1 style C fill:#b71c1c,stroke:#e53935,color:#ffebee style D fill:#880e4f,stroke:#d81b60,color:#fce4ec style E fill:#004d40,stroke:#00796b,color:#e0f2f1 style F fill:#b71c1c,stroke:#e53935,color:#ffebee style G fill:#311b92,stroke:#5e35b1,color:#ede7f6 style H fill:#b71c1c,stroke:#e53935,color:#ffebee style I fill:#004d40,stroke:#00796b,color:#e0f2f1 style J fill:#004d40,stroke:#00796b,color:#e0f2f1 style K fill:#4a148c,stroke:#7b1fa2,color:#f3e5f5 style L fill:#4a148c,stroke:#7b1fa2,color:#f3e5f5 style M fill:#01579b,stroke:#0288d1,color:#e1f5fe style N fill:#01579b,stroke:#0288d1,color:#e1f5fe style O fill:#3e2723,stroke:#6d4c41,color:#efebe9 style P fill:#3e2723,stroke:#6d4c41,color:#efebe9 üó®Ô∏è Example The Go standard library uses binary search in several places, like the sort.Search function. Here\u0026rsquo;s how you\u0026rsquo;d use it to find the position to insert a new element while maintaining order:\nimport \u0026#34;sort\u0026#34; func FindInsertPosition(sorted []int, value int) int { return sort.Search(len(sorted), func(i int) bool { return sorted[i] \u0026gt;= value }) } Remember that binary search requires sorted data, which is a crucial prerequisite. If your data isn\u0026rsquo;t sorted, you\u0026rsquo;ll need to sort it first (typically an O(n log n) operation), which changes the overall performance characteristics.\nO(n) - Linear Time: The Honest Worker # Operations where execution time grows in direct proportion to input size. Every element gets processed exactly once.\n// ContainsElement is an example of Linear Time func ContainsElement(slice []int, target int) bool { for _, val := range slice { if val == target { return true } } return false } This might look simple, but don\u0026rsquo;t underestimate it. Linear algorithms are often the best you can do for unsorted data, and they\u0026rsquo;re predictable and cache-friendly. The time required scales directly with the input size.\nflowchart TD A[\u0026#34;Start ContainsElement\u0026#34;] --\u0026gt; B[\u0026#34;i = 0\u0026#34;] B --\u0026gt; C{\u0026#34;i \u0026lt; len(slice)?\u0026#34;} C --\u0026gt;|No| D[\u0026#34;Return false\u0026#34;] C --\u0026gt;|Yes| E{\u0026#34;slice[i] == target?\u0026#34;} E --\u0026gt;|Yes| F[\u0026#34;Return true\u0026#34;] E --\u0026gt;|No| G[\u0026#34;i++\u0026#34;] G --\u0026gt; C subgraph \u0026#34;Performance Scaling\u0026#34; K[\u0026#34;Elements: 10\u0026#34;] --\u0026gt; L[\u0026#34;Iterations: 1-10\u0026#34;] M[\u0026#34;Elements: 1,000\u0026#34;] --\u0026gt; N[\u0026#34;Iterations: 1-1,000\u0026#34;] O[\u0026#34;Elements: 1,000,000\u0026#34;] --\u0026gt; P[\u0026#34;Iterations: 1-1,000,000\u0026#34;] end style A fill:#1a237e,stroke:#3949ab,color:#e8eaf6 style B fill:#004d40,stroke:#00796b,color:#e0f2f1 style C fill:#b71c1c,stroke:#e53935,color:#ffebee style D fill:#880e4f,stroke:#d81b60,color:#fce4ec style E fill:#b71c1c,stroke:#e53935,color:#ffebee style F fill:#311b92,stroke:#5e35b1,color:#ede7f6 style G fill:#004d40,stroke:#00796b,color:#e0f2f1 style K fill:#4a148c,stroke:#7b1fa2,color:#f3e5f5 style L fill:#4a148c,stroke:#7b1fa2,color:#f3e5f5 style M fill:#01579b,stroke:#0288d1,color:#e1f5fe style N fill:#01579b,stroke:#0288d1,color:#e1f5fe style O fill:#3e2723,stroke:#6d4c41,color:#efebe9 style P fill:#3e2723,stroke:#6d4c41,color:#efebe9 üìå Important Go\u0026rsquo;s slice iteration with range is highly optimized. The compiler can eliminate bounds checking in many situations, making linear scans extremely efficient‚Äîsometimes approaching the theoretical memory bandwidth limit of your hardware. Linear algorithms are often unavoidable when you need to process all elements at least once, such as when calculating sums, finding maximum values, or checking if all elements meet a condition.\nO(n log n) - Linearithmic Time: The Practical Sorter # Found in efficient sorting algorithms and divide-and-conquer approaches, O(n log n) represents the best possible time complexity for comparison-based sorting.\nGo\u0026rsquo;s standard library sort package implements an optimized version of quicksort (with insertion sort for small slices) that achieves O(n log n) average-case performance:\n// QuickSort is an example of Linearithmic Time func QuickSort(arr []int) []int { // Make a copy to avoid modifying input result := make([]int, len(arr)) copy(result, arr) // Call the recursive helper quickSortHelper(result, 0, len(result)-1) return result } func quickSortHelper(arr []int, low, high int) { if low \u0026lt; high { // Partition the array and get the pivot index pivotIndex := partition(arr, low, high) // Recursively sort the sub-arrays quickSortHelper(arr, low, pivotIndex-1) quickSortHelper(arr, pivotIndex+1, high) } } func partition(arr []int, low, high int) int { // Choose the rightmost element as pivot pivot := arr[high] // Index of smaller element i := low - 1 for j := low; j \u0026lt; high; j++ { // If current element is smaller than the pivot if arr[j] \u0026lt;= pivot { // Increment index of smaller element i++ arr[i], arr[j] = arr[j], arr[i] } } // Swap the pivot element with the element at (i+1) arr[i+1], arr[high] = arr[high], arr[i+1] // Return the partition index return i + 1 } üó®Ô∏è Example In this example, we used copy. If you are not familiar with how this works, it accepts a destination slice type and a source slice type.\nSo in our use above, we copied all the values from arr into result. Without this copy step, you\u0026rsquo;d be modifying the original slice that was passed in, which could lead to unexpected side effects.\nNow let\u0026rsquo;s analyze what happens during a quicksort with a small example:\narr = [38, 27, 43, 3, 9, 82, 10] The recursive partitioning creates a tree-like structure of work:\nflowchart TD subgraph \u0026#34;QuickSort Process Example\u0026#34; A[\u0026#34;[38, 27, 43, 3, 9, 82, 10]\u0026#34;] --\u0026gt; B[\u0026#34;Pivot = 10\u0026#34;] B --\u0026gt; C[\u0026#34;[3, 9, 10] + [38, 27, 43, 82]\u0026#34;] C --\u0026gt; D[\u0026#34;Pivot = 9\u0026#34;] C --\u0026gt; E[\u0026#34;Pivot = 27\u0026#34;] D --\u0026gt; F[\u0026#34;[3] + [9] + [10]\u0026#34;] E --\u0026gt; G[\u0026#34;[27] + [38, 43, 82]\u0026#34;] G --\u0026gt; H[\u0026#34;Pivot = 82\u0026#34;] H --\u0026gt; I[\u0026#34;[38, 43] + [82]\u0026#34;] I --\u0026gt; J[\u0026#34;Pivot = 43\u0026#34;] J --\u0026gt; K[\u0026#34;[38] + [43] + [82]\u0026#34;] end subgraph \u0026#34;Performance Analysis\u0026#34; L[\u0026#34;Elements: 10\u0026#34;] --\u0026gt; M[\u0026#34;Operations: ~30\u0026#34;] N[\u0026#34;Elements: 1,000\u0026#34;] --\u0026gt; O[\u0026#34;Operations: ~10,000\u0026#34;] P[\u0026#34;Elements: 1,000,000\u0026#34;] --\u0026gt; Q[\u0026#34;Operations: ~20,000,000\u0026#34;] end style A fill:#1a237e,stroke:#3949ab,color:#e8eaf6 style B fill:#004d40,stroke:#00796b,color:#e0f2f1 style C fill:#004d40,stroke:#00796b,color:#e0f2f1 style D fill:#b71c1c,stroke:#e53935,color:#ffebee style E fill:#b71c1c,stroke:#e53935,color:#ffebee style F fill:#311b92,stroke:#5e35b1,color:#ede7f6 style G fill:#880e4f,stroke:#d81b60,color:#fce4ec style H fill:#004d40,stroke:#00796b,color:#e0f2f1 style I fill:#004d40,stroke:#00796b,color:#e0f2f1 style J fill:#b71c1c,stroke:#e53935,color:#ffebee style K fill:#311b92,stroke:#5e35b1,color:#ede7f6 style L fill:#4a148c,stroke:#7b1fa2,color:#f3e5f5 style M fill:#4a148c,stroke:#7b1fa2,color:#f3e5f5 style N fill:#01579b,stroke:#0288d1,color:#e1f5fe style O fill:#01579b,stroke:#0288d1,color:#e1f5fe style P fill:#3e2723,stroke:#6d4c41,color:#efebe9 style Q fill:#3e2723,stroke:#6d4c41,color:#efebe9 üí° Tip In Go, prefer using the standard library\u0026rsquo;s sort package for sorting needs rather than implementing your own. It\u0026rsquo;s well-optimized and handles edge cases properly:\nimport \u0026#34;sort\u0026#34; // For slices of basic types nums := []int{5, 2, 6, 3, 1, 4} sort.Ints(nums) // For custom sorting sort.Slice(people, func(i, j int) bool { return people[i].Age \u0026lt; people[j].Age }) The O(n log n) complexity comes from:\nThe recursive partitioning creates a tree of height log n (divide) At each level, we do about n work comparing elements (conquer) This makes it much more efficient than quadratic algorithms for large datasets. When sorting a million elements, quicksort would perform about 20 million operations compared to a trillion for bubble sort!\nO(n¬≤) - Quadratic Time: The Brute-Force Approach # Characterized by nested loops, quadratic algorithms quickly become impractical as data size grows.\nI once had an engineer message me on Slack, asking how I was able to retrieve a ton of data so fast. He asked if it was because I was using Go and because he was using Python. When I told him that was part of the reason, he said he was just going to use AI to rewrite it in Go; but before he went down the vibe coding route with his Cursor setup, I asked a bunch of leading questions about how he was processing the data. Turns out, he had vibe coded a very poor implementation of bubble sort (without understanding it)!\nLet\u0026rsquo;s take a look at a cleaner implementation of bubble sort.\n// Bubble Sort is an example of Quadratic Time func BubbleSort(arr []int) { n := len(arr) for i := 0; i \u0026lt; n; i++ { swapped := false for j := 0; j \u0026lt; n-i-1; j++ { if arr[j] \u0026gt; arr[j+1] { arr[j], arr[j+1] = arr[j+1], arr[j] swapped = true } } // If no swapping occurred in this pass, the array is sorted if !swapped { break } } } Bubble sort performs comparisons and swaps between adjacent elements, gradually \u0026ldquo;bubbling\u0026rdquo; the largest elements to their correct positions. Let\u0026rsquo;s walk through it:\narr = [5, 3, 8, 4, 2] Pass 1: Compare 5 \u0026amp; 3 ‚Üí Swap ‚Üí [3, 5, 8, 4, 2] Compare 5 \u0026amp; 8 ‚Üí No swap ‚Üí [3, 5, 8, 4, 2] Compare 8 \u0026amp; 4 ‚Üí Swap ‚Üí [3, 5, 4, 8, 2] Compare 8 \u0026amp; 2 ‚Üí Swap ‚Üí [3, 5, 4, 2, 8] Pass 2: Compare 3 \u0026amp; 5 ‚Üí No swap ‚Üí [3, 5, 4, 2, 8] Compare 5 \u0026amp; 4 ‚Üí Swap ‚Üí [3, 4, 5, 2, 8] Compare 5 \u0026amp; 2 ‚Üí Swap ‚Üí [3, 4, 2, 5, 8] Pass 3: Compare 3 \u0026amp; 4 ‚Üí No swap ‚Üí [3, 4, 2, 5, 8] Compare 4 \u0026amp; 2 ‚Üí Swap ‚Üí [3, 2, 4, 5, 8] Pass 4: Compare 3 \u0026amp; 2 ‚Üí Swap ‚Üí [2, 3, 4, 5, 8] Final: [2, 3, 4, 5, 8] flowchart TD A[\u0026#34;Start BubbleSort\u0026#34;] --\u0026gt; B[\u0026#34;n = len(arr)\u0026#34;] B --\u0026gt; C[\u0026#34;Loop i from 0 to n-1\u0026#34;] C --\u0026gt; D[\u0026#34;swapped = false\u0026#34;] D --\u0026gt; E[\u0026#34;Loop j from 0 to n-i-2\u0026#34;] E --\u0026gt; F{\u0026#34;arr[j] \u0026gt; arr[j+1]?\u0026#34;} F --\u0026gt;|Yes| G[\u0026#34;Swap arr[j] and arr[j+1]\u0026#34;] G --\u0026gt; H[\u0026#34;swapped = true\u0026#34;] F --\u0026gt;|No| I[\u0026#34;j++\u0026#34;] H --\u0026gt; I I --\u0026gt; J{\u0026#34;j \u0026lt; n-i-1?\u0026#34;} J --\u0026gt;|Yes| E J --\u0026gt;|No| K{\u0026#34;swapped?\u0026#34;} K --\u0026gt;|Yes| L[\u0026#34;i++\u0026#34;] K --\u0026gt;|No| M[\u0026#34;Break outer loop\u0026#34;] L --\u0026gt; N{\u0026#34;i \u0026lt; n?\u0026#34;} N --\u0026gt;|Yes| C N --\u0026gt;|No| O[\u0026#34;End\u0026#34;] M --\u0026gt; O subgraph \u0026#34;Time Complexity Growth\u0026#34; P[\u0026#34;Elements: 10\u0026#34;] --\u0026gt; Q[\u0026#34;Comparisons: ~45\u0026#34;] R[\u0026#34;Elements: 100\u0026#34;] --\u0026gt; S[\u0026#34;Comparisons: ~4,950\u0026#34;] T[\u0026#34;Elements: 1,000\u0026#34;] --\u0026gt; U[\u0026#34;Comparisons: ~499,500\u0026#34;] end style A fill:#1a237e,stroke:#3949ab,color:#e8eaf6 style B fill:#004d40,stroke:#00796b,color:#e0f2f1 style C fill:#004d40,stroke:#00796b,color:#e0f2f1 style D fill:#004d40,stroke:#00796b,color:#e0f2f1 style E fill:#004d40,stroke:#00796b,color:#e0f2f1 style F fill:#b71c1c,stroke:#e53935,color:#ffebee style G fill:#004d40,stroke:#00796b,color:#e0f2f1 style H fill:#004d40,stroke:#00796b,color:#e0f2f1 style I fill:#004d40,stroke:#00796b,color:#e0f2f1 style J fill:#b71c1c,stroke:#e53935,color:#ffebee style K fill:#b71c1c,stroke:#e53935,color:#ffebee style L fill:#004d40,stroke:#00796b,color:#e0f2f1 style M fill:#004d40,stroke:#00796b,color:#e0f2f1 style N fill:#b71c1c,stroke:#e53935,color:#ffebee style O fill:#311b92,stroke:#5e35b1,color:#ede7f6 style P fill:#4a148c,stroke:#7b1fa2,color:#f3e5f5 style Q fill:#4a148c,stroke:#7b1fa2,color:#f3e5f5 style R fill:#01579b,stroke:#0288d1,color:#e1f5fe style S fill:#01579b,stroke:#0288d1,color:#e1f5fe style T fill:#3e2723,stroke:#6d4c41,color:#efebe9 style U fill:#3e2723,stroke:#6d4c41,color:#efebe9 üö® Caution Quadratic algorithms become impractical very quickly. For n = 1,000, a bubble sort performs nearly 500,000 comparisons. For n = 1,000,000, it would require about 500 billion comparisons! This is why we almost never use bubble sort in production code (or do we?).\nDespite their inefficiency, quadratic algorithms sometimes appear in code bases:\nWhen processing small datasets where the simplicity of implementation outweighs performance concerns When the nested loops perform constant-time operations, making the code appear simpler In legacy code (languishing) that hasn\u0026rsquo;t been optimized Always be suspicious of nested loops in performance-critical code paths, as they often indicate O(n¬≤) complexity.\nPractical Performance Comparison # To drive home the dramatic differences between these complexity classes, let\u0026rsquo;s look at how they scale with input size:\nInput Size O(1) O(log n) O(n) O(n log n) O(n¬≤) 10 1 3 10 30 100 100 1 7 100 700 10,000 1,000 1 10 1,000 10,000 1,000,000 1,000,000 1 20 1,000,000 20,000,000 1,000,000,000,000 Notice how the O(n¬≤) algorithm becomes completely impractical for large inputs, while O(log n) barely increases as the input size explodes. This is why binary search on a sorted array of 1 billion items still completes almost instantly, while a bubble sort would take years on the same data.\nGo Standard Library Performance Tips # The Go standard library was designed with performance in mind, and its implementations often use clever optimizations to achieve better-than-expected performance:\nüìå Important Go\u0026rsquo;s slice and map operations have specific performance characteristics you should know:\nappend() is amortized O(1) per element, though occasionally it requires O(n) work for resizing Map iterations with range are O(n) but in random order by design sort.Sort() uses introsort, a hybrid algorithm with O(n log n) complexity copy() is O(n) where n is the minimum of the destination and source slice lengths Beyond Big-O: The Devil in the Details # While Big-O notation is crucial, it doesn\u0026rsquo;t tell the whole story:\nConstants matter: An O(n) algorithm with a high constant factor might be slower than an O(n log n) algorithm for practical input sizes Memory access patterns: Go\u0026rsquo;s slice operations are efficient partly because they leverage CPU cache locality Best/average/worst case: Some algorithms have different complexity in different scenarios For example, Go\u0026rsquo;s map lookup is O(1) on average but could degrade to O(n) in the worst case with pathological hash collisions. In practice, this almost never happens due to Go\u0026rsquo;s implementation details.\nWhen to Optimize? # üí° Tip Choosing the right algorithm from the start isn\u0026rsquo;t premature optimization‚Äîit\u0026rsquo;s good engineering. You can refactor inefficient code, but you can\u0026rsquo;t refactor a crashed production system while it\u0026rsquo;s broken! In Go, the general approach should be:\nChoose algorithms with appropriate complexity for your expected data scale Write clean, idiomatic Go code Profile to identify actual bottlenecks Optimize only where needed Conclusion # Understanding Big-O notation is a foundational skill for every Go developer. It helps you make informed decisions about algorithm selection and predict how your application will scale as data grows.\nIn the next part of this series, we\u0026rsquo;ll dive deeper into data structures and algorithms in Go!\nUntil then, remember: the difference between O(n) and O(n¬≤) might be the difference between a system that scales smoothly and one that collapses under load.\nReferences # Big O Cheat Sheet Go Blog: Slices Go Standard Library - sort package YouTube: MIT Introduction to Algorithms Go Documentation - Maps ","date":"Apr 5, 2025","permalink":"https://blog.mikesahari.com/posts/dsa-part1-big-o/","tags":["go","algorithms","performance","big-o","computer-science"],"title":"Mastering DSAs in Go: The Big-O Guide [Part 1]"},{"content":"If you\u0026rsquo;ve been diving into Go programming (or \u0026ldquo;Golang\u0026rdquo; as the cool kids say), you\u0026rsquo;ve definitely encountered structs. They\u0026rsquo;re absolutely fundamental to how we organize and work with data in Go, and mastering them is crucial to writing clean, efficient Go code.\nI like to teach about structs, like other fundamentals, because of how powerful structs can be when used properly. Let\u0026rsquo;s break down everything you need to know about structs, from the very basics to some advanced patterns I\u0026rsquo;ve learned the hard way.\nWhat Are Structs in Go? # At their core, structs in Go are composite data types that group together variables (called fields) under a single name. If you\u0026rsquo;re coming from object-oriented languages, you might think of them as similar to classes, but with some key differences that make Go\u0026hellip; well, Go!\nüìù Note Unlike classes in OOP languages, Go structs don\u0026rsquo;t support inheritance. This is by design - Go favors composition over inheritance, which leads to more straightforward, less entangled code. Let\u0026rsquo;s visualize the basic concept of a struct:\ngraph TD A[\u0026#34;Struct: Person\u0026#34;] --\u0026gt; B[\u0026#34;Field: Name (string)\u0026#34;] A --\u0026gt; C[\u0026#34;Field: Age (int)\u0026#34;] A --\u0026gt; D[\u0026#34;Field: Address (string)\u0026#34;] style A fill:#BB2528,color:#fff style B fill:#006100,color:#fff style C fill:#006100,color:#fff style D fill:#006100,color:#fff In Go, structs serve several important purposes:\nGrouping related data together Creating custom types Implementing interfaces Enabling method attachment Providing encapsulation Setting Up a Go Project with Structs # Let\u0026rsquo;s start by setting up a simple Go project where we\u0026rsquo;ll explore structs. First, create a new directory and initialize a Go module:\nmkdir go-structs-tutorial cd go-structs-tutorial go mod init github.com/yourusername/go-structs-tutorial Now, let\u0026rsquo;s create our first file with a basic struct example:\nmain.go\npackage main import ( \u0026#34;fmt\u0026#34; ) // Person is a struct that represents a human type Person struct { Name string Age int Address string } func main() { // Creating a new Person p := Person{ Name: \u0026#34;John Doe\u0026#34;, Age: 30, Address: \u0026#34;123 Main St\u0026#34;, } fmt.Println(\u0026#34;Person:\u0026#34;, p) } Run the code with:\ngo run main.go And you should see output like:\nPerson: {John Doe 30 123 Main St} Basic Usage of Structs # Now that we understand what structs are, let\u0026rsquo;s explore some common ways to use them.\nDeclaring and Initializing Structs # There are several ways to create structs in Go:\nexamples/initialization.go\npackage main import \u0026#34;fmt\u0026#34; type Employee struct { ID int FirstName string LastName string Role string } func main() { // Method 1: Specify all fields in order emp1 := Employee{1, \u0026#34;Jacob\u0026#34;, \u0026#34;Strawberry\u0026#34;, \u0026#34;Developer\u0026#34;} // Method 2: Use field names (recommended for clarity) emp2 := Employee{ ID: 2, FirstName: \u0026#34;Theo\u0026#34;, LastName: \u0026#34;Mahindra\u0026#34;, Role: \u0026#34;SRE\u0026#34;, } // Method 3: Create an empty struct and assign fields later var emp3 Employee emp3.ID = 3 emp3.FirstName = \u0026#34;Michael\u0026#34; emp3.LastName = \u0026#34;Michaelson\u0026#34; emp3.Role = \u0026#34;Manager\u0026#34; // Method 4: Using the new() function (returns a pointer) emp4 := new(Employee) emp4.ID = 4 emp4.FirstName = \u0026#34;Sarah\u0026#34; emp4.LastName = \u0026#34;Conner\u0026#34; emp4.Role = \u0026#34;Director\u0026#34; fmt.Println(\u0026#34;Employee 1:\u0026#34;, emp1) fmt.Println(\u0026#34;Employee 2:\u0026#34;, emp2) fmt.Println(\u0026#34;Employee 3:\u0026#34;, emp3) fmt.Println(\u0026#34;Employee 4:\u0026#34;, *emp4) // Dereference the pointer } üí° Tip Always use the field-name syntax when initializing structs with many fields. It makes your code more readable and protects against errors when struct definitions change. Accessing and Modifying Struct Fields # Accessing struct fields is straightforward using the dot notation:\nexamples/accessing.go\npackage main import \u0026#34;fmt\u0026#34; type Product struct { ID string Name string Price float64 InStock bool Quantity int } func main() { product := Product{ ID: \u0026#34;p123\u0026#34;, Name: \u0026#34;Mechanical Keyboard\u0026#34;, Price: 149.99, InStock: true, Quantity: 10, } // Accessing fields fmt.Println(\u0026#34;Product Name:\u0026#34;, product.Name) fmt.Println(\u0026#34;Price:\u0026#34;, product.Price) // Modifying fields product.Price = 129.99 product.Quantity = 8 fmt.Println(\u0026#34;Updated Product:\u0026#34;, product) } Nested Structs # Structs can be embedded within other structs, allowing for complex data structures:\nexamples/nested.go\npackage main import \u0026#34;fmt\u0026#34; type Address struct { Street string City string State string ZipCode string Country string } type Contact struct { Email string Phone string } type Customer struct { ID int Name string Address Address Contact Contact } func main() { customer := Customer{ ID: 1001, Name: \u0026#34;Alice Wonderlund\u0026#34;, Address: Address{ Street: \u0026#34;456 Park Ave\u0026#34;, City: \u0026#34;New York\u0026#34;, State: \u0026#34;NY\u0026#34;, ZipCode: \u0026#34;10022\u0026#34;, Country: \u0026#34;USA\u0026#34;, }, Contact: Contact{ Email: \u0026#34;alice@example.com\u0026#34;, Phone: \u0026#34;212-867-5309\u0026#34;, }, } fmt.Println(\u0026#34;Customer:\u0026#34;, customer.Name) fmt.Println(\u0026#34;Lives in:\u0026#34;, customer.Address.City) fmt.Println(\u0026#34;Contact via:\u0026#34;, customer.Contact.Email) } Advanced Struct Techniques # Now let\u0026rsquo;s flex with some more intermediate to advanced concepts that make structs in Go truly powerful.\nStruct Embedding and Composition # Go promotes composition over inheritance, and struct embedding is one of the main tools for this:\nexamples/embedding.go\npackage main import \u0026#34;fmt\u0026#34; type Entity struct { ID int CreatedAt string UpdatedAt string } // User embeds Entity type User struct { Entity // Embedded struct (anonymous field) Username string Email string PasswordHash string } // Post embeds Entity type Post struct { Entity // Same embedded struct Title string Content string AuthorID int } func main() { user := User{ Entity: Entity{ ID: 1, CreatedAt: \u0026#34;2025-03-26T10:00:00Z\u0026#34;, UpdatedAt: \u0026#34;2025-03-26T10:00:00Z\u0026#34;, }, Username: \u0026#34;gopher\u0026#34;, Email: \u0026#34;gopher@golang.org\u0026#34;, PasswordHash: \u0026#34;hash123\u0026#34;, } // Direct access to embedded fields fmt.Println(\u0026#34;User ID:\u0026#34;, user.ID) // Not user.Entity.ID fmt.Println(\u0026#34;Username:\u0026#34;, user.Username) post := Post{ Entity: Entity{ ID: 101, CreatedAt: \u0026#34;2025-03-26T11:30:00Z\u0026#34;, UpdatedAt: \u0026#34;2025-03-26T11:30:00Z\u0026#34;, }, Title: \u0026#34;Understanding Go Structs\u0026#34;, Content: \u0026#34;Go structs are awesome...\u0026#34;, AuthorID: user.ID, } fmt.Println(\u0026#34;Post Title:\u0026#34;, post.Title) fmt.Println(\u0026#34;Created At:\u0026#34;, post.CreatedAt) } üìå Important With embedded structs, the fields of the embedded struct become \u0026ldquo;promoted\u0026rdquo; to the outer struct, allowing direct access. This is a powerful feature for building composable types in Go. Adding Methods to Structs # One of the most powerful features of structs is the ability to attach methods to them:\nexamples/methods.go\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) type Rectangle struct { Width float64 Height float64 } // Area is a method of Rectangle func (r Rectangle) Area() float64 { return r.Width * r.Height } // Perimeter is a method of Rectangle func (r Rectangle) Perimeter() float64 { return 2 * (r.Width + r.Height) } // Scale modifies the receiver func (r *Rectangle) Scale(factor float64) { r.Width *= factor r.Height *= factor } type Person struct { FirstName string LastName string Age int } // FullName returns the person\u0026#39;s full name func (p Person) FullName() string { return p.FirstName + \u0026#34; \u0026#34; + p.LastName } // IsAdult checks if the person is an adult func (p Person) IsAdult() bool { return p.Age \u0026gt;= 18 } func main() { rect := Rectangle{Width: 10, Height: 5} fmt.Printf(\u0026#34;Rectangle: %+v\\n\u0026#34;, rect) fmt.Println(\u0026#34;Area:\u0026#34;, rect.Area()) fmt.Println(\u0026#34;Perimeter:\u0026#34;, rect.Perimeter()) rect.Scale(2) fmt.Printf(\u0026#34;After scaling: %+v\\n\u0026#34;, rect) fmt.Println(\u0026#34;New area:\u0026#34;, rect.Area()) person := Person{ FirstName: \u0026#34;Go\u0026#34;, LastName: \u0026#34;Gopher\u0026#34;, Age: 13, } fmt.Println(\u0026#34;Name:\u0026#34;, person.FullName()) fmt.Println(\u0026#34;Is adult:\u0026#34;, person.IsAdult()) } The difference between value receivers and pointer receivers is crucial to understand:\ngraph TD A[\u0026#34;Method Receivers in Go\u0026#34;] --\u0026gt; B[\u0026#34;Value Receiver: func (r Rectangle) Area()\u0026#34;] A --\u0026gt; C[\u0026#34;Pointer Receiver: func (r *Rectangle) Scale()\u0026#34;] B --\u0026gt; D[\u0026#34;Receives a copy of the struct\u0026lt;br\u0026gt;Cannot modify the original struct\u0026lt;br\u0026gt;Good for read-only operations\u0026#34;] C --\u0026gt; E[\u0026#34;Receives a pointer to the struct\u0026lt;br\u0026gt;Can modify the original struct\u0026lt;br\u0026gt;More efficient for large structs\u0026#34;] style A fill:#BB2528,color:#fff style B fill:#006100,color:#fff style C fill:#006100,color:#fff style D fill:#1f2020,color:#ddd style E fill:#1f2020,color:#ddd üí° Tip Use pointer receivers when you need to modify the struct or when the struct is large to avoid copying. Use value receivers for immutable operations on smaller structs. Another diagram to visualize this would be:\ngraph TD subgraph \u0026#34;Go Method Receivers\u0026#34; direction TB subgraph \u0026#34;Value Receiver: func (r Rectangle) Area() float64\u0026#34; direction TB A1[Original Rectangle\u0026lt;br\u0026gt;Width: 10\u0026lt;br\u0026gt;Height: 5] --\u0026gt; |\u0026#34;Call Area()\u0026#34;| B1[Copy created\u0026lt;br\u0026gt;Width: 10\u0026lt;br\u0026gt;Height: 5] B1 --\u0026gt; |\u0026#34;Calculate\u0026lt;br\u0026gt;10 √ó 5\u0026#34;| C1[Return 50] A1 --\u0026gt; |\u0026#34;After method call\u0026#34;| D1[Original unchanged\u0026lt;br\u0026gt;Width: 10\u0026lt;br\u0026gt;Height: 5] style A1 fill:#00ADD8,color:#fff,stroke:#0078A0,stroke-width:2px style B1 fill:#5DC9A3,color:#fff,stroke:#3DAD83,stroke-width:2px style C1 fill:#F9A825,color:#fff,stroke:#F57F17,stroke-width:2px style D1 fill:#00ADD8,color:#fff,stroke:#0078A0,stroke-width:2px end subgraph \u0026#34;Pointer Receiver: func (r *Rectangle) Scale(factor float64)\u0026#34; direction TB A2[Original Rectangle\u0026lt;br\u0026gt;Width: 10\u0026lt;br\u0026gt;Height: 5] --\u0026gt; |\u0026#34;Call Scale(2)\u0026#34;| B2[Pointer to original\u0026lt;br\u0026gt;*Rectangle] B2 --\u0026gt; |\u0026#34;Modify through pointer\u0026lt;br\u0026gt;Width = 10 √ó 2\u0026lt;br\u0026gt;Height = 5 √ó 2\u0026#34;| C2[Original modified] C2 --\u0026gt; D2[Rectangle after Scale\u0026lt;br\u0026gt;Width: 20\u0026lt;br\u0026gt;Height: 10] style A2 fill:#00ADD8,color:#fff,stroke:#0078A0,stroke-width:2px style B2 fill:#9C27B0,color:#fff,stroke:#7B1FA2,stroke-width:2px style C2 fill:#E53935,color:#fff,stroke:#C62828,stroke-width:2px style D2 fill:#00ADD8,color:#fff,stroke:#0078A0,stroke-width:2px end end classDef default font-size:14px,font-family:Arial; Event Sourcing with Structs # Let\u0026rsquo;s build a more complex example to demonstrate the power of structs in a real-world scenario (or perhaps a coding exam). For example, you get tasked to build a banking system. It must handle opening an account, depositing money, and withdrawing money. We\u0026rsquo;ll implement a simple event sourcing system for the bank system here:\nexamples/event_sourcing.go\npackage main import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) // Event represents a domain event type Event struct { ID string Type string Timestamp time.Time Data map[string]interface{} } // Account represents a bank account type Account struct { ID string Owner string Balance float64 OpenedAt time.Time Events []Event EventHandlers map[string]func(*Account, Event) error } // NewAccount creates a new account func NewAccount(id, owner string, initialBalance float64) *Account { now := time.Now() account := \u0026amp;Account{ ID: id, Owner: owner, Balance: 0, OpenedAt: now, Events: []Event{}, EventHandlers: map[string]func(*Account, Event) error{ \u0026#34;account_opened\u0026#34;: handleAccountOpened, \u0026#34;money_deposited\u0026#34;: handleMoneyDeposited, \u0026#34;money_withdrawn\u0026#34;: handleMoneyWithdrawn, }, } // Create and apply the account_opened event account.ApplyEvent(Event{ ID: fmt.Sprintf(\u0026#34;%s-1\u0026#34;, id), Type: \u0026#34;account_opened\u0026#34;, Timestamp: now, Data: map[string]interface{}{ \u0026#34;owner\u0026#34;: owner, \u0026#34;initial_balance\u0026#34;: initialBalance, }, }) return account } // ApplyEvent applies an event to the account func (a *Account) ApplyEvent(event Event) error { handlerFunc, exists := a.EventHandlers[event.Type] if !exists { return errors.New(\u0026#34;unknown event type\u0026#34;) } if err := handlerFunc(a, event); err != nil { return err } // Store the event a.Events = append(a.Events, event) return nil } // Deposit adds money to the account func (a *Account) Deposit(amount float64) error { if amount \u0026lt;= 0 { return errors.New(\u0026#34;deposit amount must be positive\u0026#34;) } return a.ApplyEvent(Event{ ID: fmt.Sprintf(\u0026#34;%s-%d\u0026#34;, a.ID, len(a.Events)+1), Type: \u0026#34;money_deposited\u0026#34;, Timestamp: time.Now(), Data: map[string]interface{}{ \u0026#34;amount\u0026#34;: amount, }, }) } // Withdraw removes money from the account func (a *Account) Withdraw(amount float64) error { if amount \u0026lt;= 0 { return errors.New(\u0026#34;withdrawal amount must be positive\u0026#34;) } if a.Balance \u0026lt; amount { return errors.New(\u0026#34;insufficient funds\u0026#34;) } return a.ApplyEvent(Event{ ID: fmt.Sprintf(\u0026#34;%s-%d\u0026#34;, a.ID, len(a.Events)+1), Type: \u0026#34;money_withdrawn\u0026#34;, Timestamp: time.Now(), Data: map[string]interface{}{ \u0026#34;amount\u0026#34;: amount, }, }) } // Event handlers func handleAccountOpened(a *Account, e Event) error { a.Owner = e.Data[\u0026#34;owner\u0026#34;].(string) a.Balance = e.Data[\u0026#34;initial_balance\u0026#34;].(float64) return nil } func handleMoneyDeposited(a *Account, e Event) error { amount := e.Data[\u0026#34;amount\u0026#34;].(float64) a.Balance += amount return nil } func handleMoneyWithdrawn(a *Account, e Event) error { amount := e.Data[\u0026#34;amount\u0026#34;].(float64) if a.Balance \u0026lt; amount { return errors.New(\u0026#34;insufficient funds\u0026#34;) } a.Balance -= amount return nil } // Reconstruct rebuilds the account state from events func ReconstructAccount(id string, events []Event) (*Account, error) { if len(events) == 0 { return nil, errors.New(\u0026#34;no events to reconstruct from\u0026#34;) } // Create a blank account account := \u0026amp;Account{ ID: id, EventHandlers: map[string]func(*Account, Event) error{ \u0026#34;account_opened\u0026#34;: handleAccountOpened, \u0026#34;money_deposited\u0026#34;: handleMoneyDeposited, \u0026#34;money_withdrawn\u0026#34;: handleMoneyWithdrawn, }, } // Apply all events for _, event := range events { handlerFunc, exists := account.EventHandlers[event.Type] if !exists { return nil, errors.New(\u0026#34;unknown event type\u0026#34;) } if err := handlerFunc(account, event); err != nil { return nil, err } account.Events = append(account.Events, event) } return account, nil } func main() { // Create a new account account := NewAccount(\u0026#34;acc123\u0026#34;, \u0026#34;John Doe\u0026#34;, 1000.00) fmt.Printf(\u0026#34;Account created: %+v\\n\u0026#34;, account) // Deposit some $$ err := account.Deposit(500.00) if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err) } // Now withdraw some $$ err = account.Withdraw(200.00) if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err) } fmt.Printf(\u0026#34;Final account state: %+v\\n\u0026#34;, account) fmt.Println(\u0026#34;Balance:\u0026#34;, account.Balance) fmt.Println(\u0026#34;Number of events:\u0026#34;, len(account.Events)) // Show event history fmt.Println(\u0026#34;\\nEvent History:\u0026#34;) for i, event := range account.Events { fmt.Printf(\u0026#34;%d: [%s] %s at %s\\n\u0026#34;, i+1, event.Type, event.ID, event.Timestamp.Format(time.RFC3339), ) } // Demonstrate reconstruction fmt.Println(\u0026#34;\\nReconstructing account from events...\u0026#34;) reconstructedAccount, err := ReconstructAccount(\u0026#34;acc123\u0026#34;, account.Events) if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err) } else { fmt.Printf(\u0026#34;Reconstructed account: %+v\\n\u0026#34;, reconstructedAccount) fmt.Println(\u0026#34;Reconstructed balance:\u0026#34;, reconstructedAccount.Balance) } } This example demonstrates some powerful features of Go structs:\nComposition of different data types Method receivers to implement behavior Using maps to store function handlers Complex business logic using structs The event sourcing pattern is perfect for showing how structs can model both data and behavior in Go applications.\nWrapping Up # Structs are one of Go\u0026rsquo;s most fundamental and powerful features. They provide a clean, efficient way to structure your data and implement behavior in Go applications.\nWe\u0026rsquo;ve covered:\nBasic struct definition and initialization Accessing and modifying struct fields Nested and embedded structs Adding methods to structs Advanced patterns with a real-world example Remember, in Go, composition is favored over inheritance, and structs are the primary tool for composition. Mastering structs will take your Go programming to the next level.\nüìù Note While structs are incredibly powerful, they\u0026rsquo;re just one part of Go\u0026rsquo;s type system. Interfaces work hand-in-hand with structs to create flexible, decoupled code. Consider exploring interfaces as your next step in mastering Go. References # Go Documentation - Structs Go Tour - Structs Go by Example: Structs The Go Programming Language Specification ","date":"Mar 28, 2025","permalink":"https://blog.mikesahari.com/posts/go-structs/","tags":["go","programming","data-structures","fundamentals"],"title":"Structs Fundamentals: From Basics to Advanced Usage"},{"content":"I\u0026rsquo;ve been working on a handful of personal webdev Go projects, and the one thing I could never wrap my head around was Templ. I would start the project and go, \u0026ldquo;Oh no. I need a UI for this. Not everything can be made into a TUI\u0026hellip; or can it..\u0026rdquo;. This would lead me to looking at the Templ docs, not understanding how to implement it, and either use the embed package (I LOVE embed!) or starting a TypeScript frontend, creating a bunch of tsx files and coming to the sudden realization that I gave in to React.\nTempl brings type-safe, component-based HTML templating to the Go ecosystem. When paired with HTMX (Yes, I did try the GoTH stack sans Templ and thoroughly enjoyed it), it creates a powerful combination for building interactive web applications with minimal JavaScript.\nFor those of us who appreciate Go\u0026rsquo;s simplicity and performance but struggle with the frontend story, Templ represents something of a holy grail. It\u0026rsquo;s the missing puzzle piece that completes the picture of what modern Go web development can be.\nBefore discovering Templ, I bounced between various unsatisfying options:\nStandard library templates: Powerful but stringly-typed and prone to runtime errors Pure JavaScript frontends: \u0026ldquo;Two applications\u0026rdquo; syndrome Embedding HTML (and raw handcrafted artisan JS): Simple but not scalable or maintainable Each approach left me feeling like I was making a compromise. Templ finally offered a path that felt aligned with Go\u0026rsquo;s philosophy ‚Äì strong typing, compile-time validation, and composition over inheritance.\nI\u0026rsquo;m still early in my journey with Templ, but for the first time, I feel like I\u0026rsquo;m building web UIs the \u0026ldquo;Go way\u0026rdquo; instead of fighting against the language or surrendering to the JavaScript ecosystem. And that feels right.\nWhat is Templ? # Templ is a templating language and compiler for Go that focuses on type safety and composition. Unlike traditional templating engines that rely on string-based templates, Templ treats templates as first-class Go code.\nHere\u0026rsquo;s what makes Templ stand out from the crowd:\nType Safety: Templ templates are compiled to Go code, which means type errors are caught at compile-time, not runtime. Component-Based: If you\u0026rsquo;re used to the whole component structure, you\u0026rsquo;ll love this. Build reusable components that compose together naturally. Go Integration: Seamlessly integrate with your existing Go code and ecosystem. Performance: Templates compile down to efficient Go code that renders the HTML. HTMX-Friendly: Pairs perfectly with HTMX for building interactive interfaces with minimal JavaScript. Installation and Project Setup # Getting started with Templ is straightforward. You\u0026rsquo;ll need two things:\nThe Templ command-line tool (compiler) The Templ runtime library Let\u0026rsquo;s install both:\n# Install the Templ CLI go install github.com/a-h/templ/cmd/templ@latest # Add the runtime to your project go get github.com/a-h/templ Project Structure # From a high-level, our Templ project structure will look similar to this (sans the actual completed server for this blog post):\nexample-templ-project/ ‚îú‚îÄ‚îÄ cmd/ ‚îÇ ‚îî‚îÄ‚îÄ server/ ‚îÇ ‚îî‚îÄ‚îÄ main.go # Application entry point ‚îú‚îÄ‚îÄ internal/ ‚îÇ ‚îú‚îÄ‚îÄ components/ # Generated Go code (don\u0026#39;t edit these!) ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ views_templ.go ‚îÇ ‚îú‚îÄ‚îÄ handlers/ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ http.go # HTTP handlers ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ routes.go # Route setup ‚îÇ ‚îú‚îÄ‚îÄ models/ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ model.go # Domain models ‚îÇ ‚îú‚îÄ‚îÄ services/ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ service.go # Business logic ‚îÇ ‚îî‚îÄ‚îÄ views/ # Generated Go code (don\u0026#39;t edit these!) ‚îÇ ‚îî‚îÄ‚îÄ views_templ.go ‚îú‚îÄ‚îÄ scripts/ # Includes any bash scripts for build/gen ‚îú‚îÄ‚îÄ templates/ ‚îÇ ‚îú‚îÄ‚îÄ components/ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ card.templ # Reusable UI components ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ layout.templ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ nav.templ ‚îÇ ‚îú‚îÄ‚îÄ pages/ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ home.templ # Page templates ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ about.templ ‚îÇ ‚îî‚îÄ‚îÄ views/ # Content ‚îÇ ‚îú‚îÄ‚îÄ sample.templ ‚îÇ ‚îî‚îÄ‚îÄ content.templ ‚îú‚îÄ‚îÄ .air.toml ‚îú‚îÄ‚îÄ .gitignore ‚îú‚îÄ‚îÄ go.mod ‚îú‚îÄ‚îÄ go.sum ‚îî‚îÄ‚îÄ Makefile üí° Tip Keep your .templ files and their generated .go files in separate packages to avoid circular dependencies. The generated code should be in a different package from your application code. In a Go + Templ project, it\u0026rsquo;s important to follow these principles:\nSeparation of Concerns: Keep templates, handlers, and business logic separated Component-Based Design: Break down UIs into reusable components Clean Generation: Generated code should be ignored in version control Idiomatic Go: Follow standard Go project layouts and conventions To make this process easier, let\u0026rsquo;s create the following:\nA generate-templ.sh for generating .templ files and putting our templated _templ.go files under our internal/ directory. A Makefile to simplify our all our commands. A .air.toml for using Air to hot reload our app as we work on it. Scripting Templ Generating # First let\u0026rsquo;s create the script.\nmkdir -p scripts touch scripts/generate-templ.sh chmod +x scripts/generate-templ.sh And inside the script you\u0026rsquo;ll want to add the following contents:\n#!/bin/bash # Find all templ files find ./templates -name \u0026#34;*.templ\u0026#34; | while read -r src_file; do # Calculate destination path rel_path=${src_file#./templates/} dir_name=$(dirname \u0026#34;$rel_path\u0026#34;) file_name=$(basename \u0026#34;$rel_path\u0026#34;) dest_dir=\u0026#34;./internal/$dir_name\u0026#34; # Create output directory mkdir -p \u0026#34;$dest_dir\u0026#34; # Run templ on the file and capture output templ generate -f \u0026#34;$src_file\u0026#34; -stdout \u0026gt; \u0026#34;$dest_dir/${file_name%.templ}_templ.go\u0026#34; done This simple script will make it easy to generate the files from templates/ to internal/.\nSetting up the Makefile # Now you\u0026rsquo;ll want to add the compilation step to your build process. Let\u0026rsquo;s create a Makefile under the root of the directory. A good Makefile might look like this:\n.PHONY: generate build run clean dev generate: ./scripts/generate-templ.sh build: generate go build -o bin/server ./cmd/server run: build ./bin/server # Default example if none specified # This is added because our example project will have multiple cmd targets # Usage: make dev CMD_DIR=greeting-example CMD_DIR ?= server dev: CMD_DIR=$(CMD_DIR) air clean: rm -rf bin/ find ./templates -name \u0026#34;*_templ.go\u0026#34; -type f -delete Now we can run make generate over and over and over. Although, this next step will make it unnecessary with the use of Air.\nSetup Air TOML # üí° Tip Many developers use Air for hot reloading during development. It can be configured to recompile your Templ files and restart your server when changes are detected. First we want to install Air.\ngo install github.com/air-verse/air@latest And now create the .air.toml in the root directory. The contents will look like:\nroot = \u0026#34;.\u0026#34; tmp_dir = \u0026#34;tmp\u0026#34; [build] cmd = \u0026#34;./scripts/generate-templ.sh \u0026amp;\u0026amp; go build -o ./tmp/main ./cmd/${CMD_DIR}\u0026#34; bin = \u0026#34;./tmp/main\u0026#34; include_ext = [\u0026#34;go\u0026#34;, \u0026#34;templ\u0026#34;] exclude_regex = [\u0026#34;_templ.go\u0026#34;] delay = 1000 exclude_dir = [\u0026#34;assets\u0026#34;, \u0026#34;tmp\u0026#34;, \u0026#34;vendor\u0026#34;] [screen] clear_on_rebuild = true This config will let us generate and build every time the files are modified. It leverages our bash script and makes it dynamic for the multiple commands that we will be creating under cmd/.\nCoding the Project # Let\u0026rsquo;s start with some basic examples to get a feel for how Templ works with some cat-themed examples.\nYour First Templ View # Create a file named greeting.templ under templates/views/:\nmkdir -p templates/views touch templates/views/greeting.templ Create the following content:\n// Create this under `templates/views/greeting.templ` package views templ CatGreeting(catName string) { \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Hello, {catName}!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Welcome to the Templ demo\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; } Run the Templ compiler to generate Go code:\nmake generate This will create a file called greeting_templ.go (found under internal/views/) that contains the compiled Go code for your template.\nNow you can use your template in a Go HTTP handler. Let\u0026rsquo;s create a main.go to test our code. Let\u0026rsquo;s do some setup.\nmkdir -p cmd/greeting-example touch cmd/greeting-example/main.go Inside the contents:\n// Remember to create under `cmd/greeting-example/main.go` package main import ( \u0026#34;net/http\u0026#34; \u0026#34;example-templ-project/templates/views\u0026#34; \u0026#34;github.com/a-h/templ\u0026#34; ) func main() { http.Handle(\u0026#34;/\u0026#34;, templ.Handler(views.CatGreeting(\u0026#34;Whiskers\u0026#34;))) http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) } And now we can run it with:\nmake dev CMD_DIR=greeting-example Visiting localhost:8080 in your browser will show off our example!\nComponent Composition # One of Templ\u0026rsquo;s strengths is composition. Here\u0026rsquo;s how you can compose templates. First let\u0026rsquo;s create a component:\nmkdir -p templates/components touch templates/components/layout.templ Add the following content to create our reusable component under templates/components/layout.templ:\npackage components templ CatLayout(title string) { \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;{title}\u0026lt;/title\u0026gt; \u0026lt;!-- HTMX for interactivity without JavaScript --\u0026gt; \u0026lt;script src=\u0026#34;https://unpkg.com/htmx.org@1.9.6\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; body { font-family: system-ui, sans-serif; max-width: 800px; margin: 0 auto; padding: 1rem; background-color: #fffaf5; } .cat-container { border: 2px solid #ffb74d; border-radius: 8px; padding: 1rem; margin-bottom: 1rem; } .cat-paw { cursor: pointer; display: inline-block; transition: transform 0.2s; } .cat-paw:hover { transform: rotate(10deg); } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;header\u0026gt; \u0026lt;span class=\u0026#34;cat-paw\u0026#34;\u0026gt;üêæ\u0026lt;/span\u0026gt; \u0026lt;strong\u0026gt;Templ Demo\u0026lt;/strong\u0026gt; \u0026lt;/header\u0026gt; { children... } \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; } This will allow us to add HTMX and a simple box. Now let\u0026rsquo;s use our component in a view! Create templates/views/composition.templ:\npackage views import \u0026#34;example-templ-project/internal/components\u0026#34; templ CatContent(title string) { @components.CatLayout(title) { \u0026lt;main\u0026gt; \u0026lt;div class=\u0026#34;cat-container\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Welcome to my catalog of templates\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This is an amazing demo of Templ with HTMX.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/main\u0026gt; } } Now let\u0026rsquo;s test it all with an example command. Create the following cmd/composition-example/main.go with the following content:\npackage main import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/a-h/templ\u0026#34; \u0026#34;example-templ-project/internal/views\u0026#34; ) func main() { http.Handle(\u0026#34;/\u0026#34;, templ.Handler(views.CatContent(\u0026#34;Cat Page!\u0026#34;))) http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) } We can run this on localhost:8080 with:\nmake dev CMD_DIR=composition-example Here\u0026rsquo;s a diagram showing the component composition flow:\ngraph TD A[HTTP Request] --\u0026gt; B[Handler] B --\u0026gt; C[Content Component] C --\u0026gt; D[Layout Component] D --\u0026gt; E[Render HTML Response] style A fill:#2D3748,color:#E2E8F0 style B fill:#4A5568,color:#E2E8F0 style C fill:#718096,color:#E2E8F0 style D fill:#A0AEC0,color:#1A202C style E fill:#CBD5E0,color:#1A202C Conditional Rendering # Templ supports conditional rendering using Go\u0026rsquo;s own control structures. For this, let\u0026rsquo;s make use of our compositional to load htmx and let\u0026rsquo;s create a templates/views/conditional.templ:\npackage views import \u0026#34;example-templ-project/internal/components\u0026#34; templ CatTreatingContent(catName string, hasTreats bool) { \u0026lt;div id=\u0026#34;cat-treating\u0026#34; class=\u0026#34;cat-container\u0026#34;\u0026gt; if hasTreats { \u0026lt;h1\u0026gt;Thank you for the treats, {catName}!\u0026lt;/h1\u0026gt; \u0026lt;div\u0026gt; \u0026lt;span\u0026gt;üòª Happy cat is happy!\u0026lt;/span\u0026gt; \u0026lt;button hx-post=\u0026#34;/conditional?hasTreats=false\u0026#34; hx-target=\u0026#34;#cat-treating\u0026#34; hx-swap=\u0026#34;outerHTML\u0026#34; class=\u0026#34;treat-button\u0026#34;\u0026gt; Reset \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; } else { \u0026lt;h1\u0026gt;Hello, {catName}!\u0026lt;/h1\u0026gt; \u0026lt;div\u0026gt; \u0026lt;button hx-post=\u0026#34;/conditional?hasTreats=true\u0026#34; hx-target=\u0026#34;#cat-treating\u0026#34; hx-swap=\u0026#34;outerHTML\u0026#34; class=\u0026#34;treat-button\u0026#34;\u0026gt; Give Treats \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; } \u0026lt;/div\u0026gt; } templ CatTreatingPage(catName string, hasTreats bool) { @components.CatLayout(\u0026#34;Treats\u0026#34;) { @CatTreatingContent(catName, hasTreats) } } Next we need to create the example command for this. Setup cmd/iteration-example/main.go to have the following contents:\npackage main import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/a-h/templ\u0026#34; \u0026#34;example-templ-project/internal/views\u0026#34; ) func main() { http.Handle(\u0026#34;/\u0026#34;, templ.Handler(views.CatContent(\u0026#34;Cat Page!\u0026#34;))) http.HandleFunc(\u0026#34;/conditional\u0026#34;, func(w http.ResponseWriter, r *http.Request) { if r.Method == \u0026#34;GET\u0026#34; { // Full page with layout for initial load views.CatTreatingPage(\u0026#34;Whiskers\u0026#34;, false).Render(r.Context(), w) } else { // Just the content for HTMX requests hasTreats := r.URL.Query().Get(\u0026#34;hasTreats\u0026#34;) == \u0026#34;true\u0026#34; views.CatTreatingContent(\u0026#34;Whiskers\u0026#34;, hasTreats).Render(r.Context(), w) } }) http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) } Remember to change the CMD_DIR for testing this.\nmake dev CMD_DIR=conditional-example üìù Note Notice how we\u0026rsquo;ve added an HTMX-powered button that makes a POST request to /conditional and will swap its own HTML with the server response. This is how HTMX enables interactivity without writing JavaScript. Iteration # Iterating over collections is just as intuitive, although this example has quite a bit going on. Let\u0026rsquo;s create templates/views/iteration.templ:\npackage views import ( \u0026#34;fmt\u0026#34; \u0026#34;example-templ-project/internal/components\u0026#34; ) type Cat struct { ID int Name string Breed string Naps int FavToy string } templ CatList(cats []Cat) { \u0026lt;div class=\u0026#34;cat-collection\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;Cat Collection\u0026lt;/h2\u0026gt; \u0026lt;ul\u0026gt; for _, cat := range cats { \u0026lt;li id={\u0026#34;cat-\u0026#34; + fmt.Sprint(cat.ID)} class=\u0026#34;cat-item\u0026#34;\u0026gt; \u0026lt;strong\u0026gt;{cat.Name}\u0026lt;/strong\u0026gt; - {cat.Breed} \u0026lt;div\u0026gt;Naps today: {fmt.Sprintf(\u0026#34;%d\u0026#34;, cat.Naps)}\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt;Favorite toy: {cat.FavToy}\u0026lt;/div\u0026gt; \u0026lt;button hx-get={\u0026#34;/pet-cat/\u0026#34; + fmt.Sprint(cat.ID)} hx-target={\u0026#34;#cat-\u0026#34; + fmt.Sprint(cat.ID)} hx-swap=\u0026#34;outerHTML\u0026#34; \u0026gt; Pet {cat.Name} \u0026lt;/button\u0026gt; \u0026lt;/li\u0026gt; } \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; } templ CatPage(cats []Cat, hasTreats bool) { @components.CatLayout(\u0026#34;Cat Paradise\u0026#34;) { \u0026lt;main\u0026gt; \u0026lt;div id=\u0026#34;treats-section\u0026#34;\u0026gt; @CatTreatingSection(hasTreats) \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;cat-collection\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;Cat Collection\u0026lt;/h2\u0026gt; \u0026lt;ul\u0026gt; for _, cat := range cats { @CatListItem(cat) } \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/main\u0026gt; } } // Treatments section component templ CatTreatingSection(hasTreats bool) { \u0026lt;div id=\u0026#34;treats-section\u0026#34; class=\u0026#34;cat-container\u0026#34;\u0026gt; if hasTreats { \u0026lt;h2\u0026gt;Treats are available! üç§\u0026lt;/h2\u0026gt; \u0026lt;div\u0026gt; \u0026lt;span\u0026gt;üòª All cats are happy!\u0026lt;/span\u0026gt; \u0026lt;button hx-post=\u0026#34;/treats?hasTreats=false\u0026#34; hx-target=\u0026#34;#treats-section\u0026#34; hx-swap=\u0026#34;outerHTML\u0026#34; class=\u0026#34;treat-button\u0026#34;\u0026gt; Put Treats Away \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; } else { \u0026lt;h2\u0026gt;No treats currently\u0026lt;/h2\u0026gt; \u0026lt;div\u0026gt; \u0026lt;button hx-post=\u0026#34;/treats?hasTreats=true\u0026#34; hx-target=\u0026#34;#treats-section\u0026#34; hx-swap=\u0026#34;outerHTML\u0026#34; class=\u0026#34;treat-button\u0026#34;\u0026gt; Give Treats to All Cats \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; } \u0026lt;/div\u0026gt; } // Individual cat item templ CatListItem(cat Cat) { \u0026lt;li id={\u0026#34;cat-\u0026#34; + fmt.Sprint(cat.ID)} class=\u0026#34;cat-item\u0026#34;\u0026gt; \u0026lt;strong\u0026gt;{cat.Name}\u0026lt;/strong\u0026gt; - {cat.Breed} \u0026lt;div\u0026gt;Naps today: {fmt.Sprintf(\u0026#34;%d\u0026#34;, cat.Naps)}\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt;Favorite toy: {cat.FavToy}\u0026lt;/div\u0026gt; \u0026lt;button hx-get={\u0026#34;/pet-cat/\u0026#34; + fmt.Sprint(cat.ID)} hx-target={\u0026#34;#cat-\u0026#34; + fmt.Sprint(cat.ID)} hx-swap=\u0026#34;outerHTML\u0026#34; class=\u0026#34;treat-button\u0026#34; \u0026gt; Pet {cat.Name} \u0026lt;/button\u0026gt; \u0026lt;/li\u0026gt; } Let\u0026rsquo;s setup the cmd/iteration-example/main.go to handle the HTMX requests:\npackage main import ( \u0026#34;net/http\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;example-templ-project/internal/views\u0026#34; ) var ( // This is mock data. Generally you would get and update this data with a database cats = []views.Cat{ {ID: 1, Name: \u0026#34;Finn\u0026#34;, Breed: \u0026#34;Orange\u0026#34;, Naps: 5, FavToy: \u0026#34;Mouse\u0026#34;}, {ID: 2, Name: \u0026#34;Honey\u0026#34;, Breed: \u0026#34;Calico\u0026#34;, Naps: 3, FavToy: \u0026#34;String\u0026#34;}, {ID: 3, Name: \u0026#34;Wonkers\u0026#34;, Breed: \u0026#34;Black\u0026#34;, Naps: 7, FavToy: \u0026#34;Catnip Ball\u0026#34;}, } globalHasTreats = false ) func main() { http.HandleFunc(\u0026#34;/\u0026#34;, handleMainPage) http.HandleFunc(\u0026#34;/pet-cat/\u0026#34;, handlePetCat) http.HandleFunc(\u0026#34;/treats\u0026#34;, handleTreats) http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) } func handleMainPage(w http.ResponseWriter, r *http.Request) { views.CatPage(cats, globalHasTreats).Render(r.Context(), w) } func handlePetCat(w http.ResponseWriter, r *http.Request) { idStr := r.URL.Path[len(\u0026#34;/pet-cat/\u0026#34;):] id, err := strconv.Atoi(idStr) if err != nil { http.Error(w, \u0026#34;Invalid cat ID\u0026#34;, http.StatusBadRequest) return } var targetCat views.Cat var found bool for i, cat := range cats { if cat.ID == id { cats[i].Naps++ targetCat = cats[i] found = true break } } if !found { http.Error(w, \u0026#34;Cat not found\u0026#34;, http.StatusNotFound) return } views.CatListItem(targetCat).Render(r.Context(), w) } func handleTreats(w http.ResponseWriter, r *http.Request) { // Toggle treats state hasTreatsParam := r.URL.Query().Get(\u0026#34;hasTreats\u0026#34;) globalHasTreats = (hasTreatsParam == \u0026#34;true\u0026#34;) views.CatTreatingSection(globalHasTreats).Render(r.Context(), w) } We can see this in action under localhost:8080 with:\nmake dev CMD_DIR=iteration-example Wrap Up # Templ represents a significant step forward for Go web development. By bringing a component-based approach with full type safety to Go templates, it addresses many of the pain points developers have faced with traditional templating solutions.\nWhen combined with HTMX, it creates a powerful stack for building interactive web applications with minimal JavaScript.\nHere\u0026rsquo;s why you should consider Templ and HTMX for your next Go web project:\nMaintainability: Components are modular, reusable, and composable. Performance: Compiled templates are efficient and fast. Integration: Works seamlessly with the standard Go HTTP stack. Interactivity: HTMX enables dynamic interfaces without complex JavaScript frameworks. Whether you\u0026rsquo;re building a simple website or a complex web application, Templ\u0026rsquo;s approach to templating aligns perfectly with Go\u0026rsquo;s philosophy of simplicity, type safety, and performance. The idiomatic project structure ensures your code remains maintainable as it grows, while the combination with HTMX lets you create rich, interactive experiences without the complexity of a full JavaScript framework.\nCheckout the entire project code in my github repo.\nGive Templ and HTMX a try for your next Go web project - I think you\u0026rsquo;ll find it\u0026rsquo;s the templating solution you\u0026rsquo;ve been waiting for!\n","date":"Mar 21, 2025","permalink":"https://blog.mikesahari.com/posts/html-templating/","tags":["html","go","htmx","templating","templ","webdev"],"title":"Modern Templating for Go with Templ"},{"content":"I still remember the moment it clicked. I was knee-deep in refactoring a Go CLI (weekend project) for unit testing with mocks, which had become a tangled mess of dependencies when suddenly ‚Äì ü§Ø ‚Äì the elegance of Go\u0026rsquo;s interface system hit me like a revelation.\nIt has been many years, but I remember programming in C#; where interfaces were verbose constructs that required explicit declarations and implementation hierarchies. But here was Go, silently composing functionality in a way that felt almost magical.\nIf you\u0026rsquo;re coming from other languages, Go\u0026rsquo;s interfaces might seem too simple to be powerful. Trust me, that simplicity is deceptive. It\u0026rsquo;s like discovering that the unassuming Swiss Army knife in your pocket can also transform into a top of the line commercial espresso grinder (I wish this was possible).\nIt can be a hard concept for folks. I still remember at a previous job, a couple of coworkers were complaining to me about another coworker saying, \u0026ldquo;BlahBlah doesn\u0026rsquo;t understand interfaces. Just look at the codebase.\u0026rdquo; My opinion on this is that interfaces should be implemented the way they are designed for their language, and not some anti-pattern. Oh, and yes, BlahBlah did not understand interfaces for the language. They were using an anti-pattern. üòÜ\nInterfaces Across Languages: A Tale of Three Approaches # Let\u0026rsquo;s look at how interfaces work across TypeScript, Python, and Go. This should help show the different ways to implement them. For these examples, I\u0026rsquo;ll use a common thing that engineers will try to interface; a logger!\nTypeScript: Interfaces as Contracts # TypeScript\u0026rsquo;s interfaces can be done multiple ways. Here is an example of using object literals:\n// Define an interface interface Logger { log(message: string): void; error(message: string): void; } // Using an object literal const fileLogger = { log(message: string) { // Write to file: info.log console.log(`[FILE-INFO] ${message}`); }, error(message: string) { // Write to file: error.log console.error(`[FILE-ERROR] ${message}`); } }; // The function demands a Logger function processData(data: string, logger: Logger): void { try { // Process data... logger.log(\u0026#39;Data processed successfully\u0026#39;); } catch (e) { logger.error(`Failed to process data: ${e.message}`); } } // This works! TypeScript uses duck typing to verify that fileLogger matches the Logger interface processData(\u0026#39;some data\u0026#39;, fileLogger); In TypeScript land, you\u0026rsquo;re constantly dealing with:\nExplicit interface declarations Classes that formally implement those interfaces Type annotations everywhere A whole inheritance hierarchy to maintain This explicitness creates tight coupling between your interfaces and implementations. Want to adapt an existing class to work with your interface? Too bad ‚Äì you\u0026rsquo;ll need to either modify it to explicitly implement your interface or create a wrapper class.\nYou basically get the following:\nflowchart TD subgraph \u0026#34;TypeScript\u0026#34; TS_LIB[Library Code] --\u0026gt;|defines| TS_I[Interface] TS_APP[Application Code] --\u0026gt;|implements| TS_I TS_I --\u0026gt;|constrains| TS_APP end style TS_I fill:#3178C6,stroke:#2C6AA8,color:#FFFFFF style TS_LIB fill:#3178C6,stroke:#2C6AA8,color:#FFFFFF style TS_APP fill:#3178C6,stroke:#2C6AA8,color:#FFFFFF Alternatively, you can use the satisfies operator for implicit interfacing:\n// Define an interface interface Logger { log(message: string): void; error(message: string): void; } // Using satisfies to explicitly verify the object is compatible with Logger const customLogger = { log(message: string) { // Custom implementation console.log(`[CUSTOM] ${message}`); }, error(message: string) { // Custom implementation console.error(`[CUSTOM-ERROR] ${message}`); }, // We can have additional methods not in the interface warn(message: string) { console.warn(`[CUSTOM-WARN] ${message}`); } } satisfies Logger; // The function demands a Logger function processData(data: string, logger: Logger): void { try { // Process data... logger.log(\u0026#39;Data processed successfully\u0026#39;); } catch (e) { logger.error(`Failed to process data: ${e.message}`); } } // Works with our custom logger processData(\u0026#39;some data\u0026#39;, customLogger); // We can also still access the extra methods customLogger.warn(\u0026#39;This is a warning\u0026#39;); // This works! Which looks like:\nflowchart TD subgraph \u0026#34;TypeScript with satisfies\u0026#34; TS_LIB[Library Code] --\u0026gt;|defines| TS_I[Interface] TS_APP[Object Literal] --\u0026gt;|satisfies| TS_I TS_I --\u0026gt;|validates against| TS_APP TS_APP --\u0026gt;|retains original\u0026lt;br\u0026gt;literal type| TS_ORIG[Original Type] TS_ORIG --\u0026gt;|enables access to\u0026lt;br\u0026gt;additional methods| TS_EXTRA[Extra Methods] end style TS_I fill:#3178C6,stroke:#2C6AA8,color:#FFFFFF style TS_LIB fill:#3178C6,stroke:#2C6AA8,color:#FFFFFF style TS_APP fill:#3178C6,stroke:#2C6AA8,color:#FFFFFF style TS_ORIG fill:#3178C6,stroke:#2C6AA8,color:#FFFFFF style TS_EXTRA fill:#3178C6,stroke:#2C6AA8,color:#FFFFFF Python: Duck Typing with Protocols # Python traditionally relies on duck typing (\u0026ldquo;if it walks like a duck and quacks like a duck\u0026hellip;\u0026rdquo;), but in Python, Protocols are there for type checking and the closest thing to interfaces:\nfrom typing import Protocol # Define a Protocol for type checking class Logger(Protocol): def log(self, message: str) -\u0026gt; None: ... def error(self, message: str) -\u0026gt; None: ... # No explicit implementation needed! class ConsoleLogger: def log(self, message: str) -\u0026gt; None: print(f\u0026#34;[INFO] {message}\u0026#34;) def error(self, message: str) -\u0026gt; None: print(f\u0026#34;[ERROR] {message}\u0026#34;) # Type hint, but runtime doesn\u0026#39;t care def process_data(data: str, logger: Logger) -\u0026gt; None: try: # Process data... logger.log(\u0026#34;Data processed successfully\u0026#34;) except Exception as e: logger.error(f\u0026#34;Failed to process data: {str(e)}\u0026#34;) # This works even without the Protocol, # but the Protocol helps with static type checking process_data(\u0026#34;some data\u0026#34;, ConsoleLogger()) Python\u0026rsquo;s approach is:\nRuntime duck typing (any object with the right methods works) Optional static type checking with Protocols No enforcement at runtime Protocols are primarily for documentation and tooling The Protocol system is similar to Go\u0026rsquo;s interfaces but lives primarily in the type checking realm ‚Äì your code will run even if types don\u0026rsquo;t match, potentially leading to runtime errors. Of course it\u0026rsquo;s totally possible you\u0026rsquo;re working on a cloud team using Python that doesn\u0026rsquo;t understand interfaces, and simply write Python like scripts or commit full AI generated code. In that case, you\u0026rsquo;re less likely to see use of interfaces benefiting the codebase. Let it languish.\nLet\u0026rsquo;s visualize Protocol use:\nflowchart TD subgraph \u0026#34;Python\u0026#34; PY_LIB[Library Code] --\u0026gt;|expects methods| PY_DUCK[Duck-Typed Objects] PY_TYPE[Type Checker] -.-\u0026gt;|verifies against| PY_PROTO[Protocol] PY_DUCK -.-\u0026gt;|optionally checked against| PY_PROTO PY_APP[Application Code] --\u0026gt;|provides| PY_DUCK end style PY_LIB fill:#4B8BBE,stroke:#306998,color:#FFE873 style PY_DUCK fill:#4B8BBE,stroke:#306998,color:#FFE873 style PY_PROTO fill:#4B8BBE,stroke:#306998,color:#FFE873 style PY_TYPE fill:#4B8BBE,stroke:#306998,color:#FFE873 style PY_APP fill:#4B8BBE,stroke:#306998,color:#FFE873 Go: Implicit Satisfaction with Compile-Time Verification # Now let\u0026rsquo;s see Go\u0026rsquo;s approach:\n// Define an interface type Logger interface { Log(message string) Error(message string) } // No explicit implementation declaration type ConsoleLogger struct{} func (l ConsoleLogger) Log(message string) { fmt.Printf(\u0026#34;[INFO] %s\\n\u0026#34;, message) } func (l ConsoleLogger) Error(message string) { fmt.Printf(\u0026#34;[ERROR] %s\\n\u0026#34;, message) } // ProcessData requires a Logger func ProcessData(data string, logger Logger) { // Process data... logger.Log(\u0026#34;Data processed successfully\u0026#34;) } Go\u0026rsquo;s approach is:\nDefine interfaces based on what you need, not what others provide No explicit implementation declarations Compile-time verification that types satisfy interfaces Zero runtime overhead for interface checks We can visualize this as:\nflowchart TD subgraph \u0026#34;Go\u0026#34; GO_APP[Application Code] --\u0026gt;|defines| GO_I[Interface] GO_LIB[Library Code] -.-\u0026gt;|automatically satisfies| GO_I GO_COM[Compiler] --\u0026gt;|verifies| GO_LIB end style GO_I fill:#00ADD8,stroke:#00758D,color:#FFFFFF style GO_LIB fill:#00ADD8,stroke:#00758D,color:#FFFFFF style GO_APP fill:#00ADD8,stroke:#00758D,color:#FFFFFF style GO_COM fill:#00ADD8,stroke:#00758D,color:#FFFFFF In Comparison # Let\u0026rsquo;s visualize them side-by-side:\nflowchart TD subgraph \u0026#34;TypeScript\u0026#34; TS_LIB[Library Code] --\u0026gt;|defines| TS_I[Interface] TS_APP[Application Code] --\u0026gt;|implements| TS_I TS_I --\u0026gt;|constrains| TS_APP end subgraph \u0026#34;Python\u0026#34; PY_LIB[Library Code] --\u0026gt;|expects methods| PY_DUCK[Duck-Typed Objects] PY_TYPE[Type Checker] -.-\u0026gt;|verifies against| PY_PROTO[Protocol] PY_DUCK -.-\u0026gt;|optionally checked against| PY_PROTO PY_APP[Application Code] --\u0026gt;|provides| PY_DUCK end subgraph \u0026#34;Go\u0026#34; GO_APP[Application Code] --\u0026gt;|defines| GO_I[Interface] GO_LIB[Library Code] -.-\u0026gt;|automatically satisfies| GO_I GO_COM[Compiler] --\u0026gt;|verifies| GO_LIB end style TS_I fill:#3178C6,stroke:#2C6AA8,color:#FFFFFF style TS_LIB fill:#3178C6,stroke:#2C6AA8,color:#FFFFFF style TS_APP fill:#3178C6,stroke:#2C6AA8,color:#FFFFFF style PY_LIB fill:#4B8BBE,stroke:#306998,color:#FFE873 style PY_DUCK fill:#4B8BBE,stroke:#306998,color:#FFE873 style PY_PROTO fill:#4B8BBE,stroke:#306998,color:#FFE873 style PY_TYPE fill:#4B8BBE,stroke:#306998,color:#FFE873 style PY_APP fill:#4B8BBE,stroke:#306998,color:#FFE873 style GO_I fill:#00ADD8,stroke:#00758D,color:#FFFFFF style GO_LIB fill:#00ADD8,stroke:#00758D,color:#FFFFFF style GO_APP fill:#00ADD8,stroke:#00758D,color:#FFFFFF style GO_COM fill:#00ADD8,stroke:#00758D,color:#FFFFFF The fundamental difference is in who defines the interfaces and how they\u0026rsquo;re connected to implementations:\nTypeScript: Library authors define interfaces, application developers implement them. Alternatively, you can use satisfies for looser coupling. ‚ÜîÔ∏è Flexibe coupling Python: Library authors expect method signatures, application developers provide matching objects. Type checkers optionally verify. ‚ÜîÔ∏è Loose coupling with optional checking Go: Application developers define interfaces based on what they need, and any library that happens to have matching methods automatically works. ‚ÜîÔ∏è Perfect decoupling üí° Tip Go\u0026rsquo;s approach inverts the dependency relationship! Instead of libraries dictating interfaces that your code must implement, your code defines interfaces that any library can satisfy without modification.\nThis design means:\nYou can create interfaces for third-party code you don\u0026rsquo;t control Interfaces can be added to existing code without modifying it Dependencies flow in the direction you want (toward interfaces, not implementations) Your code becomes naturally more testable and modular (HUGE!) Let\u0026rsquo;s dive deeper into why Go\u0026rsquo;s interfaces are so incredible and how you can leverage their full power.\nWhat Makes Go Interfaces Special? # Unlike languages, like C#, where interfaces are explicitly implemented, Go takes a completely different approach: implicit implementation. This seemingly small design decision has massive implications for how we structure our code.\n// This is all it takes to define an interface in Go type Stringer interface { String() string } // And this type automatically implements it without any \u0026#34;implements\u0026#34; keyword type Person struct { Name string Age int } func (p Person) String() string { return fmt.Sprintf(\u0026#34;%s (%d years)\u0026#34;, p.Name, p.Age) } üí° Tip Think of Go interfaces as describing what a type can do, not what a type is. This subtle shift will change how you design your code. As Rob Pike, one of Go\u0026rsquo;s creators, famously said: \u0026ldquo;The bigger the interface, the weaker the abstraction\u0026rdquo; [1]. This wasn\u0026rsquo;t immediately intuitive to me, and I\u0026rsquo;ve made mistakes of creating big interfaces with the aws sdk in the past, but it\u0026rsquo;s become my guiding principle when designing Go code now.\nThe Interface Hierarchy (or lack thereof) # Let\u0026rsquo;s visualize how Go\u0026rsquo;s interfaces work compared to traditional OOP languages:\ngraph TD subgraph \u0026#34;Go Interfaces\u0026#34; E[SmallInterface1] --\u0026gt;|used by| G[Function1] F[SmallInterface2] --\u0026gt;|used by| H[Function2] I[ConcreteType] -.-\u0026gt;|satisfies| E I -.-\u0026gt;|satisfies| F end style E fill:#553C9A,stroke:#6B46C1,color:#E2E8F0 style F fill:#553C9A,stroke:#6B46C1,color:#E2E8F0 style G fill:#2D3748,stroke:#4A5568,color:#E2E8F0 style H fill:#2D3748,stroke:#4A5568,color:#E2E8F0 style I fill:#2D3748,stroke:#4A5568,color:#E2E8F0 graph TD subgraph \u0026#34;Traditional OOP Interfaces\u0026#34; A[BaseInterface] --\u0026gt; B[DerivedInterface1] A --\u0026gt; C[DerivedInterface2] D[Class] --\u0026gt;|implements| B D --\u0026gt;|implements| C end style A fill:#4A5568,stroke:#718096,color:#E2E8F0 style B fill:#4A5568,stroke:#718096,color:#E2E8F0 style C fill:#4A5568,stroke:#718096,color:#E2E8F0 style D fill:#2D3748,stroke:#4A5568,color:#E2E8F0 As explained in the Go documentation [2], one of Go\u0026rsquo;s most distinctive features is that interfaces are satisfied implicitly. This means there\u0026rsquo;s no \u0026ldquo;implements\u0026rdquo; keyword like in Java or C#.\nIdiomatic Interface Usage in Go # There are several patterns that have emerged as idiomatic ways to use interfaces in Go:\n1. Accept Interfaces, Return Concrete Types # Functions should accept interfaces but return concrete types. Not only does it make your code more flexible, but its this form of abstract thinking that enables your tech debt ‚Äì I mean functions become more robust with their dependency injection.\nHere\u0026rsquo;s a comparison:\n// Good: Accept interface, return concrete type. func ProcessData(reader io.Reader) *Result { // Process the data from the reader return \u0026amp;Result{...} } // Less flexible: Accept concrete type. // You\u0026#39;re locked in with this one func ProcessFile(fileName *os.File) *Result { // Can only process files, not other readers return \u0026amp;Result{...} } 2. Define Interfaces at the Point of Use # Unlike other languages where interfaces are defined by the implementor, in Go, interfaces are typically defined by the consumer, as outlined in Effective Go [3]:\n// In a client package that needs to store users package client // We define the interface we need type UserStorage interface { GetUser(id string) (*User, error) SaveUser(user *User) error } // Our code only depends on this interface func ProcessUser(storage UserStorage, id string) error { // Implementation } Defining interfaces for consumers of your package is an anti-pattern!\n3. Keep Interfaces Small # The standard library is full of tiny interfaces that do one thing well. For example:\n// From io package type Reader interface { Read(p []byte) (n int, err error) } type Writer interface { Write(p []byte) (n int, err error) } // From sort package type Interface interface { Len() int Less(i, j int) bool Swap(i, j int) } As explained in Effective Go [3]: \u0026ldquo;interfaces with only one or two methods are common in Go code, and are usually given names ending in -er, such as Reader, Writer, Formatter, etc.\u0026rdquo; It is an idiomatic style choice for the language, that I mostly follow. Just like those of us who follow the PEP 8 style guide for Python, unlike somePeople (YOU KNOW WHO YOU ARE!).\nConsuming Standard Library Interfaces # One of the most powerful aspects of Go is how the standard library uses interfaces extensively. Let\u0026rsquo;s see some examples of how to effectively work with these:\nWorking with the Database/SQL Package # The database/sql package is a masterclass in interface usage. Let\u0026rsquo;s look at how we can leverage its interfaces:\nimport ( \u0026#34;context\u0026#34; \u0026#34;database/sql\u0026#34; \u0026#34;log\u0026#34; _ \u0026#34;github.com/lib/pq\u0026#34; // PostgreSQL driver ) // Define our own interface for testability type UserRepository interface { GetUserByID(ctx context.Context, id int) (*User, error) SaveUser(ctx context.Context, user *User) error } // Concrete implementation using database/sql type SQLUserRepository struct { db *sql.DB } func (r *SQLUserRepository) GetUserByID(ctx context.Context, id int) (*User, error) { user := \u0026amp;User{} err := r.db.QueryRowContext(ctx, \u0026#34;SELECT id, name, email FROM users WHERE id = $1\u0026#34;, id, ).Scan(\u0026amp;user.ID, \u0026amp;user.Name, \u0026amp;user.Email) if err != nil { return nil, err } return user, nil } // Implementation of other methods... // Now we can use it in our business logic func ProcessUserData(repo UserRepository, userID int) error { // Our code is now testable and flexible } The beauty here is that sql.DB itself uses interfaces internally (like driver.Conn, driver.Stmt), allowing different database drivers to work with the same API.\nHTTP Handlers and Middleware # The net/http package is another excellent example of interface usage:\ntype Handler interface { ServeHTTP(ResponseWriter, *Request) } This tiny interface powers entire web frameworks! Let\u0026rsquo;s see how to use it effectively:\nimport ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) // Middleware for logging requests func LoggingMiddleware(next http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { start := time.Now() // Call the next handler next.ServeHTTP(w, r) // Log after the request is done log.Printf(\u0026#34;%s %s took %v\u0026#34;, r.Method, r.URL.Path, time.Since(start)) }) } // Our actual handler type UserHandler struct { userService UserService } func (h *UserHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { // Handler implementation } // Wire it all together func main() { userHandler := \u0026amp;UserHandler{...} // Apply middleware handler := LoggingMiddleware(userHandler) http.Handle(\u0026#34;/users/\u0026#34;, handler) http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) } Advanced Interface Techniques # 1. Interface Composition # You can compose interfaces by embedding them, as shown in the Go documentation [2]:\ntype ReadWriter interface { io.Reader io.Writer } type ReadWriteCloser interface { io.Reader io.Writer io.Closer } This is how the standard library builds up more complex interfaces from simpler ones.\n2. Optional Interface Implementation # Sometimes you want to provide special behavior for types that implement a specific interface, but fall back to default behavior for those that don\u0026rsquo;t. This pattern is explored in Ian Lance Taylor\u0026rsquo;s article on Go interfaces [6]:\n// From the encoding/json package type Marshaler interface { MarshalJSON() ([]byte, error) } // Inside the json package, it checks if values implement this interface if m, ok := value.(Marshaler); ok { return m.MarshalJSON() } // Otherwise fall back to default marshaling This pattern is used extensively throughout the standard library [4].\n3. Type Assertions and Type Switches # When working with interfaces, you often need to extract the concrete type:\nfunc HandleData(data interface{}) { // Type switch switch v := data.(type) { case string: fmt.Println(\u0026#34;String:\u0026#34;, v) case int: fmt.Println(\u0026#34;Integer:\u0026#34;, v) case fmt.Stringer: fmt.Println(\u0026#34;Stringer:\u0026#34;, v.String()) default: fmt.Printf(\u0026#34;Unknown type: %T\\n\u0026#34;, v) } // Or type assertion if str, ok := data.(string); ok { // It\u0026#39;s a string } } The Go Blog\u0026rsquo;s article on reflection [5] provides deep insights into how these mechanisms work under the hood.\nPractical Interface Examples # Example 1: Creating Mock-Friendly Code # Let\u0026rsquo;s say we need to interact with a database. One day you could be using SQLite for a project and all of a sudden your friend, who is also working on the project, switches the database to MariaDB because the creator liked his comment on LinkedIn. Or maybe you get sick of relational databases and setup Couchbase (NoSQL, LETS GOOOOOOOO).\nInstead of directly using a specific database implementation, we can define an interface:\ntype UserStore interface { GetUser(id string) (*User, error) SaveUser(user *User) error DeleteUser(id string) error } // Our business logic only depends on the interface func ProcessUserData(store UserStore, userID string) error { user, err := store.GetUser(userID) if err != nil { return err } // Process user data... user.LastProcessed = time.Now() return store.SaveUser(user) } I got super excited when I learned about interfacing to create easier mock tests. Instead of spinning up a real database, I can create a simple mock the calls:\ntype MockUserStore struct { users map[string]*User } func (m *MockUserStore) GetUser(id string) (*User, error) { user, exists := m.users[id] if !exists { return nil, fmt.Errorf(\u0026#34;user not found\u0026#34;) } return user, nil } // implement other methods... // Now testing is trivial! func TestProcessUserData(t *testing.T) { mockStore := \u0026amp;MockUserStore{ users: map[string]*User{ \u0026#34;123\u0026#34;: {ID: \u0026#34;123\u0026#34;, Name: \u0026#34;Test User\u0026#34;}, }, } err := ProcessUserData(mockStore, \u0026#34;123\u0026#34;) // Assert on results... } Example 2: Working with Third-Party Libraries Using AWS SDK v2 # Let\u0026rsquo;s see how to effectively interface with the AWS SDK v2, which was designed with better testability in mind:\nimport ( \u0026#34;context\u0026#34; \u0026#34;io\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/aws/aws-sdk-go-v2/aws\u0026#34; \u0026#34;github.com/aws/aws-sdk-go-v2/service/s3\u0026#34; ) // Define our own interface that describes just what we need type S3Client interface { GetObject(ctx context.Context, params *s3.GetObjectInput, optFns ...func(*s3.Options)) (*s3.GetObjectOutput, error) PutObject(ctx context.Context, params *s3.PutObjectInput, optFns ...func(*s3.Options)) (*s3.PutObjectOutput, error) } // Our service that depends on the interface, not the concrete implementation type StorageService struct { client S3Client } // Factory function func NewStorageService(client S3Client) *StorageService { return \u0026amp;StorageService{client: client} } func (s *StorageService) DownloadFile(ctx context.Context, bucket, key string) ([]byte, error) { result, err := s.client.GetObject(ctx, \u0026amp;s3.GetObjectInput{ Bucket: aws.String(bucket), Key: aws.String(key), }) if err != nil { return nil, err } defer result.Body.Close() return io.ReadAll(result.Body) } // For actual code, use the real client // This is quick and dirty high-level logic func main() { // Configure the SDK (error handling omitted for brevity) cfg, _ := config.LoadDefaultConfig(context.TODO(), config.WithRegion(\u0026#34;us-west-2\u0026#34;)) // S3 client client := s3.NewFromConfig(cfg) // Pass it to our service service := NewStorageService(client) data, err := service.DownloadFile(context.TODO(), \u0026#34;my-bucket\u0026#34;, \u0026#34;my-file.txt\u0026#34;) // ... } And then for the test we just need to create a struct that matches our interface.\n// For tests, use a mock implementation type MockS3Client struct { GetObjectFunc func(ctx context.Context, params *s3.GetObjectInput, optFns ...func(*s3.Options)) (*s3.GetObjectOutput, error) PutObjectFunc func(ctx context.Context, params *s3.PutObjectInput, optFns ...func(*s3.Options)) (*s3.PutObjectOutput, error) } func (m *MockS3Client) GetObject(ctx context.Context, params *s3.GetObjectInput, optFns ...func(*s3.Options)) (*s3.GetObjectOutput, error) { return m.GetObjectFunc(ctx, params, optFns...) } func (m *MockS3Client) PutObject(ctx context.Context, params *s3.PutObjectInput, optFns ...func(*s3.Options)) (*s3.PutObjectOutput, error) { return m.PutObjectFunc(ctx, params, optFns...) } func TestDownloadFile(t *testing.T) { // Create a mock that returns predefined data mockClient := \u0026amp;MockS3Client{ GetObjectFunc: func(ctx context.Context, params *s3.GetObjectInput, optFns ...func(*s3.Options)) (*s3.GetObjectOutput, error) { return \u0026amp;s3.GetObjectOutput{ Body: io.NopCloser(strings.NewReader(\u0026#34;mock file content\u0026#34;)), }, nil }, } service := NewStorageService(mockClient) data, err := service.DownloadFile(context.TODO(), \u0026#34;test-bucket\u0026#34;, \u0026#34;test-key\u0026#34;) // Assert no error if err != nil { t.Fatalf(\u0026#34;Expected no error, got %v\u0026#34;, err) } // Assert data is as expected if string(data) != \u0026#34;mock file content\u0026#34; { t.Fatalf(\u0026#34;Expected \u0026#39;mock file content\u0026#39;, got \u0026#39;%s\u0026#39;\u0026#34;, string(data)) } } And now with this, we mock the aws calls and let our DownloadFile do its thing.\nüìù Note The AWS SDK v2 was completely redesigned around interfaces, making it much more testable than v1. Notice how we define our own narrow interface that matches just the methods we actually use, rather than trying to implement the entire AWS API. This pattern gives us several advantages:\nWe only depend on the specific methods we need, not the entire API It\u0026rsquo;s clear from our interface what AWS functionality we\u0026rsquo;re using We can easily mock the client for testing (which I find better than actually calling aws resources or using middleware for testing) We can swap implementations for different environments (local dev, staging, production) The Empty Interface and Type Assertions # Before we wrap up, let\u0026rsquo;s talk about the empty interface: interface{} (or any in Go 1.18+). This interface has no methods, which means every type satisfies it.\nfunc PrintAnything(v interface{}) { // Type assertion to check if v is a string if str, ok := v.(string); ok { fmt.Println(\u0026#34;String:\u0026#34;, str) return } // Type switch for multiple types switch val := v.(type) { case int: fmt.Println(\u0026#34;Integer:\u0026#34;, val) case bool: fmt.Println(\u0026#34;Boolean:\u0026#34;, val) case []interface{}: fmt.Println(\u0026#34;Slice with\u0026#34;, len(val), \u0026#34;items\u0026#34;) default: fmt.Printf(\u0026#34;Unknown type: %T\\n\u0026#34;, v) } } üö® Caution While the empty interface is powerful, use it sparingly. The more specific your interfaces, the more the compiler can help you catch errors early. Wrapping Up: The Interface Philosophy # After years of working with Go interfaces, I\u0026rsquo;ve developed a simple philosophy that aligns with the Go documentation and community best practices:\nStart with concrete implementations Extract interfaces when you need abstraction Keep interfaces small and focused Let behavior determine the interfaces, not the other way around Embrace the fact that interfaces are satisfied implicitly flowchart LR A[Concrete Implementation] --\u0026gt;|Extract| B[Small Interface] B --\u0026gt;|Used by| C[Business Logic] D[New Implementation] -.-\u0026gt;|Implicitly satisfies| B style A fill:#2D3748,stroke:#4A5568,color:#E2E8F0 style B fill:#553C9A,stroke:#6B46C1,color:#E2E8F0 style C fill:#4A5568,stroke:#718096,color:#E2E8F0 style D fill:#2D3748,stroke:#4A5568,color:#E2E8F0 Go\u0026rsquo;s interface system forces you to think differently about abstraction, and that\u0026rsquo;s a good thing.\nSo go forth and interface all the things - just keep \u0026rsquo;em small!\nReferences # [1] Rob Pike, \u0026ldquo;Go Proverbs\u0026rdquo; [2] Go Documentation, \u0026ldquo;Interfaces\u0026rdquo; [3] The Go Authors, \u0026ldquo;Effective Go\u0026rdquo; [4] The Go Team, \u0026ldquo;Standard Library Documentation\u0026rdquo; [5] The Go Blog, \u0026ldquo;The Laws of Reflection\u0026rdquo; [6] Ian Lance Taylor, \u0026ldquo;Go Interfaces\u0026rdquo; ","date":"Mar 14, 2025","permalink":"https://blog.mikesahari.com/posts/interfaces/","tags":["go","interfaces","python","typescript","mocks","aws","fundamentals"],"title":"Understanding Go Interfaces"},{"content":"Here is a fun project to get you GO-ing! Imagine, your API is humming along nicely until that one client (a complete savage) decides to hammer it with requests, bringing everything to a crawl. This is where rate limiting comes in to save the day!\nIn this post, we\u0026rsquo;re building a configurable rate-limiting reverse proxy. And by the end of this blog, you\u0026rsquo;ll have a lightweight, performant service that sits in front of your APIs and protects them from traffic spikes.\nWhat Exactly Are We Building? # A reverse proxy acts as a middleman between clients and your actual service. Our proxy will add a critical feature: rate limiting to control how many requests per second (RPS) each client can make.\nflowchart LR classDef client fill:#8884d8,color:#fff classDef proxy fill:#82ca9d,color:#000 classDef service fill:#ffc658,color:#000 A[Client] --\u0026gt;|Request| B[Rate-Limiting Proxy] B --\u0026gt;|Under Limit| C[Your Service] B --\u0026gt;|Over Limit| D[429 Too Many Requests] class A client class B proxy class C,D service Our proxy will be configurable via environment variables:\nTARGET_URL: The API we\u0026rsquo;re protecting (i.e. localhost:8080) PROXY_PORT: The port our proxy runs on (i.e. 8000) RPS: Requests per second allowed BURST: Maximum capacity and how many requests can temporarily exceed the rate limit For this example, we will be building our rate-limiting reverse proxy using the Token Bucket Algorithm. But before we jump into things, I wanted to break down the concepts.\nThe Token Bucket Algorithm is fundamentally a traffic cop for your API. It works on a deceptively simple principle:\nYou have a bucket that holds tokens Tokens are added to the bucket at a constant rate Each API request requires one or more tokens If there are enough tokens, the request goes through and tokens are consumed If not, the request is rejected (usually with a 429 Too Many Requests) RPS (Requests Per Second) is your token generation rate - it defines how many new request permits you\u0026rsquo;re issuing every second. This is your system\u0026rsquo;s sustainable throughput.\nüó®Ô∏è Example If your RPS is set to 10:\nYour bucket gets 10 new tokens every second That\u0026rsquo;s one new token every 0.1 seconds This is your long-term, guaranteed throughput capacity The following charts visualize this:\ngraph LR subgraph \u0026#34;Tokens (RPS = 10)\u0026#34; A[Start] --\u0026gt;|t=0s| B[10 tokens] B --\u0026gt;|t=1s| C[20 tokens] C --\u0026gt;|t=2s| D[30 tokens] D --\u0026gt;|t=3s| E[30 tokens] style A fill:#1A237E,color:#fff style B fill:#303F9F,color:#fff style C fill:#3949AB,color:#fff style D fill:#3F51B5,color:#fff,stroke:#FF5722,stroke-width:2px style E fill:#3F51B5,color:#fff,stroke:#FF5722,stroke-width:2px end subgraph \u0026#34;Token Generation Rate\u0026#34; F[Token Rate: 10 per second] --\u0026gt;|\u0026#34;Steady drip into bucket\u0026#34;| G[(\u0026#34;Max capacity: 30 tokens\u0026#34;)] style F fill:#D32F2F,color:#fff style G fill:#7CB342,color:#fff end Burst capacity is like your API\u0026rsquo;s turbo button - the maximum number of requests you\u0026rsquo;ll allow all at once, even if it exceeds your sustainable rate. It\u0026rsquo;s your buffer against traffic spikes.\nüó®Ô∏è Example If your burst is 30:\nYour bucket has a maximum capacity of 30 tokens A client can make up to 30 requests immediately After burst capacity is exhausted, they\u0026rsquo;re throttled to your RPS The following visualization describes this:\ngraph TD subgraph \u0026#34;(RPS=10, Burst=30)\u0026#34; A[Initial State: Bucket Full] --\u0026gt;|\u0026#34;Client makes 30 requests instantly\u0026#34;| B[Bucket Empty] B --\u0026gt;|\u0026#34;After 1 second: +10 tokens\u0026#34;| C[10 Tokens] B --\u0026gt;|\u0026#34;Immediate new requests rejected\u0026#34;| D[429 Too Many Requests] C --\u0026gt;|\u0026#34;After 2 more seconds: +20\u0026#34;| E[30 Tokens] style A fill:#388E3C,color:#fff style B fill:#D32F2F,color:#fff style C fill:#FFA000,color:#000 style D fill:#C2185B,color:#fff style E fill:#388E3C,color:#fff end Start to make sense? Let\u0026rsquo;s jump into the project to see this in action.\nProject Setup # Let\u0026rsquo;s start by creating our project structure. I\u0026rsquo;m assuming you already have Go 1.24 installed.\nmkdir rate-limit-proxy cd rate-limit-proxy go mod init github.com/yourusername/rate-limit-proxy touch cmd/rate-limit-proxy/main.go Now let\u0026rsquo;s install the packages we\u0026rsquo;ll need:\ngo get golang.org/x/time/rate This package provides Go\u0026rsquo;s excellent token bucket rate limiter, which we\u0026rsquo;ll be using extensively.\nBuilding Our Rate-Limiting Proxy # Let\u0026rsquo;s start by creating the overall structure of our application in cmd/rate-limit-proxy/main.go:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/http/httputil\u0026#34; \u0026#34;net/url\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; \u0026#34;golang.org/x/time/rate\u0026#34; ) // ClientLimiter tracks rate limits for each client type ClientLimiter struct { limiter *rate.Limiter lastSeen time.Time } // Global map to store limiters for each client IP var ( clients = make(map[string]*ClientLimiter) mu sync.Mutex // protects clients map cleanupInt = 5 * time.Minute ) func main() { // Configuration from environment variables targetURL := getEnv(\u0026#34;TARGET_URL\u0026#34;, \u0026#34;http://localhost:8080\u0026#34;) proxyPort := getEnv(\u0026#34;PROXY_PORT\u0026#34;, \u0026#34;8000\u0026#34;) rpsStr := getEnv(\u0026#34;RPS\u0026#34;, \u0026#34;10\u0026#34;) burstStr := getEnv(\u0026#34;BURST\u0026#34;, \u0026#34;20\u0026#34;) // Parse numeric configs rps, err := strconv.ParseFloat(rpsStr, 64) if err != nil { log.Fatalf(\u0026#34;Invalid RPS value: %v\u0026#34;, err) } burst, err := strconv.Atoi(burstStr) if err != nil { log.Fatalf(\u0026#34;Invalid BURST value: %v\u0026#34;, err) } // Setup the reverse proxy url, err := url.Parse(targetURL) if err != nil { log.Fatalf(\u0026#34;Invalid target URL: %v\u0026#34;, err) } proxy := httputil.NewSingleHostReverseProxy(url) // Start cleanup routine for inactive clients go cleanupOldClients() // Set up the HTTP server with our custom handler http.HandleFunc(\u0026#34;/\u0026#34;, createRateLimitHandler(proxy, rps, burst)) fmt.Printf(\u0026#34;Starting rate-limiting proxy server on :%s\\n\u0026#34;, proxyPort) fmt.Printf(\u0026#34;Forwarding to: %s\\n\u0026#34;, targetURL) fmt.Printf(\u0026#34;Rate limit: %.1f requests/second with burst of %d\\n\u0026#34;, rps, burst) if err := http.ListenAndServe(\u0026#34;:\u0026#34;+proxyPort, nil); err != nil { log.Fatalf(\u0026#34;Failed to start server: %v\u0026#34;, err) } } // Helper function to get env variable with fallback func getEnv(key, fallback string) string { if value, exists := os.LookupEnv(key); exists { return value } return fallback } Now let\u0026rsquo;s implement the rate limiting handler and cleanup function:\n// Create our rate-limiting handler function func createRateLimitHandler(proxy *httputil.ReverseProxy, rps float64, burst int) http.HandlerFunc { return func(w http.ResponseWriter, r *http.Request) { // Get client IP clientIP := r.RemoteAddr // Get or create rate limiter for this client limiter := getClientLimiter(clientIP, rps, burst) // Check if request is allowed if limiter.limiter.Allow() { // Forward the request to the target service proxy.ServeHTTP(w, r) } else { http.Error(w, \u0026#34;429 Too Many Requests\u0026#34;, http.StatusTooManyRequests) log.Printf(\u0026#34;Rate limit exceeded for client %s\u0026#34;, clientIP) } } } // Get a rate limiter for a client func getClientLimiter(clientIP string, rps float64, burst int) *ClientLimiter { mu.Lock() defer mu.Unlock() limiter, exists := clients[clientIP] if !exists { // Create a new rate limiter for this client limiter = \u0026amp;ClientLimiter{ limiter: rate.NewLimiter(rate.Limit(rps), burst), lastSeen: time.Now(), } clients[clientIP] = limiter return limiter } // Update the last seen time limiter.lastSeen = time.Now() return limiter } // Cleanup routine to remove inactive clients func cleanupOldClients() { for { time.Sleep(cleanupInt) mu.Lock() now := time.Now() for ip, client := range clients { if now.Sub(client.lastSeen) \u0026gt; 1*time.Hour { delete(clients, ip) log.Printf(\u0026#34;Cleaned up limiter for inactive client: %s\u0026#34;, ip) } } mu.Unlock() } } Let\u0026rsquo;s break down what\u0026rsquo;s happening in this code:\nWe set up a reverse proxy using Go\u0026rsquo;s httputil package For each client (identified by IP), we create a rate limiter using Go\u0026rsquo;s token bucket implementation When a request comes in, we check if the client has exceeded their rate limit If they have, we return a 429 Too Many Requests status If not, we forward the request to the target service We also have a background goroutine that cleans up rate limiters for clients that haven\u0026rsquo;t been seen in a while üìù NOTE The token bucket algorithm allows for brief bursts of traffic while still maintaining a consistent average rate limit. This makes it more forgiving than strict per-second limits.\nThe rate.Limiter.Allow() method consumes a single token when it\u0026rsquo;s called, but it doesn\u0026rsquo;t actually block or delay execution! It simply returns false if no tokens are available.\nHandling X-Forwarded-For Headers # One issue with our current implementation is that it uses RemoteAddr to identify clients. In production environments with load balancers, you\u0026rsquo;ll typically want to respect the X-Forwarded-For header. Let\u0026rsquo;s enhance our code:\n// Get client\u0026#39;s real IP, respecting X-Forwarded-For header func getRealIP(r *http.Request) string { // Check for X-Forwarded-For header forwarded := r.Header.Get(\u0026#34;X-Forwarded-For\u0026#34;) if forwarded != \u0026#34;\u0026#34; { // X-Forwarded-For can contain multiple IPs; use the first one ips := strings.Split(forwarded, \u0026#34;,\u0026#34;) return strings.TrimSpace(ips[0]) } // Fall back to RemoteAddr if X-Forwarded-For is not present ip := r.RemoteAddr // Strip port number if present host, _, err := net.SplitHostPort(ip) if err == nil { // Successfully split host and port, use just the host ip = host } return ip } üìå IMPORTANT Don\u0026rsquo;t forget to add strings and net to your imports! Now, update the createRateLimitHandler function to use this instead:\n// Create our rate-limiting handler function func createRateLimitHandler(proxy *httputil.ReverseProxy, rps float64, burst int) http.HandlerFunc { return func(w http.ResponseWriter, r *http.Request) { // Get client IP clientIP := getRealIP(r) // Rest of the function remains the same // ... } } Testing Our Rate Limiter # Now that we have our rate-limiting proxy, let\u0026rsquo;s test it. First, make sure you have a test service running. For this example, I\u0026rsquo;ll use a simple echo server. We can create this under cmd/echo-server/main.go\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { http.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Hello from the test service! Path: %s\\n\u0026#34;, r.URL.Path) }) log.Println(\u0026#34;Starting test service on :8080\u0026#34;) http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) } In a separate terminal, start our echo server:\n# Start a simple test service go run cmd/echo-server/main.go Now, in another terminal, set the environment variables and start our rate-limiting proxy:\nexport TARGET_URL=http://localhost:8080 export PROXY_PORT=8000 export RPS=2 export BURST=3 go run cmd/rate-limit-proxy/main.go This configures our proxy to allow an average of 2 requests per second, with a burst of 3 at most.\nLet\u0026rsquo;s test it with a more aggressive approach - we\u0026rsquo;ll use Go itself to hammer the endpoint with concurrent requests!\nWe\u0026rsquo;ll create a simple go script under cmd/test-rate-limit/main.go\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { // Number of concurrent requests to send concurrency := 10 totalRequests := 20 fmt.Printf(\u0026#34;Sending %d requests with %d concurrent workers...\\n\u0026#34;, totalRequests, concurrency) // Use a WaitGroup to wait for all goroutines to finish var wg sync.WaitGroup wg.Add(concurrency) // Channel to distribute work jobs := make(chan int, totalRequests) // Fill the jobs channel for i := 1; i \u0026lt;= totalRequests; i++ { jobs \u0026lt;- i } close(jobs) // Start time for benchmarking startTime := time.Now() // Launch workers for i := 0; i \u0026lt; concurrency; i++ { go func() { defer wg.Done() for jobID := range jobs { // Make the request resp, err := http.Get(\u0026#34;http://localhost:8000/\u0026#34;) if err != nil { fmt.Printf(\u0026#34;Request %d: ERROR - %v\\n\u0026#34;, jobID, err) continue } // Read and discard body to free connection body, _ := io.ReadAll(resp.Body) resp.Body.Close() status := \u0026#34;SUCCESS\u0026#34; if resp.StatusCode != 200 { status = \u0026#34;RATE LIMITED\u0026#34; } // Print result with timestamp elapsed := time.Since(startTime).Seconds() fmt.Printf(\u0026#34;[%.3fs] Request %d: %s (Status: %d)\\n\u0026#34;, elapsed, jobID, status, resp.StatusCode) if resp.StatusCode == 200 { // Show a bit of the body for successful requests bodyPreview := string(body) if len(bodyPreview) \u0026gt; 30 { bodyPreview = bodyPreview[:30] + \u0026#34;...\u0026#34; } fmt.Printf(\u0026#34; Response: %s\\n\u0026#34;, bodyPreview) } } }() } // Wait for all workers to finish wg.Wait() // Show summary elapsed := time.Since(startTime) fmt.Printf(\u0026#34;\\nCompleted in %.2f seconds\\n\u0026#34;, elapsed.Seconds()) fmt.Printf(\u0026#34;Average RPS attempted: %.1f\\n\u0026#34;, float64(totalRequests)/elapsed.Seconds()) } You should see something like:\nüß™ Test Results Sending 20 requests with 10 concurrent workers... [0.010s] Request 2: SUCCESS (Status: 200) Response: Hello from the test service! P... [0.010s] Request 3: SUCCESS (Status: 200) Response: Hello from the test service! P... [0.010s] Request 1: SUCCESS (Status: 200) Response: Hello from the test service! P... [0.011s] Request 8: RATE LIMITED (Status: 429) [0.011s] Request 4: RATE LIMITED (Status: 429) [0.011s] Request 9: RATE LIMITED (Status: 429) [0.011s] Request 5: RATE LIMITED (Status: 429) [0.011s] Request 7: RATE LIMITED (Status: 429) [0.011s] Request 6: RATE LIMITED (Status: 429) [0.011s] Request 10: RATE LIMITED (Status: 429) [0.011s] Request 11: RATE LIMITED (Status: 429) [0.011s] Request 12: RATE LIMITED (Status: 429) [0.011s] Request 13: RATE LIMITED (Status: 429) [0.011s] Request 15: RATE LIMITED (Status: 429) [0.011s] Request 14: RATE LIMITED (Status: 429) [0.011s] Request 17: RATE LIMITED (Status: 429) [0.011s] Request 16: RATE LIMITED (Status: 429) [0.011s] Request 18: RATE LIMITED (Status: 429) [0.011s] Request 19: RATE LIMITED (Status: 429) [0.011s] Request 20: RATE LIMITED (Status: 429) Completed in 0.01 seconds Average RPS attempted: 1757.1 The first nine requests should succeed and then you\u0026rsquo;ll start seeing 429 errors as the rate limit kicks in.\nIf we were to do the following,\nexport BURST=10 go run cmd/rate-limit-proxy/main.go And then re-run our tests, we would get an output like:\nüß™ Test Results Sending 20 requests with 10 concurrent workers... [0.199s] Request 6: SUCCESS (Status: 200) Response: Hello from the test service! P... [0.199s] Request 8: SUCCESS (Status: 200) Response: Hello from the test service! P... [0.199s] Request 3: SUCCESS (Status: 200) Response: Hello from the test service! P... [0.199s] Request 11: RATE LIMITED (Status: 429) [0.199s] Request 12: RATE LIMITED (Status: 429) [0.199s] Request 10: SUCCESS (Status: 200) Response: Hello from the test service! P... [0.199s] Request 5: SUCCESS (Status: 200) Response: Hello from the test service! P... [0.199s] Request 2: SUCCESS (Status: 200) Response: Hello from the test service! P... [0.199s] Request 4: SUCCESS (Status: 200) Response: Hello from the test service! P... [0.199s] Request 15: RATE LIMITED (Status: 429) [0.199s] Request 9: SUCCESS (Status: 200) Response: Hello from the test service! P... [0.200s] Request 14: RATE LIMITED (Status: 429) [0.200s] Request 16: RATE LIMITED (Status: 429) [0.200s] Request 1: SUCCESS (Status: 200) Response: Hello from the test service! P... [0.200s] Request 13: RATE LIMITED (Status: 429) [0.200s] Request 19: RATE LIMITED (Status: 429) [0.200s] Request 17: RATE LIMITED (Status: 429) [0.200s] Request 20: RATE LIMITED (Status: 429) [0.200s] Request 7: SUCCESS (Status: 200) Response: Hello from the test service! P... [0.200s] Request 18: RATE LIMITED (Status: 429) Completed in 0.20 seconds Average RPS attempted: 100.1 üí° TIP In production, you might want to add headers like X-RateLimit-Limit and X-RateLimit-Remaining to give clients more information about their rate limit status. Rate Limiting Visualization # Let\u0026rsquo;s visualize what\u0026rsquo;s happening with our token bucket algorithm:\nsequenceDiagram participant Client participant Bucket as \u0026#34;Token Bucket\u0026#34; participant Proxy as \u0026#34;Rate-Limiting Proxy\u0026#34; participant Service as \u0026#34;Target Service\u0026#34; Note over Bucket: Initially full with tokens (BURST value) loop Every 1/RPS seconds Bucket-\u0026gt;\u0026gt;Bucket: Add new token (up to BURST) end Client-\u0026gt;\u0026gt;Proxy: Request 1 Proxy-\u0026gt;\u0026gt;Bucket: Take 1 token Bucket--\u0026gt;\u0026gt;Proxy: Token available Proxy-\u0026gt;\u0026gt;Service: Forward request Service--\u0026gt;\u0026gt;Proxy: Response Proxy--\u0026gt;\u0026gt;Client: Response Client-\u0026gt;\u0026gt;Proxy: Request 2 Proxy-\u0026gt;\u0026gt;Bucket: Take 1 token Bucket--\u0026gt;\u0026gt;Proxy: Token available Proxy-\u0026gt;\u0026gt;Service: Forward request Service--\u0026gt;\u0026gt;Proxy: Response Proxy--\u0026gt;\u0026gt;Client: Response Client-\u0026gt;\u0026gt;Proxy: Request 3 Proxy-\u0026gt;\u0026gt;Bucket: Take 1 token Bucket--\u0026gt;\u0026gt;Proxy: Token available Proxy-\u0026gt;\u0026gt;Service: Forward request Service--\u0026gt;\u0026gt;Proxy: Response Proxy--\u0026gt;\u0026gt;Client: Response Client-\u0026gt;\u0026gt;Proxy: Request 4 Proxy-\u0026gt;\u0026gt;Bucket: Take 1 token Bucket--\u0026gt;\u0026gt;Proxy: No tokens available! Proxy--\u0026gt;\u0026gt;Client: 429 Too Many Requests Wrap Up # We\u0026rsquo;ve built a configurable, efficient rate-limiting reverse proxy in Go. This proxy can protect your services from traffic spikes, malicious clients, or simply overzealous integrations.\nSome key points about our implementation:\nPer-client rate limiting: Each client gets their own rate limiter Token bucket algorithm: Allows for bursts while maintaining average limits Configurable via environment variables: Easy to adjust for different services Real IP detection: Works correctly even behind load balancers Memory efficient: Automatically cleans up inactive client limiters With minimal code, we\u0026rsquo;ve created a powerful piece of infrastructure that can be deployed in front of any HTTP service. This is the beauty of Go - it comes with so many useful packages out of the box that you can build production-ready components with very little code.\nThe full source code is available here.\nHappy coding, Gophers!\n","date":"Mar 7, 2025","permalink":"https://blog.mikesahari.com/posts/rate-limiting/","tags":["go","api","reverse-proxy","rate-limiting"],"title":"Building a Rate-Limiter in Go"},{"content":"Let\u0026rsquo;s be honest: adding Mermaid diagrams to your Hugo site should be straightforward, but it\u0026rsquo;s often a frustrating experience. Most tutorials gloss over the critical theme-specific modifications required, leaving you with broken diagrams and cryptic errors.\nAfter spending way too many hours banging my head against this particular wall with the m10c theme, I\u0026rsquo;m documenting the actual working solution so you don\u0026rsquo;t have to suffer through the same pain.\nAn Intro to Mermaid Through Examples # If you\u0026rsquo;re coming to this blog post and don\u0026rsquo;t know what Mermaid diagrams are, they\u0026rsquo;re a way to create diagrams through code. Here are several visuals to give you an idea of what you can do with Mermaid.\nSankey Diagrams # sankey-beta Traffic Sources, Social Media, 20 Traffic Sources, Direct, 40 Traffic Sources, Search, 40 Social Media, Facebook, 8 Social Media, Twitter, 7 Social Media, LinkedIn, 5 Direct, Homepage, 25 Direct, Blog, 15 Search, Homepage, 20 Search, Blog, 15 Search, Products, 5 ```mermaid sankey-beta Traffic Sources, Social Media, 20 Traffic Sources, Direct, 40 Traffic Sources, Search, 40 Social Media, Facebook, 8 Social Media, Twitter, 7 Social Media, LinkedIn, 5 Direct, Homepage, 25 Direct, Blog, 15 Search, Homepage, 20 Search, Blog, 15 Search, Products, 5 ``` Sequence Diagrams # sequenceDiagram participant Client participant API participant DB Client-\u0026gt;\u0026gt;+API: GET /users API-\u0026gt;\u0026gt;+DB: SELECT * FROM users DB--\u0026gt;\u0026gt;-API: Return user data API--\u0026gt;\u0026gt;-Client: 200 OK (JSON) Note over Client,API: Normal flow Client-\u0026gt;\u0026gt;+API: GET /invalid API--\u0026gt;\u0026gt;-Client: 404 Not Found ```mermaid sequenceDiagram participant Client participant API participant DB Client-\u0026gt;\u0026gt;+API: GET /users API-\u0026gt;\u0026gt;+DB: SELECT * FROM users DB--\u0026gt;\u0026gt;-API: Return user data API--\u0026gt;\u0026gt;-Client: 200 OK (JSON) Note over Client,API: Normal flow Client-\u0026gt;\u0026gt;+API: GET /invalid API--\u0026gt;\u0026gt;-Client: 404 Not Found ``` Class Diagrams # classDiagram class Animal { +String name +int age +makeSound() } class Dog { +String breed +bark() } class Cat { +bool hasNineLives +meow() } Animal \u0026lt;|-- Dog Animal \u0026lt;|-- Cat ```mermaid classDiagram class Animal { +String name +int age +makeSound() } class Dog { +String breed +bark() } class Cat { +bool hasNineLives +meow() } Animal \u0026lt;|-- Dog Animal \u0026lt;|-- Cat ``` State Diagrams # stateDiagram-v2 [*] --\u0026gt; Pending Pending --\u0026gt; Processing: Payment received Processing --\u0026gt; Shipped: Item in stock Processing --\u0026gt; Backordered: Out of stock Backordered --\u0026gt; Shipped: Restock Shipped --\u0026gt; Delivered Shipped --\u0026gt; Returned: Customer returns Delivered --\u0026gt; [*] Returned --\u0026gt; [*] ```mermaid stateDiagram-v2 [*] --\u0026gt; Pending Pending --\u0026gt; Processing: Payment received Processing --\u0026gt; Shipped: Item in stock Processing --\u0026gt; Backordered: Out of stock Backordered --\u0026gt; Shipped: Restock Shipped --\u0026gt; Delivered Shipped --\u0026gt; Returned: Customer returns Delivered --\u0026gt; [*] Returned --\u0026gt; [*] ``` Entity Relationship Diagrams # erDiagram USER ||--o{ POST : writes USER { int id string email string name } POST ||--o{ COMMENT : has POST { int id string title string content date created_at } COMMENT { int id string content int user_id } ```mermaid erDiagram USER ||--o{ POST : writes USER { int id string email string name } POST ||--o{ COMMENT : has POST { int id string title string content date created_at } COMMENT { int id string content int user_id } ``` Gantt Chart Diagrams # gantt title Project Timeline dateFormat YYYY-MM-DD section Planning Requirements :a1, 2024-01-01, 30d Design :after a1, 20d section Development Coding :2024-02-15, 45d Testing :2024-03-01, 30d section Launch Deployment :2024-04-01, 10d ```mermaid gantt title Project Timeline dateFormat YYYY-MM-DD section Planning Requirements :a1, 2024-01-01, 30d Design :after a1, 20d section Development Coding :2024-02-15, 45d Testing :2024-03-01, 30d section Launch Deployment :2024-04-01, 10d ``` Nice, huh? Diagrams make it easier for some readers to understand concepts. Through the work in this blog, I was able to implement the same Mermaid codeblocks as in my Obsidian notes.\nThe Problem with Standard Hugo Mermaid Tutorials # The official Hugo documentation provides a basic implementation that works great\u0026hellip; if you\u0026rsquo;re using the default theme with no customizations. But let\u0026rsquo;s be real - who does that?\nMost of us are using custom themes (like m10c in my case), and that\u0026rsquo;s where things break down. The standard implementation doesn\u0026rsquo;t account for how themes structure their templates and load JavaScript.\nüí° TIP The key insight: You need to override your theme\u0026rsquo;s base template, not just add the render hook. The Solution: Theme-Specific Implementation # Here\u0026rsquo;s my working implementation for the m10c theme, with explanations of why each part matters:\nStep 1: Create the Base Template Override # First, you need to override your theme\u0026rsquo;s base template. For m10c, that means:\nIdentify the original template: themes/m10c/layouts/_default/baseof.html Create your override at: layouts/_default/baseof.html Copy the content from the theme\u0026rsquo;s template to your override Step 2: Add Mermaid Support to the Base Template # Next, modify your override to include the Mermaid library. Add this code just before the closing \u0026lt;/body\u0026gt; tag:\n\u0026lt;!-- Add Mermaid support - must be placed before closing body tag --\u0026gt; {{ if .Store.Get \u0026#34;hasMermaid\u0026#34; }} \u0026lt;script type=\u0026#34;module\u0026#34;\u0026gt; import mermaid from \u0026#39;https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs\u0026#39;; mermaid.initialize({ startOnLoad: true, theme: \u0026#39;dark\u0026#39;, // Options: default, forest, dark, neutral securityLevel: \u0026#39;loose\u0026#39;, // Add custom theme properties themeVariables: { // Primary colors primaryColor: \u0026#39;#BB2528\u0026#39;, primaryTextColor: \u0026#39;#fff\u0026#39;, primaryBorderColor: \u0026#39;#7C0000\u0026#39;, // Secondary colors secondaryColor: \u0026#39;#006100\u0026#39;, secondaryTextColor: \u0026#39;#fff\u0026#39;, secondaryBorderColor: \u0026#39;#004d00\u0026#39;, // Other colors as needed mainBkg: \u0026#39;#1f2020\u0026#39;, textColor: \u0026#39;#ddd\u0026#39;, lineColor: \u0026#39;#999\u0026#39;, // Specific diagram colors nodeBorder: \u0026#39;#777\u0026#39;, titleColor: \u0026#39;#F8F8F8\u0026#39; } }); \u0026lt;/script\u0026gt; {{ end }} This code checks if the page has Mermaid content (using Hugo\u0026rsquo;s Store) and only loads the Mermaid library when needed. The custom theme variables ensure your diagrams match your site\u0026rsquo;s dark theme.\nStep 3: Create the Render Hook # Now create a file at layouts/_default/_markup/render-codeblock-mermaid.html with the following content:\n\u0026lt;pre class=\u0026#34;mermaid\u0026#34;\u0026gt; {{- .Inner | htmlEscape | safeHTML }} \u0026lt;/pre\u0026gt; {{ .Page.Store.Set \u0026#34;hasMermaid\u0026#34; true }} This render hook does two critical things:\nWraps your Mermaid code in the correct HTML structure Sets a flag in the page\u0026rsquo;s Store so the base template knows to load the Mermaid library How This Actually Works # Let me explain the process flow with a Mermaid diagram:\nflowchart TD A[Write Markdown with Mermaid Code] --\u0026gt; B[Hugo Processes Markdown] B --\u0026gt; C[Render Hook Processes Mermaid Blocks] C --\u0026gt; D[Sets hasMermaid Flag in Page Store] D --\u0026gt; E[Base Template Checks for hasMermaid Flag] E --\u0026gt; F[Mermaid Library Loads if Flag is True] F --\u0026gt; G[Mermaid Library Renders Diagrams] style A fill:#222,stroke:#BB2528,color:#ddd style G fill:#006100,stroke:#004d00,color:#ddd The key insight here is that the render hook and base template work together through Hugo\u0026rsquo;s Store mechanism. Without either piece, the system breaks down.\nUsing Mermaid in Your Content # With this implementation in place, you can now add Mermaid diagrams to your Markdown content like this:\n```mermaid flowchart LR A[Start] --\u0026gt; B{Decision} B --\u0026gt;|Yes| C[Action 1] B --\u0026gt;|No| D[Action 2] ``` üí° TIP Always use the explicit mermaid language identifier for your code blocks, not just triple backticks. Why Your Theme Matters # Different Hugo themes structure their templates differently. The approach I\u0026rsquo;ve outlined works for m10c, but you might need to adjust it for other themes. The general principles remain the same:\nOverride the base template that controls your HTML output Add conditional loading of the Mermaid library based on content Create a render hook that flags pages containing Mermaid code Common Pitfalls to Avoid # Here are some issues I encountered that aren\u0026rsquo;t mentioned in most tutorials:\nMissing the theme override: Just adding the render hook isn\u0026rsquo;t enough Incorrect script loading: Modern Mermaid uses ES modules, requiring the type=\u0026ldquo;module\u0026rdquo; attribute Theme incompatibility: Dark-themed sites need custom Mermaid styling Resource loading order: The Mermaid library must load after your content is ready Conclusion # Getting Mermaid diagrams working in Hugo requires understanding how your specific theme handles templates and JavaScript. The solution I\u0026rsquo;ve outlined for m10c addresses these theme-specific concerns and provides a robust implementation that works reliably.\nBy overriding the appropriate templates and leveraging Hugo\u0026rsquo;s Store mechanism, you can seamlessly integrate Mermaid diagrams into your content without fighting with your theme.\n","date":"Mar 1, 2025","permalink":"https://blog.mikesahari.com/posts/hugo-mermaid-diagrams/","tags":["hugo","mermaid","blogging"],"title":"Getting Mermaid Diagrams Working in Hugo"},{"content":"Let\u0026rsquo;s get real about pointers in Go‚Äîthey\u0026rsquo;re not the scary beasts you might remember from C (if you came from that CS background). Go\u0026rsquo;s pointer implementation strikes that perfect balance between giving you low-level control and keeping you from shooting yourself in the foot.\nFor Python Developers: Why Care About Pointers? # This blog introduces pointers, a fundamental programming concept many developers struggle with. Having worked with numerous senior Cloud Engineers, SREs, and Platform Engineers who, despite years of industry experience, have only Python knowledge and limited exposure to memory management concepts, I\u0026rsquo;ve crafted this primer to establish essential context before diving into the main teachings.\nIf you\u0026rsquo;re coming from Python, you might be wondering why we even need pointers. After all, Python handles everything behind the scenes, right? Well, that\u0026rsquo;s exactly the point - and also the limitation.\nIn Python, all variables are essentially references to objects. When you pass a variable to a function, you\u0026rsquo;re passing a reference, but you don\u0026rsquo;t get explicit control over whether something is passed by reference or by value. This is why you can modify a list inside a function, but not an integer.\nHere\u0026rsquo;s an example:\n# In Python, you can change mutable objects in functions def add_cat(cat_list): cat_list.append(\u0026#34;Felix\u0026#34;) # This modifies the original list cats = [\u0026#34;Whiskers\u0026#34;, \u0026#34;Mittens\u0026#34;] add_cat(cats) print(cats) # Output: [\u0026#34;Whiskers\u0026#34;, \u0026#34;Mittens\u0026#34;, \u0026#34;Felix\u0026#34;] # But you can\u0026#39;t change immutable objects def age_cat(cat_age): cat_age += 1 # This creates a new local variable whiskers_age = 3 age_cat(whiskers_age) print(whiskers_age) # Output: 3 (unchanged!) Let\u0026rsquo;s visualize how Python\u0026rsquo;s implicit references differ from Go\u0026rsquo;s explicit pointers:\n%%{init: {\u0026#39;theme\u0026#39;:\u0026#39;dark\u0026#39;}}%% flowchart TD subgraph \u0026#34;Py (Implicit References)\u0026#34; style pyvar fill:#6366F1,stroke:#818CF8,color:#FFFFFF,font-weight:bold style pyobj fill:#EC4899,stroke:#F472B6,color:#FFFFFF,font-weight:bold style pymut fill:#10B981,stroke:#34D399,color:#FFFFFF,font-weight:bold style pyimmut fill:#F43F5E,stroke:#FB7185,color:#FFFFFF,font-weight:bold pyvar[\u0026#34;Variables\u0026#34;] pyobj[\u0026#34;Objects in Memory\u0026#34;] pymut[\u0026#34;Mutable Objects\u0026lt;br\u0026gt;(lists, dicts, etc)\u0026#34;] pyimmut[\u0026#34;Immutable Objects\u0026lt;br\u0026gt;(int, str, tuple, etc)\u0026#34;] pyvar --\u0026gt;|\u0026#34;Implicit References\u0026#34;| pyobj pyobj --\u0026gt; pymut \u0026amp; pyimmut pymut --\u0026gt;|\u0026#34;Can be modified\u0026lt;br\u0026gt;through reference\u0026#34;| pymut_mod[\u0026#34;‚úÖ\u0026#34;] pyimmut --\u0026gt;|\u0026#34;Creates new object\u0026lt;br\u0026gt;when \u0026#39;modified\u0026#39;\u0026#34;| pyimmut_mod[\u0026#34;‚ùå\u0026#34;] end subgraph \u0026#34;Go (Explicit Pointers)\u0026#34; style goval fill:#6366F1,stroke:#818CF8,color:#FFFFFF,font-weight:bold style goptr fill:#10B981,stroke:#34D399,color:#FFFFFF,font-weight:bold style gomem fill:#EC4899,stroke:#F472B6,color:#FFFFFF,font-weight:bold goval[\u0026#34;Value Variables\u0026lt;br\u0026gt;(int, string, struct)\u0026#34;] goptr[\u0026#34;Pointer Variables\u0026lt;br\u0026gt;(*int, *string, *struct)\u0026#34;] gomem[\u0026#34;Memory Locations\u0026#34;] goval --\u0026gt;|\u0026#34;Direct Value\u0026#34;| gomem goptr --\u0026gt;|\u0026#34;Explicit Pointer\u0026#34;| gomem gomem --\u0026gt;|\u0026#34;Modify via pointer\u0026#34;| gomod[\u0026#34;‚úÖ Developer\u0026#39;s\u0026lt;br\u0026gt;Explicit Choice\u0026#34;] end So What Are Pointers? # Pointers are variables that store memory addresses. Instead of storing values directly, they point to where those values live in memory. This seemingly simple concept unlocks powerful programming patterns and performance optimizations.\nüí° TIP Pointers provide both indirection (accessing a value through its address) and the ability to modify values across function boundaries. Here\u0026rsquo;s what a pointer looks like in Go code:\nvar x int = 42 var p *int = \u0026amp;x // p is a pointer to x The key symbols to understand:\n\u0026amp; (address-of operator): Gets the memory address of a variable * (dereference operator): Gets the value stored at that memory address Let\u0026rsquo;s visualize the core pointer concept:\n%%{init: {\u0026#39;theme\u0026#39;:\u0026#39;dark\u0026#39;}}%% flowchart LR style varX fill:#6366F1,stroke:#818CF8,color:#FFFFFF,font-weight:bold style ptrP fill:#10B981,stroke:#34D399,color:#FFFFFF,font-weight:bold style memAddress fill:#F59E0B,stroke:#FBBF24,color:#1F2937,font-weight:bold varX[\u0026#34;Variable x (42)\u0026#34;] ptrP[\u0026#34;Pointer p (*int)\u0026#34;] memAddress[\u0026#34;Memory Address 0x82c10a0\u0026#34;] ptrP --\u0026gt;|\u0026#34;points to\u0026#34;| memAddress memAddress -.-\u0026gt;|\u0026#34;stores\u0026#34;| varX How Go Manages Memory with Pointers # Go\u0026rsquo;s memory model is worth understanding when working with pointers. Unlike C, Go features automatic garbage collection, which means you don\u0026rsquo;t need to manually free memory. This prevents many common pointer-related bugs.\nHere\u0026rsquo;s a visualization of Go\u0026rsquo;s memory layout:\n%%{init: {\u0026#39;theme\u0026#39;:\u0026#39;dark\u0026#39;}}%% flowchart TD style stack fill:#8B5CF6,stroke:#A78BFA,color:#FFFFFF,font-weight:bold style heap fill:#EC4899,stroke:#F472B6,color:#FFFFFF,font-weight:bold style stackVar fill:#6366F1,stroke:#818CF8,color:#FFFFFF,font-weight:bold style heapObj fill:#F97316,stroke:#FB923C,color:#FFFFFF,font-weight:bold style pointer fill:#10B981,stroke:#34D399,color:#FFFFFF,font-weight:bold stack[\u0026#34;Stack Memory\u0026#34;] heap[\u0026#34;Heap Memory\u0026#34;] stackVar[\u0026#34;Local Variables\u0026lt;br\u0026gt;i := 10\u0026lt;br\u0026gt;p *Person\u0026#34;] heapObj[\u0026#34;Objects\u0026lt;br\u0026gt;Person{Name: \u0026#39;Alice\u0026#39;}\u0026#34;] pointer[\u0026#34;Pointer\u0026#34;] stack --- stackVar heap --- heapObj stackVar -- \u0026#34;points to\u0026#34; --\u0026gt; heapObj pointer -.- stackVar In Go:\nStack: Fast memory for local variables (automatically cleaned up when function returns) Heap: Memory for objects that outlive their creating function Garbage Collector: Automatically cleans up unreachable objects in the heap Setting Up a Go Project for Pointer Experimentation # To follow along with the examples, create a small project structure:\nmkdir pointers-demo cd pointers-demo go mod init pointers-demo touch main.go This creates a minimal Go module where you can experiment with the code examples that follow. We will be editing and running main.go throughout.\nüìå IMPORTANT Remember to run each example with go run main.go Basic Pointer Examples # Let\u0026rsquo;s start with simple, practical examples of Go pointers in action.\nExample 1: Working with Integer Pointers # package main import \u0026#34;fmt\u0026#34; func main() { // Create an integer variable count := 42 // Create a pointer to the integer countPtr := \u0026amp;count // Print the original value fmt.Println(\u0026#34;Original value:\u0026#34;, count) // Print the pointer (memory address) fmt.Println(\u0026#34;Pointer address:\u0026#34;, countPtr) // Dereference the pointer to get the value fmt.Println(\u0026#34;Dereferenced value:\u0026#34;, *countPtr) // Modify the value through the pointer *countPtr = 100 // See that the original variable was changed fmt.Println(\u0026#34;New value:\u0026#34;, count) } This example demonstrates the core operations of pointers:\nCreating a variable (count) Getting its memory address with \u0026amp; (countPtr) Accessing the value at that address with * (*countPtr) Modifying the original value through the pointer by assigning to *countPtr Let\u0026rsquo;s visualize what\u0026rsquo;s happening in memory:\n%%{init: {\u0026#39;theme\u0026#39;:\u0026#39;dark\u0026#39;}}%% flowchart LR style stack fill:#8B5CF6,stroke:#A78BFA,color:#FFFFFF,font-weight:bold style count fill:#F97316,stroke:#FB923C,color:#FFFFFF,font-weight:bold style countPtr fill:#10B981,stroke:#34D399,color:#FFFFFF,font-weight:bold style memCell fill:#EC4899,stroke:#F472B6,color:#FFFFFF,font-weight:bold stack[\u0026#34;Stack Memory\u0026#34;] count[\u0026#34;count (int)\u0026#34;] countPtr[\u0026#34;countPtr (*int)\u0026#34;] memCell[\u0026#34;Memory Cell\u0026lt;br\u0026gt;Initially: 42\u0026lt;br\u0026gt;After: 100\u0026#34;] stack --\u0026gt; count \u0026amp; countPtr countPtr --\u0026gt;|\u0026#34;points to\u0026#34;| memCell count -.-\u0026gt;|\u0026#34;direct value\u0026#34;| memCell Example 2: Working with String Pointers # Pointers work with all types in Go, including strings:\npackage main import \u0026#34;fmt\u0026#34; func main() { // Create a string variable message := \u0026#34;Hello, Go!\u0026#34; // Create a pointer to the string messagePtr := \u0026amp;message // Print original string fmt.Println(\u0026#34;Original:\u0026#34;, message) // Modify through pointer *messagePtr = \u0026#34;Updated via pointer!\u0026#34; // See the changed string fmt.Println(\u0026#34;Updated:\u0026#34;, message) } When you run this code, you\u0026rsquo;ll see that modifying the string through the pointer affects the original variable. This works because the pointer gives direct access to the memory where message is stored.\nThe memory visualization:\n%%{init: {\u0026#39;theme\u0026#39;:\u0026#39;dark\u0026#39;}}%% flowchart LR style message fill:#F97316,stroke:#FB923C,color:#FFFFFF,font-weight:bold style messagePtr fill:#10B981,stroke:#34D399,color:#FFFFFF,font-weight:bold style stringData fill:#EC4899,stroke:#F472B6,color:#FFFFFF,font-weight:bold style arrow fill:#6366F1,stroke:#818CF8,color:#FFFFFF,font-weight:bold message[\u0026#34;message (string)\u0026#34;] messagePtr[\u0026#34;messagePtr (*string)\u0026#34;] stringData[\u0026#34;String Data in Memory\u0026#34;] messagePtr --\u0026gt;|\u0026#34;points to\u0026#34;| message message --\u0026gt;|\u0026#34;initially contains\u0026#34;| stringData stringData --\u0026gt;|\u0026#34;Hello, Go!\u0026lt;br\u0026gt;‚Üì\u0026lt;br\u0026gt;Updated via pointer!\u0026#34;| arrow Example 3: Pointers to Structs # Struct pointers are extremely common in Go for modifying complex data types:\npackage main import \u0026#34;fmt\u0026#34; // Define a simple struct type Cat struct { Name string Age int Breed string } func main() { // Create a cat struct whiskers := Cat{ Name: \u0026#34;Whiskers\u0026#34;, Age: 3, Breed: \u0026#34;Maine Coon\u0026#34;, } // Create a pointer to the struct whiskersPtr := \u0026amp;whiskers // Print original struct fmt.Println(\u0026#34;Original:\u0026#34;, whiskers) // Access and modify using pointer // Go allows direct field access with struct pointers whiskersPtr.Age = 4 // This is equivalent to (*whiskersPtr).Age = 4 // See the changed struct fmt.Println(\u0026#34;Updated:\u0026#34;, whiskers) } Go provides syntax sugar for working with struct pointers. Notice that we can use whiskersPtr.Age instead of needing to write (*whiskersPtr).Age. This convenience makes working with struct pointers much more readable.\nLet\u0026rsquo;s visualize the struct pointer:\n%%{init: {\u0026#39;theme\u0026#39;:\u0026#39;dark\u0026#39;}}%% flowchart TD style whiskers fill:#F97316,stroke:#FB923C,color:#FFFFFF,font-weight:bold style whiskersPtr fill:#10B981,stroke:#34D399,color:#FFFFFF,font-weight:bold style struct fill:#EC4899,stroke:#F472B6,color:#FFFFFF,font-weight:bold style name fill:#6366F1,stroke:#818CF8,color:#FFFFFF,font-weight:bold style age fill:#6366F1,stroke:#818CF8,color:#FFFFFF,font-weight:bold style breed fill:#6366F1,stroke:#818CF8,color:#FFFFFF,font-weight:bold whiskers[\u0026#34;whiskers (Cat)\u0026#34;] whiskersPtr[\u0026#34;whiskersPtr (*Cat)\u0026#34;] struct[\u0026#34;Cat Struct\u0026#34;] name[\u0026#34;Name: \u0026#39;Whiskers\u0026#39;\u0026#34;] age[\u0026#34;Age: 3 ‚Üí 4\u0026#34;] breed[\u0026#34;Breed: \u0026#39;Maine Coon\u0026#39;\u0026#34;] whiskers --- struct struct --- name \u0026amp; age \u0026amp; breed whiskersPtr --\u0026gt;|\u0026#34;points to\u0026#34;| struct Function Parameters and Pointers # One of the most common uses of pointers in Go is to modify values within functions:\npackage main import \u0026#34;fmt\u0026#34; // This function modifies the cat via a pointer func celebrateBirthday(c *Cat) { c.Age++ fmt.Println(\u0026#34;Happy Birthday, \u0026#34; + c.Name + \u0026#34;! You are now\u0026#34;, c.Age) } type Cat struct { Name string Age int Breed string } func main() { mittens := Cat{ Name: \u0026#34;Mittens\u0026#34;, Age: 2, Breed: \u0026#34;Tabby\u0026#34;, } fmt.Println(\u0026#34;Before:\u0026#34;, mittens) // Pass a pointer to the cat celebrateBirthday(\u0026amp;mittens) fmt.Println(\u0026#34;After:\u0026#34;, mittens) } Without pointers, Go is pass-by-value, meaning functions receive copies of arguments. By passing a pointer, you\u0026rsquo;re enabling the function to modify the original value. The celebrateBirthday function can directly modify the Person struct passed to it.\nThe function flow:\n%%{init: {\u0026#39;theme\u0026#39;:\u0026#39;dark\u0026#39;}}%% flowchart LR style main fill:#8B5CF6,stroke:#A78BFA,color:#FFFFFF,font-weight:bold style func fill:#EC4899,stroke:#F472B6,color:#FFFFFF,font-weight:bold style mittens fill:#F97316,stroke:#FB923C,color:#FFFFFF,font-weight:bold style cParam fill:#10B981,stroke:#34D399,color:#FFFFFF,font-weight:bold main[\u0026#34;main() function\u0026#34;] func[\u0026#34;celebrateBirthday() function\u0026#34;] mittens[\u0026#34;mittens: Cat\u0026lt;br\u0026gt;Age: 2 ‚Üí 3\u0026#34;] cParam[\u0026#34;c *Cat\u0026lt;br\u0026gt;(points to mittens)\u0026#34;] main --\u0026gt;|\u0026#34;call with \u0026amp;mittens\u0026#34;| func main --- mittens func --- cParam cParam --\u0026gt;|\u0026#34;modifies\u0026#34;| mittens Nil Pointers and Safety # Pointers in Go have a zero value of nil, which requires careful handling:\npackage main import \u0026#34;fmt\u0026#34; func main() { var ptr *int // Declared but not initialized fmt.Println(\u0026#34;Nil pointer:\u0026#34;, ptr) // Safety check before dereferencing if ptr != nil { fmt.Println(\u0026#34;Value:\u0026#34;, *ptr) } else { fmt.Println(\u0026#34;Cannot dereference nil pointer!\u0026#34;) } // Initialize the pointer value := 42 ptr = \u0026amp;value // Now safe to dereference fmt.Println(\u0026#34;Value after initialization:\u0026#34;, *ptr) } Always check if a pointer is nil before dereferencing it. Attempting to dereference a nil pointer will cause a runtime panic, which crashes your program.\nVisualizing nil pointer safety:\n%%{init: {\u0026#39;theme\u0026#39;:\u0026#39;dark\u0026#39;}}%% flowchart TD style ptr fill:#10B981,stroke:#34D399,color:#FFFFFF,font-weight:bold style nil fill:#F43F5E,stroke:#FB7185,color:#FFFFFF,font-weight:bold style check fill:#F59E0B,stroke:#FBBF24,color:#1F2937,font-weight:bold style value fill:#8B5CF6,stroke:#A78BFA,color:#FFFFFF,font-weight:bold style memory fill:#EC4899,stroke:#F472B6,color:#FFFFFF,font-weight:bold ptr[\u0026#34;var ptr *int\u0026#34;] nil[\u0026#34;nil (zero value)\u0026#34;] check[\u0026#34;if ptr != nil\u0026#34;] value[\u0026#34;value := 42\u0026#34;] memory[\u0026#34;Memory with 42\u0026#34;] ptr --\u0026gt;|\u0026#34;initially\u0026#34;| nil nil --- check check --\u0026gt;|\u0026#34;fail\u0026#34;| safety[\u0026#34;Safety Error\u0026lt;br\u0026gt;Prevented!\u0026#34;] ptr -.-\u0026gt;|\u0026#34;later assigned\u0026#34;| memory value --- memory Advanced Pointer Example: Custom Data Structure with Pointers # Let\u0026rsquo;s build a simple linked list, one of the classic data structures that relies on pointers:\npackage main import \u0026#34;fmt\u0026#34; // CatNode represents a node in a linked list of cats type CatNode struct { Name string Age int Next *CatNode // Pointer to the next cat node } // CatList represents a linked list of cats type CatList struct { Head *CatNode } // AddCat adds a new cat node to the end of the list func (l *CatList) AddCat(name string, age int) { newCat := \u0026amp;CatNode{Name: name, Age: age} if l.Head == nil { l.Head = newCat return } current := l.Head for current.Next != nil { current = current.Next } current.Next = newCat } // PrintCats prints all cats in the list func (l *CatList) PrintCats() { current := l.Head for current != nil { fmt.Printf(\u0026#34;%s (age %d) -\u0026gt; \u0026#34;, current.Name, current.Age) current = current.Next } fmt.Println(\u0026#34;nil\u0026#34;) } func main() { // Create a new cat list catList := CatList{} // Add cat nodes catList.AddCat(\u0026#34;Whiskers\u0026#34;, 3) catList.AddCat(\u0026#34;Mittens\u0026#34;, 2) catList.AddCat(\u0026#34;Felix\u0026#34;, 5) // Print the list catList.PrintCats() // Output: Whiskers (age 3) -\u0026gt; Mittens (age 2) -\u0026gt; Felix (age 5) -\u0026gt; nil } This example demonstrates how pointers enable the creation of a linked list data structure:\nEach CatNode contains cat information and a pointer to the next node The CatList has a pointer to the head cat node The AddCat method traverses the list using pointers The PrintCats method also traverses the list with pointers Without pointers, implementing a linked list would be significantly more complex, if not im-paw-ssible.\nWhen to Use Pointers in Go # Here\u0026rsquo;s a decision guide for when pointers make the most sense:\n%%{init: {\u0026#39;theme\u0026#39;:\u0026#39;dark\u0026#39;}}%% flowchart TD style start fill:#8B5CF6,stroke:#A78BFA,color:#FFFFFF,font-weight:bold style q1 fill:#F97316,stroke:#FB923C,color:#FFFFFF,font-weight:bold style q2 fill:#F97316,stroke:#FB923C,color:#FFFFFF,font-weight:bold style q3 fill:#F97316,stroke:#FB923C,color:#FFFFFF,font-weight:bold style usePointer fill:#10B981,stroke:#34D399,color:#FFFFFF,font-weight:bold style useValue fill:#F43F5E,stroke:#FB7185,color:#FFFFFF,font-weight:bold start[\u0026#34;Do I need a pointer?\u0026#34;] q1[\u0026#34;Need to modify the\u0026lt;br\u0026gt;variable in a function?\u0026#34;] q2[\u0026#34;Working with a large\u0026lt;br\u0026gt;struct or array?\u0026#34;] q3[\u0026#34;Need to express\u0026lt;br\u0026gt;optional/nil state?\u0026#34;] usePointer[\u0026#34;Use a pointer (*T)\u0026#34;] useValue[\u0026#34;Use a value (T)\u0026#34;] start --\u0026gt; q1 \u0026amp; q2 \u0026amp; q3 q1 --\u0026gt;|\u0026#34;Yes\u0026#34;| usePointer q2 --\u0026gt;|\u0026#34;Yes\u0026#34;| usePointer q3 --\u0026gt;|\u0026#34;Yes\u0026#34;| usePointer q1 --\u0026gt;|\u0026#34;No\u0026#34;| useValue q2 --\u0026gt;|\u0026#34;No\u0026#34;| useValue q3 --\u0026gt;|\u0026#34;No\u0026#34;| useValue üí° TIP Use pointers when you need to modify a value, when working with large data structures, or when you need to represent the absence of a value with nil. Common Pitfalls with Pointers # While Go\u0026rsquo;s pointers are safer than those in C/C++, there are still some common mistakes to avoid:\nForgetting to check for nil: Always check if a pointer is nil before dereferencing it. (I\u0026rsquo;m definitely guilty of failing to do this on projects) Returning pointers to stack variables: Don\u0026rsquo;t return pointers to local variables, as they become invalid when the function returns. Unnecessary pointer usage: Using pointers for small, simple values can actually be less efficient due to indirection and garbage collection overhead. Pointer arithmetic: Go intentionally does not support pointer arithmetic to prevent buffer overflows and other memory corruption issues. Wrapping Up # Pointers in Go provide a powerful way to work with memory directly without the complexity and danger often associated with pointers in languages like C. They enable efficient memory usage and allow you to implement complex data structures like linked lists, trees, and graphs.\nKey takeaways:\nPointers store memory addresses, not values Use \u0026amp; to get an address, * to get the value at an address Pointers enable call-by-reference for modifying values in functions The zero value of a pointer is nil Always check for nil before dereferencing Pointers are crucial for implementing data structures like linked lists By now, you should have a solid understanding of how pointers work in Go and be ready to use them in your projects. Start simple, experiment, and gradually incorporate these concepts into your Go programming toolkit.\n","date":"Feb 28, 2025","permalink":"https://blog.mikesahari.com/posts/go-pointers/","tags":["go","pointers","memory","fundamentals"],"title":"A Guide to Pointers in Go"},{"content":"Hello fellow Gophers!\nI\u0026rsquo;m absolutely thrilled to dive deep into one of Go\u0026rsquo;s most elegant features: Channels! If you\u0026rsquo;re just starting your Go journey or looking to level up your concurrency game, you\u0026rsquo;re in for a treat.\nChannels are the communication mechanism that makes goroutines work together efficiently and safely. They enable goroutines to exchange data without shared memory, reducing the risk of race conditions.\nI hate to use an analogy here, but imagine you have a team of engineers working on some big company project.. let\u0026rsquo;s call it Kilonova.\nFor project Kilonova to be complete, your engineers need to meet to chat and exchange information, along with completing their work. Channels are that method of meeting. They are an area where your goroutines‚ÄîI mean engineers can communicate to complete Kilonova. Without channels, it would be like the team of engineers never talk to each other and go about working in silos (and we all know how well that works out! üòÖ).\nAnalogy out of the way, this blog post is full of material because I have tons of notes (I use Obsidian btw) on Go Channels. Let\u0026rsquo;s dive in.\nTable of Contents # Understanding Go Channels Basic Channel Operations Example: Sending and Receiving Data Detecting Closed Channels Example: Checking if a Channel is Open Common Gotcha: Sending on Closed Channels Iterating Over Channels with range Example: Using range with Channels Unbuffered Channels: Synchronous Communication Example: Unbuffered Channel in Action When to Use Unbuffered Channels Buffered Channels: Asynchronous Communication Example: Buffered Channel in Action Choosing the Right Buffer Size Select Statement: The Channel Traffic Controller Example: Timeouts with Select Example: Non-blocking Channel Operations Channel Direction: Type-Safe Communication Example: Using Channel Direction in Functions Real-Life Use Cases for Channels 1. Background Task Processing 2. Building a Terminal UI with Charm\u0026rsquo;s Bubble Tea 3. Worker Pool for Efficient Parallel Processing 4. Fan-out, Fan-in Pattern 5. Rate Limiting and Throttling Advanced Channel Patterns Done Channel Pattern Pipeline Pattern Or-Done Channel Pattern Best Practices and Common Pitfalls Memory Leaks: Forgotten Goroutines Deadlocks: The Concurrency Standoff Race Conditions: Timing Is Everything Wrapping Up Understanding Go Channels # A channel in Go is a typed communication conduit that connects concurrent goroutines. Channels implement the \u0026ldquo;don\u0026rsquo;t communicate by sharing memory; share memory by communicating\u0026rdquo; philosophy that makes Go concurrency effective and safe.\nüìù NOTE Channels ensure type-safe communication between goroutines and provide built-in synchronization. Channels come in two varieties:\nUnbuffered Channels: Synchronous communication where sender and receiver must be ready simultaneously Buffered Channels: Allow sending multiple values without an immediate receiver (up to the buffer capacity) Basic Channel Operations # // Creating channels ch := make(chan string) // Unbuffered channel of strings bufferedCh := make(chan int, 10) // Buffered channel of ints with capacity 10 // Sending values (note the arrow points INTO the channel) ch \u0026lt;- \u0026#34;I languish\u0026#34; // Send a string into the channel bufferedCh \u0026lt;- 42 // Send an int into the buffered channel // Receiving values (arrow points OUT FROM the channel) message := \u0026lt;-ch // Receive a value and assign it value := \u0026lt;-bufferedCh // Receive from buffered channel \u0026lt;-ch // Receive and discard the value // Closing a channel close(ch) // Prevent further sends Example: Sending and Receiving Data # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { ch := make(chan string) // Anonymous function as a goroutine go func() { // Simulate work with a slight delay time.Sleep(100 * time.Millisecond) ch \u0026lt;- \u0026#34;Buy more coffee!\u0026#34; }() // Main goroutine receives the message msg := \u0026lt;-ch fmt.Println(msg) } Output:\nBuy more coffee! In this example, I\u0026rsquo;m creating a goroutine that sends a message through the channel after a brief pause (simulating actual work). Meanwhile, the main goroutine waits to receive that message before printing it out.\nThis demonstrates how channels naturally synchronize concurrent operations without explicit locks or condition variables.\nDetecting Closed Channels # When working with channels, determining if a channel has been closed is important! Go provides a two-value assignment idiom for this purpose:\nExample: Checking if a Channel is Open # package main import \u0026#34;fmt\u0026#34; func main() { jobs := make(chan int, 5) done := make(chan bool) // Producer goroutine go func() { for i := 1; i \u0026lt;= 3; i++ { jobs \u0026lt;- i } close(jobs) // No more jobs to send fmt.Println(\u0026#34;All jobs sent!\u0026#34;) }() // Consumer goroutine go func() { for { job, more := \u0026lt;-jobs // Check if channel is still open if more { fmt.Println(\u0026#34;Received job:\u0026#34;, job) } else { fmt.Println(\u0026#34;All jobs received!\u0026#34;) done \u0026lt;- true return } } }() \u0026lt;-done // Wait for the worker to finish } Output:\nAll jobs sent! Received job: 1 Received job: 2 Received job: 3 All jobs received! If the code was a little to dense, this flow chart shows the logic:\nflowchart TD A[Start] --\u0026gt; B{Receive from Channel} B --\u0026gt;|ok == true| C[Channel is open - Received valid value] B --\u0026gt;|ok == false| D[Channel is closed - No more values] C --\u0026gt; E[Process the value] E --\u0026gt; B D --\u0026gt; F[Exit loop or perform cleanup] class C green class D red classDef green fill:#d1e7dd,stroke:#13795b,color:#0a3622 classDef red fill:#f8d7da,stroke:#842029,color:#58151c Common Gotcha: Sending on Closed Channels # An important fact to remember: sending on a closed channel causes a panic.\nch := make(chan int) close(ch) ch \u0026lt;- 1 // PANIC: send on closed channel The fix is straightforward: ensure proper coordination of channel closure, typically by having only the sender close the channel.\nIterating Over Channels with range # The range keyword provides an elegant way to receive values from a channel until it\u0026rsquo;s closed.\nExample: Using range with Channels # package main import \u0026#34;fmt\u0026#34; func main() { ch := make(chan string, 3) // Send some messages and close go func() { messages := []string{\u0026#34;Orange\u0026#34;, \u0026#34;LaCroix\u0026#34;, \u0026#34;Cat\u0026#34;} for _, msg := range messages { ch \u0026lt;- msg } close(ch) // Important! Range needs this to stop }() // Receive with range - much cleaner! for msg := range ch { fmt.Println(\u0026#34;Got message:\u0026#34;, msg) } fmt.Println(\u0026#34;Channel closed, no more messages.\u0026#34;) } Output:\nGot message: Orange Got message: LaCroix Got message: Cat Channel closed, no more messages. Using range with channels eliminates the need for manual checking with the comma-ok syntax, resulting in more readable code.\nHere is a flowchart to help understand the above code:\nflowchart TD A[Start] --\u0026gt; B[Create Channel] B --\u0026gt; C[Launch Goroutine to Send Values] C --\u0026gt; D[Close Channel When Done Sending] B --\u0026gt; E[Iterate with for val := range ch] E --\u0026gt; F{More Values?} F --\u0026gt;|Yes| G[Process Value] G --\u0026gt; F F --\u0026gt;|No| H[Loop Exits Automatically] D -.-\u0026gt; F classDef important fill:#ffc107,stroke:#fd7e14,color:#000 class D important Unbuffered Channels: Synchronous Communication # Unbuffered channels enforce synchronization between goroutines. They ensure that the sender and receiver rendezvous at the same point in execution.\nExample: Unbuffered Channel in Action # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { ch := make(chan string) // Unbuffered channel go func() { fmt.Println(\u0026#34;Goroutine: Ready to send message\u0026#34;) time.Sleep(2 * time.Second) // Simulate work fmt.Println(\u0026#34;Goroutine: Sending message...\u0026#34;) ch \u0026lt;- \u0026#34;Synchronous Message\u0026#34; fmt.Println(\u0026#34;Goroutine: Message sent!\u0026#34;) }() time.Sleep(1 * time.Second) // Main thread does other work fmt.Println(\u0026#34;Main: Ready to receive\u0026#34;) msg := \u0026lt;-ch // Will block until sender delivers fmt.Println(\u0026#34;Main: Received:\u0026#34;, msg) } Output:\nGoroutine: Ready to send message Main: Ready to receive Goroutine: Sending message... Goroutine: Message sent! Main: Received: Synchronous Message The receiver waits for the sender, and the sender doesn\u0026rsquo;t continue until the receiver has taken the message. This demonstrates the synchronization that unbuffered channels provide.\nThe flowchart breaks down the logic:\nflowchart TD A[Start] --\u0026gt; B[Create Unbuffered Channel] %% Sender flow B --\u0026gt; C[Goroutine 1: Sender] C --\u0026gt; D[Prepare value] D --\u0026gt; E[Attempt to send] E --\u0026gt; F[Block until receiver ready] F --\u0026gt; G[Transfer value] G --\u0026gt; H[Continue execution] %% Receiver flow B --\u0026gt; I[Goroutine 2: Receiver] I --\u0026gt; J[Attempt to receive] J --\u0026gt; K[Block until sender ready] K --\u0026gt; L[Accept value] L --\u0026gt; M[Continue execution] %% Synchronization point F --- K G --- L classDef sendBlock fill:#ff8080,stroke:#cc0000,color:#000000 classDef receiveBlock fill:#80ff80,stroke:#00cc00,color:#000000 classDef syncPoint fill:#ffdd80,stroke:#cc9900,color:#000000 class F sendBlock class K receiveBlock class G syncPoint class L syncPoint When to Use Unbuffered Channels # Unbuffered channels are particularly useful when:\nYou need a strict handshake between goroutines The timing of operations is critical You want to limit concurrent operations You\u0026rsquo;re implementing request/response patterns Buffered Channels: Asynchronous Communication # Buffered channels add capacity, allowing multiple values to be sent without an immediate receiver.\nExample: Buffered Channel in Action # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { // Buffered channel with room for 2 messages ch := make(chan string, 2) go func() { messages := []string{\u0026#34;First\u0026#34;, \u0026#34;Second\u0026#34;, \u0026#34;Third\u0026#34;} for i, msg := range messages { fmt.Printf(\u0026#34;Sending message %d: %s\\n\u0026#34;, i+1, msg) ch \u0026lt;- msg fmt.Printf(\u0026#34;Sent message %d\\n\u0026#34;, i+1) } }() // Give goroutine time to send messages time.Sleep(1 * time.Second) // Now receive them all for i := 0; i \u0026lt; 3; i++ { msg := \u0026lt;-ch fmt.Printf(\u0026#34;Received: %s\\n\u0026#34;, msg) time.Sleep(500 * time.Millisecond) // Process each message } } Output:\nSending message 1: First Sent message 1 Sending message 2: Second Sent message 2 Sending message 3: Third Received: First Received: Second Sent message 3 Received: Third The first two sends complete immediately, but the third one has to wait until we receive a message and free up buffer space. This demonstrates how buffered channels work.\nLogic Flowchart:\nflowchart TD A[Start] --\u0026gt; B[Create Buffered Channel with capacity N] %% Sender flow B --\u0026gt; C[Goroutine 1: Sender] C --\u0026gt; D[Prepare value] D --\u0026gt; E[Attempt to send] E --\u0026gt; F{Buffer full?} F --\u0026gt;|Yes| G[Block until space available] F --\u0026gt;|No| H[Store in buffer and continue] G --\u0026gt; H H --\u0026gt; I[Sender continues execution] %% Receiver flow B --\u0026gt; J[Goroutine 2: Receiver] J --\u0026gt; K[Attempt to receive] K --\u0026gt; L{Buffer empty?} L --\u0026gt;|Yes| M[Block until data available] L --\u0026gt;|No| N[Take from buffer and continue] M --\u0026gt; N N --\u0026gt; O[Receiver continues execution] %% Buffer state affects both sides H -.-\u0026gt; L N -.-\u0026gt; F classDef sendBlock fill:#ff8080,stroke:#cc0000,color:#000000 classDef receiveBlock fill:#80ff80,stroke:#00cc00,color:#000000 classDef buffer fill:#80b3ff,stroke:#0066cc,color:#000000 classDef decision fill:#d9d9d9,stroke:#666666,color:#000000 class G sendBlock class M receiveBlock class B,H,N buffer class F,L decision Choosing the Right Buffer Size # Buffer size selection has important implications:\nBuffer size = 0: Use when synchronization is required Buffer size = 1: Use when you want to decouple sender and receiver but still control flow Buffer size = N: Use when you can predict peak load or want to handle bursts of activity Very large buffers: Be cautious‚Äîthey can hide backpressure issues and lead to memory problems Select Statement: The Channel Traffic Controller # The select statement allows a goroutine to wait on multiple channel operations simultaneously.\nExample: Timeouts with Select # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { ch := make(chan string) go func() { // Simulating a slow operation time.Sleep(2 * time.Second) ch \u0026lt;- \u0026#34;Operation completed\u0026#34; }() // Wait with timeout using select select { case result := \u0026lt;-ch: fmt.Println(\u0026#34;Success:\u0026#34;, result) case \u0026lt;-time.After(1 * time.Second): fmt.Println(\u0026#34;Timeout: operation took too long!\u0026#34;) } } Output:\nTimeout: operation took too long! The logic for this example is as follows:\nflowchart TD A[Start] --\u0026gt; B[Create channel for operation] B --\u0026gt; C[Start goroutine for long-running operation] C --\u0026gt; D[Operation running] D --\u0026gt; E[Send result to channel when done] B --\u0026gt; F[Set up timeout with time.After] F --\u0026gt; G[Enter select statement] G --\u0026gt; H{Which case is ready first?} H --\u0026gt;|Result channel| I[Process result] H --\u0026gt;|Timeout channel| J[Handle timeout] I --\u0026gt; K[Operation completed successfully] J --\u0026gt; L[Operation timed out] classDef normal fill:#d9d9d9,stroke:#666666,color:#000000 classDef success fill:#80ff80,stroke:#00cc00,color:#000000 classDef timeout fill:#ff8080,stroke:#cc0000,color:#000000 classDef select fill:#ffdd80,stroke:#cc9900,color:#000000 class A,B,C,D,E,F normal class G,H select class I,K success class J,L timeout This pattern is valuable for preventing goroutines from blocking indefinitely and is commonly used in production services to ensure responsiveness.\nExample: Non-blocking Channel Operations # package main import \u0026#34;fmt\u0026#34; func main() { ch := make(chan string) // Try to receive, but don\u0026#39;t block select { case msg := \u0026lt;-ch: fmt.Println(\u0026#34;Received:\u0026#34;, msg) default: fmt.Println(\u0026#34;No message available\u0026#34;) } // Try to send, but don\u0026#39;t block select { case ch \u0026lt;- \u0026#34;Hello\u0026#34;: fmt.Println(\u0026#34;Sent message\u0026#34;) default: fmt.Println(\u0026#34;Cannot send: no receiver ready\u0026#34;) } } Output:\nNo message available Cannot send: no receiver ready Here\u0026rsquo;s what the non-blocking logic looks like:\nflowchart TD A[Start] --\u0026gt; B[Create channel] B --\u0026gt; C[Enter select statement] C --\u0026gt; D{Which case is ready?} D --\u0026gt;|Send case| E[Can send immediately?] D --\u0026gt;|Receive case| F[Can receive immediately?] D --\u0026gt;|Default case| G[No operation ready] E --\u0026gt;|Yes| H[Send value and continue] E --\u0026gt;|No| G F --\u0026gt;|Yes| I[Receive value and continue] F --\u0026gt;|No| G G --\u0026gt; J[Execute default case and continue] H --\u0026gt; K[Continue program flow] I --\u0026gt; K J --\u0026gt; K classDef normal fill:#d9d9d9,stroke:#666666,color:#000000 classDef sendOp fill:#80ff80,stroke:#00cc00,color:#000000 classDef recvOp fill:#80b3ff,stroke:#0066cc,color:#000000 classDef defaultCase fill:#ffdd80,stroke:#cc9900,color:#000000 classDef select fill:#d9d9d9,stroke:#666666,color:#000000,stroke-width:3px class A,B,K normal class C,D select class E,H sendOp class F,I recvOp class G,J defaultCase The default case in select makes channel operations non-blocking, which is useful when implementing complex event processing systems.\nChannel Direction: Type-Safe Communication # Go allows specifying channel direction in function signatures, providing additional type safety to concurrent code.\nExample: Using Channel Direction in Functions # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) // This function can only send to the channel func producer(ch chan\u0026lt;- string) { for i := 0; i \u0026lt; 3; i++ { ch \u0026lt;- fmt.Sprintf(\u0026#34;Message %d\u0026#34;, i+1) time.Sleep(100 * time.Millisecond) } close(ch) } // This function can only receive from the channel func consumer(ch \u0026lt;-chan string, done chan\u0026lt;- bool) { for msg := range ch { fmt.Println(\u0026#34;Consumed:\u0026#34;, msg) } done \u0026lt;- true } func main() { ch := make(chan string) done := make(chan bool) go producer(ch) go consumer(ch, done) \u0026lt;-done // Wait for consumer to finish } Output:\nConsumed: Message 1 Consumed: Message 2 Consumed: Message 3 We can see the logic as:\nflowchart TD A[Start] --\u0026gt; B[Create bidirectional channel: chan T] B --\u0026gt; C[Pass to Producer as: chan\u0026lt;- T] B --\u0026gt; D[Pass to Consumer as: \u0026lt;-chan T] C --\u0026gt; E[Producer function] D --\u0026gt; F[Consumer function] E --\u0026gt; G[Can only send to channel] F --\u0026gt; H[Can only receive from channel] G --\u0026gt; I[Compile-time safety] H --\u0026gt; I I --\u0026gt; J[No accidental receives in Producer] I --\u0026gt; K[No accidental sends in Consumer] subgraph Functions E F end subgraph Restrictions G H end subgraph Benefits I J K end classDef normal fill:#d9d9d9,stroke:#666666,color:#000000 classDef producer fill:#80ff80,stroke:#00cc00,color:#000000 classDef consumer fill:#80b3ff,stroke:#0066cc,color:#000000 classDef bidirectional fill:#ffdd80,stroke:#cc9900,color:#000000 classDef benefit fill:#d9d9d9,stroke:#666666,color:#000000,stroke-width:3px class A,I,J,K normal class B bidirectional class C,E,G producer class D,F,H consumer Using directional channels (chan\u0026lt;- for send-only and \u0026lt;-chan for receive-only) adds compile-time safety. The compiler prevents accidental sends on receive-only channels and vice versa.\nReal-Life Use Cases for Channels # Here are practical scenarios where channels prove invaluable:\n1. Background Task Processing # When building web applications, channels excel at handling tasks that shouldn\u0026rsquo;t block the request-response cycle:\n// Simplified example: Image processing service type ImageProcessor struct { tasks chan Task results chan Result errors chan error workers int } func NewImageProcessor(workers int) *ImageProcessor { ip := \u0026amp;ImageProcessor{ tasks: make(chan Task), results: make(chan Result), errors: make(chan error), workers: workers, } ip.Start() return ip } func (ip *ImageProcessor) Start() { for i := 0; i \u0026lt; ip.workers; i++ { go func(workerID int) { for task := range ip.tasks { fmt.Printf(\u0026#34;Worker %d processing image: %s\\n\u0026#34;, workerID, task.ImageID) // Process image (resize, filter, etc.) if err := processImage(task); err != nil { ip.errors \u0026lt;- err continue } ip.results \u0026lt;- Result{TaskID: task.ID, Status: \u0026#34;completed\u0026#34;} } }(i) } } func (ip *ImageProcessor) ProcessAsync(task Task) { ip.tasks \u0026lt;- task } I implemented a similar pattern in a photo-sharing application. The web server immediately returned a \u0026ldquo;processing\u0026rdquo; status to the client while the actual image manipulation happened asynchronously via channels.\n2. Building a Terminal UI with Charm\u0026rsquo;s Bubble Tea # Bubble Tea is a framework for terminal UIs (TUIs) that uses a message-passing model with channels under the hood. I LOVE Bubble Tea for TUIs. I created an amazing TUI last year using Bubble Tea and gave it a retro name. Alas, I cannot share that code, but I can provide you this basic example.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/charmbracelet/bubbletea\u0026#34; ) // Define our model type model struct { messages chan string log []string loading bool } // Initialize the model func (m model) Init() bubbletea.Cmd { return func() bubbletea.Msg { time.Sleep(2 * time.Second) return loadedMsg(\u0026#34;Initial data loaded\u0026#34;) } } // Define messages type tickMsg time.Time type loadedMsg string type errorMsg struct{ err error } // Update the model based on messages func (m model) Update(msg bubbletea.Msg) (bubbletea.Model, bubbletea.Cmd) { switch msg := msg.(type) { case loadedMsg: m.loading = false m.log = append(m.log, string(msg)) return m, nil case tickMsg: return m, nil case errorMsg: m.loading = false m.log = append(m.log, \u0026#34;Error: \u0026#34;+msg.err.Error()) return m, nil } return m, nil } // Render the UI func (m model) View() string { if m.loading { return \u0026#34;Loading...\\n\u0026#34; } s := \u0026#34;Activity Log:\\n\u0026#34; for _, entry := range m.log { s += fmt.Sprintf(\u0026#34;‚Ä¢ %s\\n\u0026#34;, entry) } return s + \u0026#34;\\nPress Ctrl+C to quit\u0026#34; } func main() { initialModel := model{ messages: make(chan string), loading: true, } p := bubbletea.NewProgram(initialModel) if err := p.Start(); err != nil { fmt.Println(\u0026#34;Error running program:\u0026#34;, err) } } 3. Worker Pool for Efficient Parallel Processing # Worker pools are a classic use case for channels, allowing you to process multiple tasks concurrently while controlling resource usage:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) // Task represents work to be done type Task struct { ID int Payload string } // Result represents completed work type Result struct { TaskID int Output string Completed time.Time } func worker(id int, tasks \u0026lt;-chan Task, results chan\u0026lt;- Result, wg *sync.WaitGroup) { defer wg.Done() for task := range tasks { fmt.Printf(\u0026#34;Worker %d processing task %d\\n\u0026#34;, id, task.ID) // Simulate varying processing times processingTime := time.Duration(task.ID*200) * time.Millisecond time.Sleep(processingTime) // Send the result back results \u0026lt;- Result{ TaskID: task.ID, Output: fmt.Sprintf(\u0026#34;Processed: %s\u0026#34;, task.Payload), Completed: time.Now(), } } } func main() { // Create channels for tasks and results tasks := make(chan Task, 10) results := make(chan Result, 10) // Launch a pool of workers numWorkers := 3 var wg sync.WaitGroup // Start workers for i := 1; i \u0026lt;= numWorkers; i++ { wg.Add(1) go worker(i, tasks, results, \u0026amp;wg) } // Send work go func() { for i := 1; i \u0026lt;= 9; i++ { tasks \u0026lt;- Task{ ID: i, Payload: fmt.Sprintf(\u0026#34;Task data %d\u0026#34;, i), } } close(tasks) // No more tasks to send }() // Start a goroutine to close results channel when all workers done go func() { wg.Wait() close(results) }() // Collect results for result := range results { fmt.Printf(\u0026#34;Result: task %d completed at %v with output: %s\\n\u0026#34;, result.TaskID, result.Completed.Format(\u0026#34;15:04:05.000\u0026#34;), result.Output) } } This pattern is great for services that need to make many API calls or database queries in parallel. It\u0026rsquo;s more efficient than sequential processing while still controlling resource usage by limiting concurrency.\n4. Fan-out, Fan-in Pattern # This pattern distributes work to multiple goroutines and then combines their results:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func generator(nums ...int) \u0026lt;-chan int { out := make(chan int) go func() { for _, n := range nums { out \u0026lt;- n } close(out) }() return out } func square(in \u0026lt;-chan int) \u0026lt;-chan int { out := make(chan int) go func() { for n := range in { out \u0026lt;- n * n } close(out) }() return out } func merge(cs ...\u0026lt;-chan int) \u0026lt;-chan int { var wg sync.WaitGroup out := make(chan int) // Start an output goroutine for each input channel output := func(c \u0026lt;-chan int) { for n := range c { out \u0026lt;- n } wg.Done() } wg.Add(len(cs)) for _, c := range cs { go output(c) } // Start a goroutine to close out once all output goroutines are done go func() { wg.Wait() close(out) }() return out } func main() { in := generator(1, 2, 3, 4, 5, 6, 7, 8, 9, 10) // Distribute work to 3 goroutines that all read from in c1 := square(in) c2 := square(in) c3 := square(in) // Consume the merged output from c1, c2, and c3 for result := range merge(c1, c2, c3) { fmt.Println(result) } } This pattern is powerful for data processing pipelines, especially when different stages have different performance characteristics.\n5. Rate Limiting and Throttling # Channels are excellent for implementing rate limiters:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) // RateLimiter limits the frequency of operations type RateLimiter struct { ticker *time.Ticker tokens chan struct{} quit chan struct{} } func NewRateLimiter(rate time.Duration) *RateLimiter { rl := \u0026amp;RateLimiter{ ticker: time.NewTicker(rate), tokens: make(chan struct{}, 1), // Buffer of 1 for non-blocking operations quit: make(chan struct{}), } // Start the token generator go func() { for { select { case \u0026lt;-rl.ticker.C: // Try to add a token select { case rl.tokens \u0026lt;- struct{}{}: // Token added default: // Buffer full, token dropped } case \u0026lt;-rl.quit: rl.ticker.Stop() return } } }() return rl } func (rl *RateLimiter) Wait() { \u0026lt;-rl.tokens } func (rl *RateLimiter) Stop() { close(rl.quit) } func main() { // Create a rate limiter allowing one operation per second limiter := NewRateLimiter(time.Second) defer limiter.Stop() // Simulate making rate-limited API calls for i := 1; i \u0026lt;= 5; i++ { limiter.Wait() // This blocks until a token is available fmt.Printf(\u0026#34;%s: Performing operation %d\\n\u0026#34;, time.Now().Format(\u0026#34;15:04:05\u0026#34;), i) } } I wonder if AWS\u0026rsquo;s IAM Identity Center\u0026rsquo;s APIs have something like this implemented. Their UI is not built for speed and my Go solutions just get rate limited\u0026hellip;\nAdvanced Channel Patterns # Several channel patterns solve specific concurrency challenges:\nDone Channel Pattern # The \u0026ldquo;done channel\u0026rdquo; pattern provides a clean way to signal cancellation to multiple goroutines:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func worker(id int, jobs \u0026lt;-chan int, done \u0026lt;-chan struct{}) { for { select { case \u0026lt;-done: fmt.Printf(\u0026#34;Worker %d shutting down\\n\u0026#34;, id) return case job, ok := \u0026lt;-jobs: if !ok { return // Channel closed } fmt.Printf(\u0026#34;Worker %d started job %d\\n\u0026#34;, id, job) time.Sleep(500 * time.Millisecond) fmt.Printf(\u0026#34;Worker %d finished job %d\\n\u0026#34;, id, job) } } } func main() { jobs := make(chan int, 10) done := make(chan struct{}) // Start workers for i := 1; i \u0026lt;= 3; i++ { go worker(i, jobs, done) } // Send some jobs for j := 1; j \u0026lt;= 5; j++ { jobs \u0026lt;- j } // Wait a bit then terminate all workers time.Sleep(1500 * time.Millisecond) close(done) // Give them time to shut down time.Sleep(500 * time.Millisecond) fmt.Println(\u0026#34;All workers shut down\u0026#34;) } This pattern is essential for graceful shutdowns and cancellations in production services.\nPipeline Pattern # The pipeline pattern connects stages of processing with channels:\npackage main import \u0026#34;fmt\u0026#34; func generator(max int) \u0026lt;-chan int { out := make(chan int) go func() { for i := 1; i \u0026lt;= max; i++ { out \u0026lt;- i } close(out) }() return out } func square(in \u0026lt;-chan int) \u0026lt;-chan int { out := make(chan int) go func() { for n := range in { out \u0026lt;- n * n } close(out) }() return out } func odd(in \u0026lt;-chan int) \u0026lt;-chan int { out := make(chan int) go func() { for n := range in { if n%2 != 0 { out \u0026lt;- n } } close(out) }() return out } func sum(in \u0026lt;-chan int) \u0026lt;-chan int { out := make(chan int) go func() { total := 0 for n := range in { total += n } out \u0026lt;- total close(out) }() return out } func main() { // Create a pipeline: generate numbers -\u0026gt; square them -\u0026gt; keep odd ones -\u0026gt; sum them result := sum(odd(square(generator(10)))) // Get the final result fmt.Println(\u0026#34;Sum of odd squares:\u0026#34;, \u0026lt;-result) } Each stage focuses on a single responsibility, making the code modular and easy to test.\nOr-Done Channel Pattern # This pattern allows waiting for multiple events but exiting when the first one occurs or when a cancellation signal arrives:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func orDone(done \u0026lt;-chan struct{}, c \u0026lt;-chan string) \u0026lt;-chan string { valStream := make(chan string) go func() { defer close(valStream) for { select { case \u0026lt;-done: return case v, ok := \u0026lt;-c: if !ok { return } select { case valStream \u0026lt;- v: case \u0026lt;-done: return } } } }() return valStream } func main() { done := make(chan struct{}) // Simulate services that complete at different times serviceA := make(chan string) serviceB := make(chan string) serviceC := make(chan string) go func() { time.Sleep(2 * time.Second) serviceA \u0026lt;- \u0026#34;Service A completed\u0026#34; close(serviceA) }() go func() { time.Sleep(1 * time.Second) serviceB \u0026lt;- \u0026#34;Service B completed\u0026#34; close(serviceB) }() go func() { time.Sleep(3 * time.Second) serviceC \u0026lt;- \u0026#34;Service C completed\u0026#34; close(serviceC) }() // Monitor all services with the orDone pattern for val := range orDone(done, serviceB) { fmt.Println(val) // We got a result, so cancel the operation close(done) } fmt.Println(\u0026#34;Operation completed or canceled\u0026#34;) } This pattern is valuable when waiting for the first of several concurrent operations to complete.\nBest Practices and Common Pitfalls # Memory Leaks: Forgotten Goroutines # A common issue in Go is launching goroutines without ensuring they terminate:\n// DON\u0026#39;T do this in production code func processRequest(req Request) { go func() { // This goroutine might never terminate if the channel is never read from results \u0026lt;- process(req) }() // No way to cancel or wait for completion } Always provide a way to terminate goroutines, especially in long-running applications:\n// Better approach func processRequest(req Request, ctx context.Context) { go func() { select { case \u0026lt;-ctx.Done(): return // Cancellation signal received case results \u0026lt;- process(req): // Successfully sent result } }() } Deadlocks: The Concurrency Standoff # Deadlocks occur when goroutines are waiting for each other in a circular dependency. Go\u0026rsquo;s runtime will detect some deadlocks:\nfunc main() { ch := make(chan int) ch \u0026lt;- 1 // Will deadlock immediately - nobody is receiving fmt.Println(\u0026lt;-ch) } Output:\nfatal error: all goroutines are asleep - deadlock! Another sneaky source of deadlocks is nil channels. A nil channel blocks forever and can cause your program to hang silently:\nfunc main() { var ch chan string // Declared but not initialized - nil channel go func() { // This will block forever because sending on a nil channel blocks forever ch \u0026lt;- \u0026#34;This message will never be sent\u0026#34; fmt.Println(\u0026#34;This will never print\u0026#34;) }() time.Sleep(1 * time.Second) fmt.Println(\u0026#34;Program continues while goroutine is blocked\u0026#34;) // This will also block forever - receiving from a nil channel msg := \u0026lt;-ch fmt.Println(\u0026#34;This will never be reached:\u0026#34;, msg) } Notice the declaration of the channel. I read somewhere online that make is your friend and you should always use it when using either a chan or map. Let\u0026rsquo;s take a look at the wrong vs right way to implement this:\n// WRONG - might leave channel as nil var ch chan string if someCondition { ch = make(chan string) } // RIGHT - always initialize, control behavior differently ch := make(chan string) if !someCondition { // Maybe close it immediately or use a separate flag close(ch) } To avoid deadlocks:\nEnsure proper channel initialization and closure Use timeouts and contexts for bounded waiting Be cautious with nested channel operations Consider buffered channels when appropriate Make sure receives have matching sends (and vice versa) Use the race detector and thorough testing to identify potential deadlocks Race Conditions: Timing Is Everything # Race conditions occur when multiple goroutines access shared data without proper synchronization:\nfunc main() { counter := 0 var wg sync.WaitGroup for i := 0; i \u0026lt; 1000; i++ { wg.Add(1) go func() { defer wg.Done() counter++ // RACE CONDITION: unsynchronized access }() } wg.Wait() fmt.Println(\u0026#34;Counter:\u0026#34;, counter) // Will likely be less than 1000 } Channels provide a safer approach to shared state:\nfunc main() { counter := 0 var wg sync.WaitGroup ch := make(chan int, 100) // Buffered channel for performance // Counter manager goroutine go func() { for _ = range ch { counter++ } }() // Worker goroutines for i := 0; i \u0026lt; 1000; i++ { wg.Add(1) go func() { defer wg.Done() ch \u0026lt;- 1 // Send increment signal }() } wg.Wait() close(ch) // Signal that no more increments are coming // Allow time for processing remaining channel items time.Sleep(time.Millisecond * 10) fmt.Println(\u0026#34;Final counter:\u0026#34;, counter) // Will be exactly 1000 } Using a dedicated goroutine to manage state and communicating with it via channels eliminates race conditions by ensuring only one goroutine modifies the shared state.\nWrapping Up # Go channels transform concurrent programming from a complex, error-prone endeavor into an elegant, manageable process. By enforcing the philosophy of \u0026ldquo;communicating by sharing memory\u0026rdquo; rather than \u0026ldquo;sharing memory to communicate,\u0026rdquo; Go helps developers build robust concurrent systems with fewer bugs.\nKey takeaways:\nUnbuffered channels provide synchronization when both sender and receiver need to coordinate Buffered channels allow for asynchronous operations with controlled capacity The select statement enables managing multiple channels simultaneously Directional channels provide compile-time guarantees about channel usage Patterns like worker pools and pipelines provide reusable solutions to common concurrency challenges While channels aren\u0026rsquo;t the only concurrency primitive in Go (there\u0026rsquo;s also sync.Mutex, sync.WaitGroup, and more), they\u0026rsquo;re often the most idiomatic and lead to code that\u0026rsquo;s easier to reason about.\nI encourage you to experiment with these patterns in your own code, starting with simple examples and gradually building up to more complex use cases.\nHappy concurrent programming, fellow Gophers!\n","date":"Feb 21, 2025","permalink":"https://blog.mikesahari.com/posts/go-channels/","tags":["go","channels","concurrency","parallelism","fundamentals"],"title":"Go Channels: A Concurrency Guide"},{"content":"After spending years writing Go, the introduction of generic type aliases in Go 1.24 is something that I have to say is exciting! Let\u0026rsquo;s break down exactly what this means, how it works, and how it compares to other languages.\nUnderstanding Go\u0026rsquo;s Type System Evolution # Type Aliases vs Type Definitions # First, let\u0026rsquo;s clear up a fundamental concept in Go:\n// Type Definition - Creates a NEW type type MyInt int // MyInt is a different type than int // Type Alias - Creates a SYNONYM for existing type type AliasInt = int // AliasInt is exactly the same as int Here\u0026rsquo;s a practical example showing the difference:\nfunc main() { // Type Definition behavior type UserID int var id UserID = 1 var number int = 2 // id = number // This fails! Different types id = UserID(number) // This works with explicit conversion // Type Alias behavior type RequestID = int var reqID RequestID = 1 var otherNumber int = 2 reqID = otherNumber // This works! Same type } Understanding Generic Type Aliases # graph TD A[Define Generic Type Alias] --\u0026gt; B{Choose Constraint} B --\u0026gt;|any| C[No Constraints] B --\u0026gt;|comparable| D[Must Support ==] B --\u0026gt;|Custom| E[User Defined] C --\u0026gt; F[Implementation] D --\u0026gt; F E --\u0026gt; F F --\u0026gt; G[Usage] G --\u0026gt; H[With Strings] G --\u0026gt; I[With Numbers] G --\u0026gt; J[With Custom Types] style A fill:#1B5E20,stroke:#90EE90,stroke-width:2px,color:#fff style C fill:#388E3C,stroke:#A5D6A7,stroke-width:2px,color:#fff style D fill:#388E3C,stroke:#A5D6A7,stroke-width:2px,color:#fff style E fill:#388E3C,stroke:#A5D6A7,stroke-width:2px,color:#fff style F fill:#1B5E20,stroke:#90EE90,stroke-width:2px,color:#fff style H fill:#388E3C,stroke:#A5D6A7,stroke-width:2px,color:#fff style I fill:#388E3C,stroke:#A5D6A7,stroke-width:2px,color:#fff style J fill:#388E3C,stroke:#A5D6A7,stroke-width:2px,color:#fff Generic type aliases allow us to create type synonyms that can work with different data types while maintaining Go\u0026rsquo;s strong type safety. Think of it as creating flexible building blocks that can adapt to different data types without sacrificing compile-time safety.\nBasic Examples: Result and Set Types # Let\u0026rsquo;s break down some fundamental patterns that you\u0026rsquo;ll use constantly:\n// Result represents a common pattern in Go: // handling both successful operations and errors type Result[T any] = struct { Data T // The actual data of any type Success bool // Operation status Error error // Error if any } // Set represents a collection of unique items // using Go\u0026#39;s efficient map implementation type Set[T comparable] = map[T]bool func main() { // Let\u0026#39;s see how Result works with strings userData := Result[string]{ Data: \u0026#34;John Doe\u0026#34;, Success: true, Error: nil, } fmt.Printf(\u0026#34;User data: %v\\n\u0026#34;, userData.Data) // Output: User data: John Doe // Now with numbers - same type, different data calculationResult := Result[int]{ Data: 42, Success: true, Error: nil, } fmt.Printf(\u0026#34;Calculation result: %d\\n\u0026#34;, calculationResult.Data) // Output: Calculation result: 42 // Sets are perfect for managing unique collections fruitSet := Set[string]{ \u0026#34;apple\u0026#34;: true, // Present in set \u0026#34;banana\u0026#34;: true, // Present in set } // Checking membership is lightning fast fmt.Println(\u0026#34;Is apple in set?\u0026#34;, fruitSet[\u0026#34;apple\u0026#34;]) // Output: true fmt.Println(\u0026#34;Is orange in set?\u0026#34;, fruitSet[\u0026#34;orange\u0026#34;]) // Output: false // Sets work just as well with numbers primeSet := Set[int]{ 2: true, 3: true, 5: true, } fmt.Println(\u0026#34;Is 2 prime?\u0026#34;, primeSet[2]) // Output: true } Advanced Use Cases: Building Robust Data Structures # Now let\u0026rsquo;s look at some more sophisticated patterns that showcase the full power of generic type aliases:\nimport \u0026#34;sync\u0026#34; // Optional represents a value that might or might not be present // Perfect for handling nullable values without using pointers type Optional[T any] = struct { Value T HasValue bool } // SafeMap provides a thread-safe map implementation // using Go\u0026#39;s sync.RWMutex for concurrent access type SafeMap[K comparable, V any] = struct { Data map[K]V mu sync.RWMutex } // Queue implements a simple FIFO data structure type Queue[T any] = struct { items []T } func main() { // Optional is perfect for handling potentially missing values userEmail := Optional[string]{ Value: \u0026#34;user@example.com\u0026#34;, HasValue: true, } if userEmail.HasValue { fmt.Printf(\u0026#34;Email: %s\\n\u0026#34;, userEmail.Value) } // SafeMap provides thread-safe operations userScores := SafeMap[string, int]{ Data: make(map[string]int), } // Thread-safe operations userScores.mu.Lock() userScores.Data[\u0026#34;Alice\u0026#34;] = 100 userScores.mu.Unlock() // Reading data safely userScores.mu.RLock() score := userScores.Data[\u0026#34;Alice\u0026#34;] userScores.mu.RUnlock() fmt.Printf(\u0026#34;Alice\u0026#39;s score: %d\\n\u0026#34;, score) } The real power of these generic type aliases becomes apparent when you need to:\nHandle different data types with the same logic Provide type safety without code duplication Build reusable components that work across your codebase Here\u0026rsquo;s a practical example combining these concepts:\n// ResultSet combines our Result and Set types type ResultSet[T comparable] = struct { Results []Result[T] UniqueValues Set[T] } func main() { // Using ResultSet with strings userNames := ResultSet[string]{ Results: []Result[string]{ {Data: \u0026#34;Alice\u0026#34;, Success: true}, {Data: \u0026#34;Bob\u0026#34;, Success: true}, {Data: \u0026#34;Alice\u0026#34;, Success: true}, // Duplicate }, UniqueValues: Set[string]{ \u0026#34;Alice\u0026#34;: true, \u0026#34;Bob\u0026#34;: true, }, } // Check unique values fmt.Println(\u0026#34;Is Alice in set?\u0026#34;, userNames.UniqueValues[\u0026#34;Alice\u0026#34;]) // Count successful results successCount := 0 for _, result := range userNames.Results { if result.Success { successCount++ } } fmt.Printf(\u0026#34;Successful results: %d\\n\u0026#34;, successCount) } Language Comparison: Generic Type Aliases Across Other Languages # Let\u0026rsquo;s explore how TypeScript and Python handle generic type aliases compared to Go 1.24. This should help those of you reading who are familiar with other languages, but have never touched type aliases (let alone generics!).\nTypeScript: Type Aliases # TypeScript\u0026rsquo;s type system is like that overachieving friend who always does extra credit - it comes with a rich set of features for type manipulation. Here\u0026rsquo;s how TypeScript approaches generic type aliases:\n// The classic Result type - TypeScript style type Result\u0026lt;T\u0026gt; = { data: T; // Generic data of any type success: boolean; // Operation status error: Error | null; // Notice the union type - very TypeScript! }; // Sets with TypeScript\u0026#39;s powerful type constraints type Set\u0026lt;T extends string | number | symbol\u0026gt; = { [key in T]: boolean; // Using mapped types - a TypeScript specialty }; // Optional values using union types type Optional\u0026lt;T\u0026gt; = { value: T; hasValue: boolean; } | null; // Union with null - TypeScript\u0026#39;s way of handling optional values // Let\u0026#39;s put these to work const userResult: Result\u0026lt;string\u0026gt; = { data: \u0026#39;John Doe\u0026#39;, success: true, error: null }; // TypeScript\u0026#39;s type inference is pretty smart const numberSet: Set\u0026lt;number\u0026gt; = { 1: true, 2: true // Try adding a string here - TypeScript will yell at you! }; // The compiler catches type mismatches const invalidSet: Set\u0026lt;number\u0026gt; = { one: true // Error: string key in number set }; What makes TypeScript special:\nUnion types (Error | null) Mapped types ([key in T]) Type constraints (extends string | number | symbol) Excellent type inference Python: Type Hints with a Twist # Type aliases are interesting in Python. While there is no way to enforce typing, with the exception of some strong mypy type checking (or some custom decorators), generics and type aliases are done through typing hinting. Here\u0026rsquo;s how Python 3.13 handles generic type aliases:\nfrom typing import TypeVar, Generic, TypeAlias from dataclasses import dataclass # TypeVar is Python\u0026#39;s way of saying \u0026#34;this could be anything\u0026#34; T = TypeVar(\u0026#39;T\u0026#39;) K = TypeVar(\u0026#39;K\u0026#39;) V = TypeVar(\u0026#39;V\u0026#39;) # Using dataclass to reduce boilerplate @dataclass class Result(Generic[T]): data: T # Generic data field success: bool # Status flag error: Exception | None # Python 3.10+ union type syntax # Type aliases in Python - simpler but powerful Set: TypeAlias = dict[T, bool] @dataclass class Optional(Generic[T]): value: T | None # Modern Python union type syntax has_value: bool # Using our generic types def process_data() -\u0026gt; Result[str]: return Result( data=\u0026#34;Processing complete\u0026#34;, success=True, error=None ) # Type checkers will validate this string_result = Result[str]( data=\u0026#34;Hello Python!\u0026#34;, success=True, error=None ) # But Python won\u0026#39;t stop you at runtime number_set: Set[int] = { 1: True, \u0026#34;oops\u0026#34;: True # This will work (but your type checker will complain) } Python\u0026rsquo;s approach is unique because:\nType hints are optional Runtime behavior isn\u0026rsquo;t affected by types External type checkers (like mypy) do the heavy lifting Generics are implemented through the typing module The Key Differences # While all three languages support generic type aliases, they each have their own philosophy:\nGo:\nCompile-time enforcement Simple, straightforward syntax No runtime overhead Explicit type conversions required TypeScript:\nRich type system features Extensive type inference Compile-time checking (but compiles to JavaScript) Powerful type manipulation capabilities Python:\nOptional type hints Runtime type checking tools Gradual typing approach Type hints as documentation Here\u0026rsquo;s a quick side-by-side comparison using our Result type:\n// Go type Result[T any] = struct { Data T Success bool Error error } // TypeScript type Result\u0026lt;T\u0026gt; = { data: T; success: boolean; error: Error | null; }; # Python @dataclass class Result(Generic[T]): data: T success: bool error: Exception | None The syntax might be different, but the goal is the same: creating reusable, type-safe code. Each language just takes its own path to get there!\nBest Practices for Go Generic Type Aliases # 1. Keep It Simple # Don\u0026rsquo;t make them over complex, but also don\u0026rsquo;t be vague with your parameters.\n// Good - Clear purpose type JsonResponse[T any] = struct { Data T Status int Message string } // Bad - Vague and difficult to understand type JsonResponse[T any, E comparable, M ~string] = struct { Data T Status int Error E Message M } 2. Use Meaningful Constraints # It is too easy to just say \u0026ldquo;any\u0026rdquo;. Unless you really don\u0026rsquo;t plan on refactoring your code, try to constrain the generics to expected types.\n// Good - Clear constraint usage type NumericResult[T ~int | ~float64] = struct { Value T Valid bool } // Not ideal - Overly permissive type Result[T any] = struct { Value T Valid bool } 3. Document Your Types # Documentation makes it easier for the poor souls who inherit your tech debt, including you!\n// UserResult represents an API response containing user data. // T can be any user-related struct. type UserResult[T any] = struct { Data T Status int Message string } Closing # Remember: Generic type aliases in Go provide a powerful way to create reusable, type-safe code while maintaining Go\u0026rsquo;s simplicity and explicitness. Choose them when they make your code clearer and more maintainable.\n","date":"Feb 15, 2025","permalink":"https://blog.mikesahari.com/posts/type-aliases/","tags":["go","python","typescript","generics"],"title":"Understanding Generic Type Aliases in Go 1.24"},{"content":"Hey there, fellow Go enthusiasts! Today, I\u0026rsquo;m going to share something that completely changed my CLI development game. Buckle up ‚Äì we\u0026rsquo;re diving deep into making CLIs that users will actually enjoy using!\nThe CLI Development Evolution # You know how we all instinctively reach for cobra when building command-line tools in Go? Well, here is the perfect companion that\u0026rsquo;s transformed how I think about CLI interactions: huh by Charmbracelet.\nHere\u0026rsquo;s the thing that got me excited: While cobra handles all the heavy lifting of command structure and flags (and does it beautifully, I might add), huh brings something entirely different to the table. It\u0026rsquo;s all about creating those smooth, interactive forms and prompts that make your CLIs feel professional and polished. Think of it as the difference between a bare-bones terminal app and something that feels like it belongs in 2025.\nGetting Started with huh # First things first, let\u0026rsquo;s get the package:\ngo get github.com/charmbracelet/huh This is where the magic starts. Here\u0026rsquo;s the simplest way to get going with a basic input prompt:\nvar name string huh.NewInput(). Title(\u0026#34;What\u0026#39;s your name?\u0026#34;). Value(\u0026amp;name). Run() // Watch out - this is blocking! fmt.Printf(\u0026#34;Hey, %s!\\n\u0026#34;, name) If you\u0026rsquo;re already using cobra\u0026rsquo;s StringVarP for flags, you can create this sweet fallback system. When a flag isn\u0026rsquo;t provided, your CLI smoothly transitions to an interactive prompt. It\u0026rsquo;s like having the best of both worlds!\nThe Real MVP: Select Prompts # Okay, this is where things get really interesting. Remember struggling with promptui for selection menus? (I sure do, and let me tell you, it wasn\u0026rsquo;t pretty.) Check this out:\nhuh.NewSelect[string](). Title(\u0026#34;Pick a country.\u0026#34;). Options( huh.NewOption(\u0026#34;United States\u0026#34;, \u0026#34;US\u0026#34;), huh.NewOption(\u0026#34;Germany\u0026#34;, \u0026#34;DE\u0026#34;), huh.NewOption(\u0026#34;Brazil\u0026#34;, \u0026#34;BR\u0026#34;), huh.NewOption(\u0026#34;Canada\u0026#34;, \u0026#34;CA\u0026#34;), ). Value(\u0026amp;country) Not only is it clean and intuitive, but it comes with built-in navigation, filtering, and selection handling. No more wrestling with keyboard events and terminal codes!\nReal-World Implementation: net-tools Deep Dive # Let me walk you through a real-world project where I put all this into practice. I built this network troubleshooting toolkit called net-tools that combines everything we\u0026rsquo;ve talked about. It\u0026rsquo;s my Swiss Army knife for network diagnostics, built with Go.\nThe Dig Command: Simple but Powerful # Here\u0026rsquo;s where validation really shines:\nfunc interactiveDig() { form := huh.NewForm( huh.NewGroup( huh.NewInput(). Title(\u0026#34;Domain/Subdomain:\u0026#34;). Prompt(\u0026#34;? \u0026#34;). Validate(func(str string) error { if !strings.Contains(str, \u0026#34;.\u0026#34;) { return errors.New(\u0026#34;domains should have a \u0026#39;.\u0026#39; in them\u0026#34;) } return nil }). Value(\u0026amp;domain), ), ) } üìù NOTE That validation function isn\u0026rsquo;t just error checking - it\u0026rsquo;s about guiding users to success. The IP Command: Elegant Selection # This is where select forms really shine:\nfunc interactiveIP() { form := huh.NewForm( huh.NewGroup( huh.NewSelect[string](). Title(\u0026#34;IP Type:\u0026#34;). Options( huh.NewOption(\u0026#34;Both\u0026#34;, \u0026#34;both\u0026#34;), huh.NewOption(\u0026#34;Private\u0026#34;, \u0026#34;private\u0026#34;), huh.NewOption(\u0026#34;Public\u0026#34;, \u0026#34;public\u0026#34;), ). Value(\u0026amp;ipType), ), ) } Extra: Dynamic Selection Options # üìù NOTE This section is a little advanced and requires some knowledge on generics. I thought I would share because I couldn\u0026rsquo;t find much documentation online about this. My example above is simple and hardcoded. Let\u0026rsquo;s face it; not every situation can handle the options being known and hardcoded. Let\u0026rsquo;s make our forms more dynamic and reusable. I\u0026rsquo;ve developed a couple of utility functions (outside this project) that have saved me countless hours when dealing with dynamic select options.\n// NewSelectForm creates a new select form func NewSelectForm[T comparable](options []huh.Option[T], title string) (T, error) { var output T form := huh.NewForm( huh.NewGroup( huh.NewSelect[T](). Title(title). Options(options...). Value(\u0026amp;output), ), ) err := form.Run() if err != nil { return output, err } return output, nil } // GenerateGenericOptions generates options dynamically func GenerateGenericOptions[T comparable](items []T) []huh.Option[T] { options := make([]huh.Option[T], len(items)) for i, item := range items { options[i] = huh.Option[T]{ Key: fmt.Sprintf(\u0026#34;%v\u0026#34;, item), Value: item, } } return options } Let me break down why these functions are game-changers:\nType-Safe Generics: The [T comparable] constraint ensures our functions work with any comparable type (This means you can use it with strings, ints, or even custom types!) Simplified Form Creation: Using the above, we can do the following: // Example usage with a slice of strings protocols := []string{\u0026#34;HTTP\u0026#34;, \u0026#34;HTTPS\u0026#34;, \u0026#34;FTP\u0026#34;, \u0026#34;SSH\u0026#34;} options := GenerateGenericOptions(protocols) selectedProtocol, err := NewSelectForm(options, \u0026#34;Select Protocol\u0026#34;) Dynamic Option Generation: You can feed it any slice of comparable items. This will automatically generate the display keys and values (Remember, the Key is what users see, Value is what your code gets!). The Netcat Command: Advanced Form Handling # Now this is where we really level up our game with multiple inputs and sophisticated validation:\nfunc interactiveNetcat() { form := huh.NewForm( huh.NewGroup( huh.NewInput(). Title(\u0026#34;IP to check:\u0026#34;). Prompt(\u0026#34;? \u0026#34;). Validate(func(str string) error { // autopass localhost - because hey, we all need a quick local test sometimes! if str == \u0026#34;localhost\u0026#34; { return nil } // Here\u0026#39;s where the magic happens - we test both IPv4 and IPv6 parsedIP := net.ParseIP(str) if parsedIP == nil { // If it\u0026#39;s not an IP, maybe it\u0026#39;s a hostname? _, err := net.LookupHost(str) if err != nil { return errors.New(\u0026#34;not a valid IP address\u0026#34;) } } return nil }). Value(\u0026amp;host), // Now for the port validation - this is crucial! huh.NewInput(). Title(\u0026#34;Port to check:\u0026#34;). Prompt(\u0026#34;? \u0026#34;). Validate(func(str string) error { portNum, err := strconv.Atoi(str) if err != nil { return errors.New(\u0026#34;not a valid port\u0026#34;) } // Always validate port ranges! isValidPort := portNum \u0026gt; 0 \u0026amp;\u0026amp; portNum \u0026lt;= 65535 if !isValidPort { return errors.New(\u0026#34;port provided is outside of valid port range\u0026#34;) } return nil }). Value(\u0026amp;port), ), ) err := form.Run() if err != nil { log.Fatal(err) } } Let\u0026rsquo;s break down what makes this netcat implementation special:\nForm Structure:\nA single NewGroup contains two inputs - IP/hostname and port Grouping related inputs makes the UX more intuitive! IP/Hostname Validation:\nFast-tracks \u0026ldquo;localhost\u0026rdquo; for quick local testing Handles both direct IP addresses and domain names Gotcha alert: Don\u0026rsquo;t forget the DNS lookup for hostnames! Port Validation:\nConverts string input to numeric port Validates against the full port range (1-65535) Fun fact: This prevents those \u0026ldquo;why isn\u0026rsquo;t it working?\u0026rdquo; moments when someone tries port 0! Error Handling:\nBlocking form.Run() ensures valid input Comprehensive error catching at the form level The blocking nature means your subsequent code can trust the input! Taking It to the Next Level: Visual Polish ‚ú® # Want to make your CLI even more professional? Meet lipgloss - think of it as CSS for your terminal apps. It works seamlessly with huh!\nHere\u0026rsquo;s some suggestions on using lipgloss:\nGreen for successful operations Red for errors and warnings Clear visual hierarchy for scan results Why This Matters # Remember: great CLIs aren\u0026rsquo;t just about functionality - they\u0026rsquo;re about creating an experience that makes users actually want to use your tools. With huh, you\u0026rsquo;re:\nReducing user errors through validation Providing intuitive interfaces Making your tools more approachable Building professional-grade experiences Getting Started with Your Own Project # Ready to build something amazing? Here\u0026rsquo;s your quick start guide:\nSet up your project with cobra for command structure Add huh for interactive elements Consider lipgloss for styling Check out net-tools for implementation examples Start simple with basic prompts, then gradually add validation and complexity as you get comfortable with the library.\nWrapping Up # The combination of cobra for structure and huh for interaction is powerful stuff. Whether you\u0026rsquo;re building developer tools, system utilities, or anything in between, these libraries give you the building blocks for creating CLIs that users will love.\nRemember: the best tools aren\u0026rsquo;t just functional - they\u0026rsquo;re a joy to use. Now go forth and build something awesome!\n","date":"Feb 8, 2025","permalink":"https://blog.mikesahari.com/posts/clis-and-huh/","tags":["go","commandline","cli","charmbracelet"],"title":"Building Beautiful CLIs with Huh"},{"content":"Hello readers! Today I bring you a little blog around my development environment, using dotfiles and Neovim configurations.\nLet me walk you through how I\u0026rsquo;ve structured my dotfiles for managing multiple environments while keeping everything clean and maintainable - and most importantly, version controlled.\nThe Core Structure # First, let\u0026rsquo;s look at how everything is organized:\n./ ‚îú‚îÄ‚îÄ alacritty-darwin/ # MacOS terminal config ‚îÇ ‚îî‚îÄ‚îÄ .alacritty.yml ‚îú‚îÄ‚îÄ alacritty-linux/ # Linux terminal config ‚îÇ ‚îî‚îÄ‚îÄ .alacritty.yml ‚îú‚îÄ‚îÄ backgrounds/ # Personal touch with retrowave ‚îÇ ‚îî‚îÄ‚îÄ Pictures/ ‚îÇ ‚îî‚îÄ‚îÄ retrowave.jpg ‚îú‚îÄ‚îÄ nvim/ # Neovim as a submodule ‚îÇ ‚îî‚îÄ‚îÄ .config/ ‚îÇ ‚îî‚îÄ‚îÄ nvim/ ‚îú‚îÄ‚îÄ tmux/ # Terminal multiplexing ‚îÇ ‚îî‚îÄ‚îÄ .tmux.conf ‚îî‚îÄ‚îÄ zsh/ # Shell configuration ‚îú‚îÄ‚îÄ .zsh.d/ ‚îÇ ‚îú‚îÄ‚îÄ common_aliases.zsh ‚îÇ ‚îú‚îÄ‚îÄ functions.zsh ‚îÇ ‚îú‚îÄ‚îÄ paths.zsh ‚îÇ ‚îî‚îÄ‚îÄ prompt.zsh ‚îî‚îÄ‚îÄ .zshrc üìù NOTE This directory structure is setup for stow (mentioned further below) to symlink configs. Neovim: The Development Environment # The Neovim configuration is simple - it\u0026rsquo;s structured as a clean, modular setup:\n./ ‚îú‚îÄ‚îÄ init.lua # Entry point ‚îú‚îÄ‚îÄ lazy-lock.json # Plugin version locking ‚îú‚îÄ‚îÄ lua/ ‚îÇ ‚îú‚îÄ‚îÄ config/ # Core configuration ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ keymaps.lua # Key bindings ‚îÇ ‚îî‚îÄ‚îÄ plugins/ # Plugin configurations ‚îú‚îÄ‚îÄ codeium.lua # AI completion ‚îú‚îÄ‚îÄ core.lua # Essential plugins ‚îú‚îÄ‚îÄ lsp.lua # Language server config ‚îî‚îÄ‚îÄ telescope.lua # Fuzzy finder setup üìù NOTE My actual config has more plugins. This tree is an example to show how I structure my Neovim config repo. Managing Multiple Environments with Submodules # Git submodules are one of those powerful features that, once mastered, completely change how you manage complex projects. Much like the satisfaction of mastering git stash (remember the first time you saved yourself from a messy branch switch?), understanding submodules opens up entirely new ways of structuring your repositories.\nYou can maintain separate Neovim configurations using submodules for work and personal use, even with private repositories. Here\u0026rsquo;s how:\nCreate separate repositories for your configurations Add them as submodules: # Personal config (public) git submodule add git@github.com:personal/nvim-config.git nvim-personal # Work config (private) git submodule add git@github.com:your-org/private-nvim-config.git nvim-work You can maintain separate Neovim configurations by using Git submodules - your public dotfiles repo can reference a private Neovim config repository using SSH URLs (like git@github.com:your-org/private-nvim-config.git), and when users clone your dotfiles, only those with proper SSH authentication to the private repo (your-org) will be able to pull down that configuration.\nThis setup is perfect for keeping your work-specific Neovim configuration private while still maintaining a public dotfiles repository that others can learn from and use.\nüìå IMPORTANT Do not version control your secrets or private keys in plaintext! (Even to a private repository!) The beauty of this approach is that it lets you share your dotfiles publicly while keeping sensitive configs completely separate.\nThe Smart Setup Script # The setup.sh script in the dotfiles is the orchestrator of this whole system. Here is an example of mine:\n#!/usr/bin/env bash # This script requires you have stow installed # make sure we have pulled in and updated any submodules git submodule init git submodule update # OS-specific configuration if [ $(uname) = \u0026#39;Darwin\u0026#39; ]; then ALACRITTY=alacritty-darwin else ALACRITTY=alacritty-linux fi # Base packages for all environments base=( nvim tmux bash zsh $ALACRITTY backgrounds wezterm ) # Our stow function stowit() { usr=$1 app=$2 stow -v -R -t ${usr} ${app} } echo \u0026#34;\u0026#34; echo \u0026#34;Stowing apps for user: ${whoami}\u0026#34; # install apps available to local users and root for app in ${base[@]}; do stowit \u0026#34;${HOME}\u0026#34; $app done Here\u0026rsquo;s the deal with stow and how it fits into our dotfiles management\u0026hellip;\nStow is the secret sauce in my setup script that handles all the symlinking of configuration files to their correct locations. Instead of manually creating symlinks or copying files around, my setup.sh script uses Stow to automatically create the necessary symlinks based on the directory structure.\nWhen you look at my setup script, you\u0026rsquo;ll see it\u0026rsquo;s using the stowit() function that takes a target directory (like $HOME) and a package name (like nvim or tmux), then uses stow -v -R -t to recursively create all the required symlinks - this is what makes it so easy to handle OS-specific configurations like having separate Alacritty configs for Linux and MacOS while maintaining the same seamless installation process.\nSetting Up Multiple Environment Configurations # Seeing as I made a conditional to handle Alacritty, the same can be done with Neovim configs.\nTo maintain separate configurations:\nFirst, adjust your setup script to detect the environment: if [ -f ~/.work_machine ]; then NVIM_CONFIG=\u0026#34;nvim-work\u0026#34; else NVIM_CONFIG=\u0026#34;nvim-personal\u0026#34; fi Modify the base array to use the correct config: base=( $NVIM_CONFIG # This will be either nvim-work or nvim-personal tmux bash zsh $ALACRITTY backgrounds wezterm ) When working with private repositories, always use SSH URLs in your .gitmodules file - it makes authentication much smoother.\nGetting Started # To set up this environment on a new machine:\n# Clone with all submodules git clone --recurse-submodules YOUR_REPO_URL cd dotfiles # Mark as work machine if needed touch ~/.work_machine # Only on work machines! # Run the setup ./setup.sh This approach gives you a clean separation between work and personal configurations while maintaining the flexibility to share common elements. The power of Git submodules combined with stow makes it seamless to manage multiple environments without sacrificing maintainability.\nWrapping Up # Your dotfiles are more than just configurations - they\u0026rsquo;re a reflection of how you work. By leveraging Git submodules for flexibility and stow for elegant symlink management, you create a development environment that feels like home on any machine. Whether you\u0026rsquo;re keeping work configs private or sharing with the community, this setup grows with you while maintaining that consistent feel that makes terminal-based development such a joy.\n","date":"Feb 7, 2025","permalink":"https://blog.mikesahari.com/posts/dev-with-dotfiles/","tags":["dev","dotfiles","neovim"],"title":"Managing Development Environments with Dotfiles"},{"content":"I was inspired to write this article after a recent discussion about programming language preferences, specifically questioning my stance on Python. Let me start by acknowledging Python\u0026rsquo;s strengths - it excels in machine learning and generative AI applications. However, I prefer Go for several compelling reasons:\nMemory management with pointers Elegant concurrency using channels and goroutines Straightforward cross-compilation of binaries Clean implementation of interfaces and structs But preferences often face challenges. Some argue, \u0026ldquo;Python now has concurrency, so you should switch to Python.\u0026rdquo; I fundamentally disagree with this reasoning. Developers should write code in languages they enjoy and find productive. In professional settings, use your preferred language until organizational standards dictate otherwise (i.e. Thou shalt use only thy golden hammer language of the team).\nThis debate sparked my curiosity: how does Python 3.13\u0026rsquo;s new GIL-disabled feature actually perform compared to Go\u0026rsquo;s native concurrency? Let\u0026rsquo;s run through an experiment and find out.\nUnderstanding the Basics: Concurrency vs. Parallelism # Before we compare Go and Python, let\u0026rsquo;s clarify two important terms:\nConcurrency ‚Äì The ability to execute multiple tasks at the same time, but not necessarily in parallel. Tasks may start, run, and complete independently but share CPU resources. Parallelism ‚Äì The ability to execute multiple tasks simultaneously using multiple CPU cores. Think of concurrency as multitasking (switching between tasks quickly) and parallelism as multiple workers doing different tasks at the same time. I find this important to talk about since I find engineers (or people who like to talk technical) using these interchangeably.\nConcurrency Example (Go) # Go allows multiple tasks (goroutines) to be scheduled efficiently, even if they\u0026rsquo;re not running in parallel.\ngo doTaskA() // Runs independently go doTaskB() // Runs independently Parallelism Example (Python) # Python uses multiple processes to achieve parallelism, where each process runs on a different CPU core.\nüìù NOTE This is true of traditional Python. 3.13 lets you disable the setting that produces this behavior. I will explain that in the next section below. from multiprocessing import Pool def task(x): return x * 2 with Pool(4) as p: # 4 parallel workers results = p.map(task, range(10)) The Fundamental Difference: GIL/Gill-Free vs Native Concurrency # Before I get into the Python analysis, I want to talk about the GIL. For those of you unfamiliar with Python, or those of you that only know enough of it to be dangerous, the GIL is the Global Interpreter Lock. You can read up more on it online, but two key features of it are:\nincreased speed of single threaded programs easy integration with C libraries Python: Evolution Beyond the GIL # Starting with Python 3.13, there are two significant approaches to parallel execution:\nTraditional GIL-Based Threading:\nHistorical limitation where only one thread can execute Python code at a time Still the default behavior for backward compatibility Suitable for I/O-bound tasks GIL-Free Execution (Python 3.13+):\nAbility to disable GIL for true parallel execution Requires explicit opt-in Enables CPU-bound tasks to run in parallel Let\u0026rsquo;s perform a benchmark to show average time with GIL-Based Threading vs GIL-Free Execution. And then after that, I\u0026rsquo;ll show you that Go still beats it.\nüìù NOTE Turning off the GIL requires that you either compile it with flags or download it. I just installed it using pyenv and appending t to the version. # install 1.13.1 (GIL enabled by default) pyenv install 1.13.1 # install 1.13.1 with GIL disabled pyenv install 1.13.1t Then you can verify in python with\nimport sys print(sys._is_gil_enabled()) # should return False Anyways, here\u0026rsquo;s how to leverage both approaches. First we need a script to test multiprocessing. We\u0026rsquo;ll run it with the GIL enabled first. Then disabled second.\ncpu_test.py # import sys import time import multiprocessing from typing import List from threading import Thread, Event, Lock class CPUBenchmark: \u0026#34;\u0026#34;\u0026#34; Benchmark class for measuring CPU-bound task performance. \u0026#34;\u0026#34;\u0026#34; def __init__(self, num_threads: int): self.num_threads = num_threads self.completed = Event() self.lock = Lock() self.count = 0 def cpu_task(self) -\u0026gt; None: \u0026#34;\u0026#34;\u0026#34;CPU-intensive calculation.\u0026#34;\u0026#34;\u0026#34; result = 0.0 for i in range(50_000_000): result += (i * i) / (i + 1) with self.lock: self.count += 1 if self.count == self.num_threads: self.completed.set() def run_threads(self) -\u0026gt; float: \u0026#34;\u0026#34;\u0026#34; Execute CPU task across multiple threads. Returns execution time in seconds. \u0026#34;\u0026#34;\u0026#34; start_time = time.perf_counter() threads: List[Thread] = [] # Create and start threads for _ in range(self.num_threads): thread = Thread(target=self.cpu_task) thread.start() threads.append(thread) # Wait for completion for thread in threads: thread.join() return time.perf_counter() - start_time def main() -\u0026gt; None: # Get system information cpu_count = multiprocessing.cpu_count() print(f\u0026#34;Python Version: {sys.version}\u0026#34;) print(f\u0026#34;CPU Cores: {cpu_count}\\n\u0026#34;) # Run benchmark benchmark = CPUBenchmark(cpu_count) duration = benchmark.run_threads() # Report results print(f\u0026#34;Threads: {cpu_count}\u0026#34;) print(f\u0026#34;Execution Time: {duration:.2f} seconds\u0026#34;) print(f\u0026#34;Average Time per Thread: {duration/cpu_count:.2f} seconds\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() Again, I use pyenv to switch between my python versions, but choose whatever method works best.\nGIL Enabled Example\n# set my local terminal to use 3.13.1 GIL enabled pyenv local 3.13.1 python cpu_test.py For me, this had an output of:\nPython Version: 3.13.1 CPU Cores: 16 Threads: 16 Execution Time: 79.27 seconds Average Time per Thread: 4.95 seconds Next I tested with GIL disabled. This was pretty interesting since I never experimented with it when this first became available.\nGIL Disabled Example\n# set my local terminal to use 3.13.1 GIL disabled pyenv local 3.13.1t python cpu_test.py The GIL-free had the output,\nPython Version: 3.13.1 experimental free-threading build CPU Cores: 16 Threads: 16 Execution Time: 16.19 seconds Average Time per Thread: 1.01 seconds That was cool and pretty fast. But realistically, when are you going to get a team at work to embrace something experimental because it\u0026rsquo;s faster?\nGo: Goroutines and Channels # Here are some basics on Go\u0026rsquo;s native concurrency:\nGo uses goroutines, which are lightweight threads managed by the Go runtime. Goroutines do not require OS threads and have very low memory overhead (~2KB per goroutine). Channels are used to safely share data between goroutines (though I don\u0026rsquo;t think I\u0026rsquo;ll go into them in this blog). Let\u0026rsquo;s create a simple Go script. Setup the project and create a Go file.\ngo mod init cputest main.go # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func cpuTask(wg *sync.WaitGroup, results chan\u0026lt;- float64) { defer wg.Done() var result float64 // CPU-intensive calculation matching Python example for i := 0; i \u0026lt; 50_000_000; i++ { result += float64(i*i) / float64(i+1) } results \u0026lt;- result } func runBenchmark() time.Duration { // Get number of CPU cores numCPU := runtime.NumCPU() // Initialize sync primitives var wg sync.WaitGroup results := make(chan float64, numCPU) // Record start time start := time.Now() // Launch goroutines for i := 0; i \u0026lt; numCPU; i++ { wg.Add(1) go cpuTask(\u0026amp;wg, results) } // Wait for completion in separate goroutine go func() { wg.Wait() close(results) }() // Collect results for range results { // Process results if needed } return time.Since(start) } func main() { // Configure CPU usage numCPU := runtime.NumCPU() runtime.GOMAXPROCS(numCPU) // Print system info fmt.Printf(\u0026#34;Go Version: %s\\n\u0026#34;, runtime.Version()) fmt.Printf(\u0026#34;CPU Cores: %d\\n\\n\u0026#34;, numCPU) // Run benchmark duration := runBenchmark() // Report results fmt.Printf(\u0026#34;Execution Time: %.2f seconds\\n\u0026#34;, duration.Seconds()) fmt.Printf(\u0026#34;Average Time per Goroutine: %.2f seconds\\n\u0026#34;, duration.Seconds()/float64(numCPU)) } Next run go run main.go and you should see the output. My example:\nGo Version: go1.23.4 CPU Cores: 16 Execution Time: 0.11 seconds Average Time per Goroutine: 0.01 seconds Comparisons # After diving deep into both Go and Python\u0026rsquo;s parallel processing capabilities, I\u0026rsquo;ve got to say - Go\u0026rsquo;s approach to concurrency is just beautiful in its simplicity. The numbers speak for themselves: 0.11 seconds versus Python\u0026rsquo;s best effort of 16.19 seconds (even with the GIL disabled). That\u0026rsquo;s not just a difference; that\u0026rsquo;s a different league entirely.\nWhile Python 3.13\u0026rsquo;s GIL-free execution is impressive and shows the language\u0026rsquo;s evolution, it still feels like retrofitting a solution onto an existing problem. Sure, a 5x performance improvement is nothing to sneeze at, but when Go\u0026rsquo;s giving you nearly 150x better performance with a cleaner syntax and simpler mental model? That\u0026rsquo;s hard to ignore.\nHere\u0026rsquo;s the thing - I appreciate what Python\u0026rsquo;s trying to do here. The ability to disable the GIL is a significant step forward, and for existing Python codebases, it\u0026rsquo;s a game-changer. But if I\u0026rsquo;m starting a new project that needs serious concurrent processing? Go\u0026rsquo;s my first choice, no question. The combination of:\nLightning-fast execution Dead-simple goroutine syntax Built-in concurrent design patterns Production-ready stability Just makes it the obvious choice for building modern, concurrent systems. Python might be catching up, but Go was born ready for this stuff.\nüìù NOTE Go has brought interesting changes to Python before. Python\u0026rsquo;s Protocol system was inspired by Go\u0026rsquo;s interfaces.\nI\u0026rsquo;ve implemented Protocols across several projects. Despite their theoretical benefits, team members often bypass the defined Protocol interfaces, favoring direct code duplication instead.\nThe Verdict on Concurrency: Go vs Python üéØ # When it comes to concurrent programming, Go isn\u0026rsquo;t just a good choice - it\u0026rsquo;s demonstrably superior. While Python 3.13\u0026rsquo;s GIL-free implementation shows promise, its use cases should be carefully considered.\nAppropriate Use Cases # The GIL-free Python implementation could benefit specific domains:\nMachine Learning workflows requiring parallel processing Data science pipelines with CPU-intensive operations Scientific computing applications A new and simple FastAPI that a Python dev team can maintain Misaligned Applications # However, using GIL-free Python for certain tasks, particularly those already optimized in Go, seems counter-intuitive. For example:\nWriting CLIs that wrap Go-based tools (Terraform, Helm, etc) Implementing network services requiring high concurrency Building system-level utilities Why not just import the packages in Go, and just extend the usage to your use case?\nFuture Potential # The most intriguing potential lies in Python\u0026rsquo;s machine learning ecosystem. Given Python\u0026rsquo;s dominance in ML, the performance improvements from GIL-free execution could significantly impact:\nTraining optimization Model inference Parallel data processing pipelines Thanks for diving into this performance comparison with me - now go experiment and build something concurrent, preferably in Go!\n","date":"Feb 1, 2025","permalink":"https://blog.mikesahari.com/posts/parallel-processing/","tags":["go","python","concurrency","parallelism"],"title":"Go vs Python for Parallel Processing"},{"content":"Have you ever wondered how modern web applications handle user authentication and data securely? In this guide, we\u0026rsquo;ll explore building a secure REST API from the ground up using Go. Whether you\u0026rsquo;re new to Go or an experienced developer, you\u0026rsquo;ll learn how to create an API that handles user authentication.\nFor those who need to see the whole code before diving in, you can find all of this on Github\nTechnology Stack Overview # Our API implementation uses three main technologies:\nGo: A programming language designed for building efficient, secure network services with built-in concurrency support (My language of choice). Gin: A high-performance web framework for Go that provides excellent routing capabilities and middleware support. SQLite: A lightweight database that\u0026rsquo;s ideal for development and applications with moderate traffic requirements. Understanding Our Project Structure # The project uses a standard Go application layout that separates concerns for maintainability:\nmyapp/ |-- main.go |-- db/ | |-- connection.go | |-- user.go |-- handlers/ | |-- auth.go | |-- signup.go | |-- login.go | |-- user.go |-- internal/ | |-- jwt/ | | |-- token.go | | |-- middleware.go |-- models/ | |-- user.go | |-- errors.go I like to separate domain specific logic. That way when another engineer starts exploring the repository, they have some general idea where logic exists.\ndb -\u0026gt; database logic\nhandlers -\u0026gt; api handlers\ninternal -\u0026gt; contains repository specific packages (this is idiomatic Go)\nmodels -\u0026gt; contains my data models\nüìù NOTE I have opted to build out my models rather than use something like an ORM because this is a simple example. You can use something like ent for bigger and more complex projects. Setting Up Your Development Environment # First, let\u0026rsquo;s gather our ingredients (dependencies). Open your terminal and run:\n# Create a new Go project go mod init myapp # Install our essential tools go get github.com/gin-gonic/gin # Our web framework go get github.com/mattn/go-sqlite3 # Database driver go get github.com/golang-jwt/jwt/v4 # For secure user tokens Define the Model # Create the models directory.\nmkdir -p models Next we will start creating go files under models. The user model will be defined in the models/user.go.\nmodels/user.go # package models import ( \u0026#34;encoding/json\u0026#34; \u0026#34;time\u0026#34; ) type User struct { ID int64 `json:\u0026#34;id\u0026#34; db:\u0026#34;id\u0026#34;` Username string `json:\u0026#34;username\u0026#34; db:\u0026#34;username\u0026#34;` Password string `json:\u0026#34;-\u0026#34; db:\u0026#34;password\u0026#34;` // The \u0026#34;-\u0026#34; tag prevents password from being included in JSON CreatedAt time.Time `json:\u0026#34;created_at\u0026#34; db:\u0026#34;created_at\u0026#34;` UpdatedAt time.Time `json:\u0026#34;updated_at\u0026#34; db:\u0026#34;updated_at\u0026#34;` } // NewUser creates a new user with the current timestamp func NewUser(username, password string) *User { now := time.Now() return \u0026amp;User{ Username: username, Password: password, CreatedAt: now, UpdatedAt: now, } } // ValidateForCreation performs basic validation for user creation func (u *User) ValidateForCreation() error { if len(u.Username) \u0026lt; 3 { return ErrUsernameTooShort } if len(u.Password) \u0026lt; 8 { return ErrPasswordTooWeak } return nil } // BeforeCreate is called before inserting the user into the database func (u *User) BeforeCreate() { now := time.Now() u.CreatedAt = now u.UpdatedAt = now } // BeforeUpdate is called before updating the user in the database func (u *User) BeforeUpdate() { u.UpdatedAt = time.Now() } // MarshalJSON implements custom JSON marshaling func (u *User) MarshalJSON() ([]byte, error) { type Alias User // Prevents recursive MarshalJSON calls return json.Marshal(\u0026amp;struct { *Alias Password string `json:\u0026#34;-\u0026#34;` // Explicitly exclude password }{ Alias: (*Alias)(u), }) } If you have an IDE or your language server complaining right now, fear not. We will be defining the missing error variables.\nDefine the errors in the models/errors.go\nmodels/errors.go # package models import \u0026#34;errors\u0026#34; var ( ErrUserNotFound = errors.New(\u0026#34;user not found\u0026#34;) ErrUsernameTooShort = errors.New(\u0026#34;username must be at least 3 characters\u0026#34;) ErrPasswordTooWeak = errors.New(\u0026#34;password must be at least 8 characters\u0026#34;) ErrUsernameExists = errors.New(\u0026#34;username already exists\u0026#34;) ErrInvalidCredentials = errors.New(\u0026#34;invalid credentials\u0026#34;) ) // ValidationError represents a domain validation error type ValidationError struct { Field string Message string } func (e *ValidationError) Error() string { return e.Field + \u0026#34;: \u0026#34; + e.Message } // NewValidationError creates a new validation error func NewValidationError(field, message string) *ValidationError { return \u0026amp;ValidationError{ Field: field, Message: message, } } The models package provides several important features:\nStructured Data: The User struct defines the shape of our user data with proper JSON and database tags. Data Validation: The ValidateForCreation method ensures data integrity before database operations. Lifecycle Hooks: BeforeCreate and BeforeUpdate methods handle timestamp management automatically. Security: The Password field is explicitly excluded from JSON serialization using the \u0026ldquo;-\u0026rdquo; tag. Domain Errors: Custom error types help with precise error handling throughout the application. Creating the Database # Next create the db directory. We will put all the database domain logic here.\nmkdir -p db Starting with the db/connection.go, let\u0026rsquo;s create our functions to create the database and table.\ndb/connection.go # package db import ( \u0026#34;database/sql\u0026#34; \u0026#34;fmt\u0026#34; _ \u0026#34;github.com/mattn/go-sqlite3\u0026#34; ) var DB *sql.DB func InitDB() error { var err error DB, err = sql.Open(\u0026#34;sqlite3\u0026#34;, \u0026#34;./myapp.db\u0026#34;) if err != nil { return fmt.Errorf(\u0026#34;database connection failed: %v\u0026#34;, err) } if err := createTables(); err != nil { return fmt.Errorf(\u0026#34;failed to create tables: %v\u0026#34;, err) } return nil } func createTables() error { query := `CREATE TABLE IF NOT EXISTS users ( id INTEGER PRIMARY KEY AUTOINCREMENT, username TEXT NOT NULL UNIQUE, password TEXT NOT NULL, created_at DATETIME NOT NULL, updated_at DATETIME NOT NULL );` _, err := DB.Exec(query) return err } func CloseDB() error { return DB.Close() } üìù NOTE This expects that you have sqlite3 on your machine. Define Database Operations # Now define the database operations to be used by the handlers. These will be in db/user.go.\ndb/user.go # package db import ( \u0026#34;database/sql\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;myapp/models\u0026#34; ) type UserStore struct { db *sql.DB } func NewUserStore(db *sql.DB) *UserStore { return \u0026amp;UserStore{db: db} } func (s *UserStore) CreateUser(username, hashedPassword string) error { user := models.NewUser(username, hashedPassword) if err := user.ValidateForCreation(); err != nil { return err } user.BeforeCreate() query := `INSERT INTO users (username, password, created_at, updated_at) VALUES (?, ?, ?, ?)` result, err := s.db.Exec(query, user.Username, user.Password, user.CreatedAt, user.UpdatedAt, ) if err != nil { // Check for unique constraint violation if strings.Contains(err.Error(), \u0026#34;UNIQUE constraint failed\u0026#34;) { return models.ErrUsernameExists } return err } id, err := result.LastInsertId() if err != nil { return err } user.ID = id return nil } func (s *UserStore) GetUserByUsername(username string) (*models.User, error) { var user models.User query := \u0026#34;SELECT id, username, password FROM users WHERE username = ?\u0026#34; err := s.db.QueryRow(query, username).Scan(\u0026amp;user.ID, \u0026amp;user.Username, \u0026amp;user.Password) if err != nil { return nil, err } return \u0026amp;user, nil } JWT Token # The jwt internal package will contain all our jwt auth logic. Create the directory structure.\nmkdir -p internal/jwt The following is just quick and dirty logic for implementing it. Create the internal/jwt/token.go with the following contents.\ninternal/jwt/token.go # package jwt import ( \u0026#34;time\u0026#34; \u0026#34;github.com/golang-jwt/jwt/v4\u0026#34; ) var JwtKey = []byte(\u0026#34;your-secret-key\u0026#34;) // In production, use environment variables type Claims struct { Username string `json:\u0026#34;username\u0026#34;` jwt.StandardClaims } func GenerateToken(username string) (string, error) { expirationTime := time.Now().Add(24 * time.Hour) claims := \u0026amp;Claims{ Username: username, StandardClaims: jwt.StandardClaims{ ExpiresAt: expirationTime.Unix(), }, } token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims) return token.SignedString(JwtKey) } func ValidateToken(tokenStr string) (*Claims, error) { claims := \u0026amp;Claims{} token, err := jwt.ParseWithClaims(tokenStr, claims, func(token *jwt.Token) (interface{}, error) { return JwtKey, nil }) if err != nil || !token.Valid { return nil, err } return claims, nil } JWT Middleware # Now to add some Gin middleware for our auth. Create the internal/jwt/middleware.go with this function.\ninternal/jwt/middleware.go # package jwt import ( \u0026#34;net/http\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func AuthMiddleware() gin.HandlerFunc { return func(c *gin.Context) { authHeader := c.GetHeader(\u0026#34;Authorization\u0026#34;) if authHeader == \u0026#34;\u0026#34; { c.AbortWithStatus(http.StatusUnauthorized) return } tokenParts := strings.Split(authHeader, \u0026#34; \u0026#34;) if len(tokenParts) != 2 || tokenParts[0] != \u0026#34;Bearer\u0026#34; { c.AbortWithStatus(http.StatusUnauthorized) return } claims, err := ValidateToken(tokenParts[1]) if err != nil { c.AbortWithStatus(http.StatusUnauthorized) return } c.Set(\u0026#34;username\u0026#34;, claims.Username) c.Next() } } Create the handlers for the API # Start by defining a struct to pass a db pointer (and future inputs) to the handlers. Create the handlers directory.\nmkdir -p handlers And start by creating handlers/auth.go with the following. auth.go will be used for the signup and login methods. Technically we could just put all this domain logic in a single go file. But as the application grows, you will start to notice that finding specific logic could start getting scattered and inconsistent.\nhandlers/auth.go # package handlers import ( \u0026#34;myapp/db\u0026#34; ) type AuthHandler struct { userStore *db.UserStore } func NewAuthHandler(userStore *db.UserStore) *AuthHandler { return \u0026amp;AuthHandler{userStore: userStore} } In the handlers/signup.go we add our signup logic.\nhandlers/signup.go # package handlers import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;golang.org/x/crypto/bcrypt\u0026#34; \u0026#34;myapp/models\u0026#34; ) func (h *AuthHandler) Signup(c *gin.Context) { var user models.User if err := c.ShouldBindJSON(\u0026amp;user); err != nil { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) return } hashedPassword, err := bcrypt.GenerateFromPassword( []byte(user.Password), bcrypt.DefaultCost, ) if err != nil { c.JSON(http.StatusInternalServerError, gin.H{\u0026#34;error\u0026#34;: \u0026#34;Internal server error\u0026#34;}) return } if err := h.userStore.CreateUser(user.Username, string(hashedPassword)); err != nil { c.JSON(http.StatusInternalServerError, gin.H{\u0026#34;error\u0026#34;: \u0026#34;Failed to create user\u0026#34;}) return } c.Status(http.StatusCreated) } Now under handlers/login.go add the login function.\nhandlers/login.go # package handlers import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;golang.org/x/crypto/bcrypt\u0026#34; \u0026#34;myapp/internal/jwt\u0026#34; \u0026#34;myapp/models\u0026#34; ) func (h *AuthHandler) Login(c *gin.Context) { var user models.User if err := c.ShouldBindJSON(\u0026amp;user); err != nil { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) return } storedUser, err := h.userStore.GetUserByUsername(user.Username) if err != nil { c.JSON(http.StatusUnauthorized, gin.H{\u0026#34;error\u0026#34;: \u0026#34;Invalid credentials\u0026#34;}) return } if err := bcrypt.CompareHashAndPassword( []byte(storedUser.Password), []byte(user.Password), ); err != nil { c.JSON(http.StatusUnauthorized, gin.H{\u0026#34;error\u0026#34;: \u0026#34;Invalid credentials\u0026#34;}) return } token, err := jwt.GenerateToken(user.Username) if err != nil { c.JSON(http.StatusInternalServerError, gin.H{\u0026#34;error\u0026#34;: \u0026#34;Failed to generate token\u0026#34;}) return } c.JSON(http.StatusOK, gin.H{\u0026#34;token\u0026#34;: token}) } Finally all the user logic under handlers/user.go. This contains the protected api logic for users.\nhandlers/user.go # package handlers import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;myapp/db\u0026#34; \u0026#34;myapp/models\u0026#34; ) type UserHandler struct { userStore *db.UserStore } func NewUserHandler(userStore *db.UserStore) *UserHandler { return \u0026amp;UserHandler{userStore: userStore} } func (h *UserHandler) GetUser(c *gin.Context) { // Get username from the JWT claims that were set in the middleware username, exists := c.Get(\u0026#34;username\u0026#34;) if !exists { c.JSON(http.StatusInternalServerError, gin.H{\u0026#34;error\u0026#34;: \u0026#34;User context not found\u0026#34;}) return } // Fetch user details from the database user, err := h.userStore.GetUserByUsername(username.(string)) if err != nil { if err == models.ErrUserNotFound { c.JSON(http.StatusNotFound, gin.H{\u0026#34;error\u0026#34;: \u0026#34;User not found\u0026#34;}) return } c.JSON(http.StatusInternalServerError, gin.H{\u0026#34;error\u0026#34;: \u0026#34;Failed to fetch user details\u0026#34;}) return } // Return user data (password will be automatically excluded by json:\u0026#34;-\u0026#34; tag) c.JSON(http.StatusOK, user) } Core Application Setup # The main.go file initializes the server and configures routing. It separates public and authenticated routes.\nmain.go # package main import ( \u0026#34;log\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;myapp/db\u0026#34; \u0026#34;myapp/handlers\u0026#34; \u0026#34;myapp/internal/jwt\u0026#34; ) func main() { if err := db.InitDB(); err != nil { log.Fatalf(\u0026#34;Failed to initialize database: %v\u0026#34;, err) } defer db.CloseDB() userStore := db.NewUserStore(db.DB) authHandler := handlers.NewAuthHandler(userStore) r := gin.Default() // Public routes r.POST(\u0026#34;/login\u0026#34;, authHandler.Login) r.POST(\u0026#34;/signup\u0026#34;, authHandler.Signup) // Initialize handlers userHandler := handlers.NewUserHandler(userStore) // Protected routes authorized := r.Group(\u0026#34;/\u0026#34;) authorized.Use(jwt.AuthMiddleware()) { authorized.GET(\u0026#34;/user\u0026#34;, userHandler.GetUser) } if err := r.Run(\u0026#34;:8080\u0026#34;); err != nil { log.Fatalf(\u0026#34;Failed to start server: %v\u0026#34;, err) } } Running Your API # Simply tidy things up and run with\ngo mod tidy go run main.go Testing Your API # Now that everything\u0026rsquo;s set up, you can test your API using curl or any API testing tool:\nCreate a new user: curl -X POST http://localhost:8080/signup \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;username\u0026#34;:\u0026#34;testuser\u0026#34;,\u0026#34;password\u0026#34;:\u0026#34;securepass123\u0026#34;}\u0026#39; Log in to get a token: curl -X POST http://localhost:8080/login \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;username\u0026#34;:\u0026#34;testuser\u0026#34;,\u0026#34;password\u0026#34;:\u0026#34;securepass123\u0026#34;}\u0026#39; Use the token to access protected routes: curl http://localhost:8080/user \\ -H \u0026#34;Authorization: Bearer \u0026lt;your-token-here\u0026gt;\u0026#34; Summary # Throughout this tutorial, we\u0026rsquo;ve followed several security best practices:\nPassword hashing using bcrypt JWT-based authentication Protected routes with middleware No sensitive data exposure Proper error handling without revealing system details Input validation and sanitization These are just some basics. A lot more can be done (e.g. Add password complexity requirements, rate limiting, better logging, etc). In addition, there\u0026rsquo;s the whole containerization and deployment to consider.\nüìù NOTE Here are some further considerations. Remember that this is a development example. Remember to enable TLS, rotate passwords, and properly handle JWT secrets. Also consider creating roles to create some RBAC to the API. Again, you can find all this code on Github.\nThanks for reading. Happy coding! üöÄ\n","date":"Jan 25, 2025","permalink":"https://blog.mikesahari.com/posts/go-simple-api/","tags":["go","api","rest","jwt"],"title":"Building a REST API with Go"},{"content":"Hello readers. Welcome to my blog!\nI was debating on if I would write out a full post for this initial one (to test, you know?). Instead, I decided to go through my collection of notes and found a topic to post; Go \u0026amp; htmx.\nHowever, if you\u0026rsquo;d like to learn more about me, check out my about page.\nIntroduction # When building modern web applications, we often seek solutions that combine the robustness of server-side programming with the interactivity of client-side applications. Today, I\u0026rsquo;m excited to share my experience working with Go and HTMX, a powerful combination that achieves exactly this balance.\nHTMX is a lightweight JavaScript library that allows you to access modern browser features directly from HTML, without writing JavaScript. When paired with Go\u0026rsquo;s excellent web capabilities, it creates a streamlined development experience that\u0026rsquo;s both powerful and maintainable.\nProject Setup # Let\u0026rsquo;s start by creating a new Go project. First, initialize your Go module:\ngo mod init \u0026lt;project\u0026gt; For our web server, we\u0026rsquo;ll use Echo, a high-performance, minimalist Go web framework. While Go\u0026rsquo;s standard net/http package would work perfectly fine, Echo provides some nice quality-of-life features that will make our development smoother. Install it using:\ngo get github.com/labstack/echo/v4 Creating the Server # Create a main.go file in your project root. Here\u0026rsquo;s our server implementation with detailed explanations of each component:\npackage main import ( \u0026#34;html/template\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;github.com/labstack/echo/v4\u0026#34; \u0026#34;github.com/labstack/echo/v4/middleware\u0026#34; ) // TemplateRenderer is a custom html/template renderer for Echo framework // This allows us to use Go\u0026#39;s powerful templating system with Echo type TemplateRenderer struct { templates *template.Template } // Render handles the execution of templates with the provided data // This method is required to implement echo.Renderer interface func (t *TemplateRenderer) Render(w io.Writer, name string, data interface{}, c echo.Context) error { // Add global methods if data is a map // This makes route helpers available in templates if viewContext, isMap := data.(map[string]interface{}); isMap { viewContext[\u0026#34;reverse\u0026#34;] = c.Echo().Reverse } return t.templates.ExecuteTemplate(w, name, data) } func main() { // Create a new Echo instance e := echo.New() // Add essential middleware e.Pre(middleware.RemoveTrailingSlash()) // Handles URLs consistently with/without trailing slash e.Use(middleware.Logger()) // Logs HTTP requests e.Use(middleware.Recover()) // Recovers from panics // Set up template rendering renderer := \u0026amp;TemplateRenderer{ templates: template.Must(template.ParseGlob(\u0026#34;*.html\u0026#34;)), } e.Renderer = renderer // Define routes e.GET(\u0026#34;/\u0026#34;, func(c echo.Context) error { return c.String(http.StatusOK, \u0026#34;Hello, World!\\n\u0026#34;) }) e.GET(\u0026#34;/hello\u0026#34;, func(c echo.Context) error { res := map[string]interface{}{ \u0026#34;Message\u0026#34;: \u0026#34;This is a test\u0026#34;, } return c.Render(http.StatusOK, \u0026#34;index\u0026#34;, res) }) // Start server on port 31000 e.Logger.Fatal(e.Start(\u0026#34;:31000\u0026#34;)) } Setting Up the Frontend # Create an index.html file in your project root. This template will handle our view layer:\n{{define \u0026#34;index\u0026#34;}} \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Hello World\u0026lt;/title\u0026gt; \u0026lt;!-- Include TailwindCSS for styling --\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.tailwindcss.com\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- Include HTMX for dynamic interactions --\u0026gt; \u0026lt;script src=\u0026#34;https://unpkg.com/htmx.org@1.9.7\u0026#34; integrity=\u0026#34;sha384-EAzY246d6BpbWR7sQ8+WEm40J8c3dHFsqC58IgPlh4kMbRRI6P6WA+LA/qGAyAu8\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- Display the message passed from our Go handler --\u0026gt; \u0026lt;p\u0026gt;{{.Message}}\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; {{end}} Running the Application # To start your server, run:\ngo run main.go You can now access your application:\nVisit http://localhost:31000 to see the basic \u0026ldquo;Hello, World!\u0026rdquo; message Navigate to http://localhost:31000/hello to see the template-rendered message with HTMX capabilities Next Steps # This is just the beginning of what you can do with Go and HTMX. For a more complex implementation, check out my chat application repository: jenn-ai, which demonstrates advanced features like real-time updates and dynamic content loading.\nConclusion # The combination of Go and HTMX offers a powerful approach to building modern web applications. Go provides the robust backend we need, while HTMX allows us to add dynamic features without the complexity of a full JavaScript framework. This setup is particularly well-suited for applications that need to be both interactive and maintainable.\nI hope this guide helps you get started with your own Go and HTMX projects. Feel free to experiment with the code and adapt it to your needs.\nYou can see a more advanced version of all of this with a Chat App I wrote: here\nThat\u0026rsquo;s all I had for this post. Thanks for reading.\n","date":"Jan 23, 2025","permalink":"https://blog.mikesahari.com/posts/intro-to-go-htmx/","tags":["go","htmx"],"title":"Introduction to Go and HTMX"}]